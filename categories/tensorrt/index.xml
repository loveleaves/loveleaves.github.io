<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>TensorRT on 安哲睿</title>
        <link>https://loveleaves.github.io/categories/tensorrt/</link>
        <description>Recent content in TensorRT on 安哲睿</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Andrew Stark</copyright>
        <lastBuildDate>Wed, 05 Mar 2025 20:45:08 +0800</lastBuildDate><atom:link href="https://loveleaves.github.io/categories/tensorrt/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>【TensorRT】 TensorRT模型部署介绍</title>
        <link>https://loveleaves.github.io/p/tensorrt_deploy/</link>
        <pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate>
        
        <guid>https://loveleaves.github.io/p/tensorrt_deploy/</guid>
        <description>&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/latest/getting-started/quick-start-guide.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;tensorrt docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/archives/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;tensorrt api&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/latest/installing-tensorrt/installing.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;install tensorrt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/NVIDIA/TensorRT/tree/main/samples&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorRT samples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/wang-xinyu/tensorrtx&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Implementation of popular deep learning networks with TensorRT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tensorrt推理部署方案&#34;&gt;TensorRT推理部署方案
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/jinmin527/learning-cuda-trt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;learning-cuda-trt code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/loveleaves/TensorRT-Quantization&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;tensorRT quantization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;c硬代码方案&#34;&gt;C++硬代码方案
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;代表：&lt;a class=&#34;link&#34; href=&#34;https://github.com/wang-xinyu/tensorrtx&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;tensorrtx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;流程：C++硬代码=》TRT API =》 TRT Builder =》 TRT Engine&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;onnx方案&#34;&gt;ONNX方案
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;流程：ONNX(libnvonnxparser.so) =》TRT API =》 TRT Builder =》 TRT Engine&lt;/li&gt;
&lt;li&gt;一般思路：
&lt;ol&gt;
&lt;li&gt;导出模型onnx，查看输入和输出。&lt;/li&gt;
&lt;li&gt;查看代码，找到onnx的预处理，分析预处理逻辑&lt;/li&gt;
&lt;li&gt;利用上述信息实现onnx py推理实现&lt;/li&gt;
&lt;li&gt;验证正常可实现转TRT模型用C++实现推理&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tensorrt库文件&#34;&gt;TensorRT库文件
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;libnvinfer.so：TensorRT核心库&lt;/li&gt;
&lt;li&gt;libnvinfer_plugin.so：nvidia官方提供的插件，&lt;a class=&#34;link&#34; href=&#34;https://github.com/NVIDIA/TensorRT/tree/main/plugin&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;libprotobuf.so：protobuf库&lt;/li&gt;
&lt;li&gt;libnvonnxparser.so：ONNX解析&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tensorrt部署推理模型流程&#34;&gt;TensorRT部署推理模型流程
&lt;/h2&gt;&lt;h3 id=&#34;模型构建&#34;&gt;模型构建
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;tensorrt的工作流程如下图：
&lt;ul&gt;
&lt;li&gt;首先定义网络&lt;/li&gt;
&lt;li&gt;优化builder参数&lt;/li&gt;
&lt;li&gt;通过builder生成engine,用于模型保存、推理等&lt;/li&gt;
&lt;li&gt;engine可以通过序列化和逆序列化转化模型数据类型（转化为二进制byte文件，加快传输速率），再进一步推动模型由输入张量到输出张量的推理。&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;avatar&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;code structure
&lt;ol&gt;
&lt;li&gt;定义 builder, config 和network，其中builder表示所创建的构建器，config表示创建的构建配置（指定TensorRT应该如何优化模型），network为创建的网络定义。&lt;/li&gt;
&lt;li&gt;输入，模型结构和输出的基本信息（如下图所示）
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;avatar&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;生成engine模型文件&lt;/li&gt;
&lt;li&gt;序列化模型文件并存储&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;模型推理&#34;&gt;模型推理
&lt;/h3&gt;&lt;p&gt;执行推理的步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;准备模型并加载&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;创建runtime：&lt;code&gt;createInferRuntime(logger)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用运行时时，以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;反序列化创建engine, 得为engine提供数据：&lt;code&gt;runtime-&amp;gt;deserializeCudaEngine(modelData, modelSize)&lt;/code&gt;,其中&lt;code&gt;modelData&lt;/code&gt;包含的是input和output的名字，形状，大小和数据类型&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ModelData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;INPUT_NAME&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;INPUT_SHAPE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// [B, C, H, W]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OUTPUT_NAME&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;prob&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;OUTPUT_SIZE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;DTYPE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;trt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从engine创建执行上下文:&lt;code&gt;engine-&amp;gt;createExecutionContext()&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;创建CUDA流&lt;code&gt;cudaStreamCreate(&amp;amp;stream)&lt;/code&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CUDA编程流是组织异步工作的一种方式，创建流来确定batch推理的独立&lt;/li&gt;
&lt;li&gt;为每个独立batch使用IExecutionContext(3.2中已经创建了)，并为每个独立批次使用cudaStreamCreate创建CUDA流。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据准备：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在host上声明&lt;code&gt;input&lt;/code&gt;数据和&lt;code&gt;output&lt;/code&gt;数组大小，搬运到gpu上&lt;/li&gt;
&lt;li&gt;要执行inference，必须用一个指针数组指定&lt;code&gt;input&lt;/code&gt;和&lt;code&gt;output&lt;/code&gt;在gpu中的指针。&lt;/li&gt;
&lt;li&gt;推理并将&lt;code&gt;output&lt;/code&gt;搬运回CPU&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;启动所有工作后，与所有流同步以等待结果:&lt;code&gt;cudaStreamSynchronize&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;按照与创建相反的顺序释放内存&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;重要接口使用说明&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TR10中的节点索引变更为字符串，之前是数值&lt;/li&gt;
&lt;li&gt;必须使用createNetworkV2,并指定为1（表示显性batch）。createNetwork已经废弃，非显性batch官方不推荐。这个方式直接影响推理时enqueue还是enqueueV2（TR10为V3）&lt;/li&gt;
&lt;li&gt;builder、config等指针，记得释放，否则会有内存泄漏，使用ptr-&amp;gt;destroy()（TR10使用delete）释放&lt;/li&gt;
&lt;li&gt;markOutput表示是该模型的输出节点，mark几次，就有几个输出，addlnput几次就有几个输入。这与推理时相呼应&lt;/li&gt;
&lt;li&gt;workspaceSize是工作空间大小，某些layer需要使用额外存储时，不会自己分配空间，而是为了内存复用，直接找tensorRT要workspace空间。&lt;/li&gt;
&lt;li&gt;bindings是tensorRT对输入输出张量的描述，&lt;code&gt;bindings = input-tensor + output-tensor&lt;/code&gt;。比如input有a, output有b,c, d,那么&lt;code&gt;bindings = [a, b, c, d],bindings[0] = a, bindings[2] = c&lt;/code&gt;。此时看到&lt;code&gt;engine- &amp;gt;getBindingDimensions(0)&lt;/code&gt;你得知道获取的是什么（TRT10改成了IOTensors）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enqueueV2&lt;/code&gt;是异步推理，加入到stream队列等待执行。输入的bindings则是tensors的指针（注意是device pointer）。其shape对应于编译时指定的输入输出的shape(这里只演示全部shape静态)（TRT10使用&lt;code&gt;enqueueV3&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;动态shape&#34;&gt;动态shape
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;构建网络时：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.1. 必须在模型定义时，输入维度给定为-1，否则该维度不会动态。注意一下两点：
&lt;ul&gt;
&lt;li&gt;1.1.1. 若onnx文件，则onnx文件打开后应该看到为动态或者-1&lt;/li&gt;
&lt;li&gt;1.1.2. 如果你的模型中存在reshape类操作，那么reshape的参数必须随动态进行计算。而大部分时候这都是问题。除非你是全卷积模型，否则大部分时候只需要为batch_size维度设置为动态，其他维度尽量避免设置动态&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;1.2. 配置profile:
&lt;ul&gt;
&lt;li&gt;1.2.1. create: &lt;code&gt;builder-&amp;gt;createOptimizationProfile()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;1.2.2. set: &lt;code&gt;setDimensions()&lt;/code&gt;设置&lt;code&gt;kMIN&lt;/code&gt;, &lt;code&gt;kOPT&lt;/code&gt;, &lt;code&gt;kMAX&lt;/code&gt;的一系列输入尺寸范围&lt;/li&gt;
&lt;li&gt;1.2.3. add:&lt;code&gt;config-&amp;gt;addOptimizationProfile(profile);&lt;/code&gt;添加profile到网络配置中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;推理阶段时：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2.1. 您需要在选择profile的索引后设置&lt;code&gt;input&lt;/code&gt;维度：&lt;code&gt;execution_context-&amp;gt;setBindingDimensions(0, nvinfer1::Dims4(1, 1, 3, 3));&lt;/code&gt; （TR10为&lt;code&gt;setInputShape&lt;/code&gt;）
&lt;ul&gt;
&lt;li&gt;2.1.1. 关于profile索引:
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;multiple-optimization-profiles&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;2.1.2. 在运行时，向engine请求绑定维度会返回用于构建网络的相同维度。这意味着，得到的还是动态的维度[-1, in_channel, -1, -1]：
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getBindingDimensions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// return [-1, 1, -1, -1]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// execution_context-&amp;gt;getTensorShape // TR10接口
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;获取当前的实际维度，需要查询执行上下文：
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getBindingDimensions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// return [3, 1, 3, 3]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;检查正确性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们通常可以利用pytorch来校验是否发生了错误&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;onnx模型操作&#34;&gt;ONNX模型操作
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/loveleaves/onnx-quantization/tree/main/onnx-editor&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;代码实战&lt;/a&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;pytorch-gen-onnx.py&lt;/code&gt;：是之前讲过的从pytorch转换onnx格式的代码。&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;onnx-ml.proto&lt;/code&gt;和&lt;code&gt;make-onnx-pb.sh&lt;/code&gt;了解onnx的结构
&lt;ul&gt;
&lt;li&gt;2.1. onnx是基于protobuf来做数据存储和传输,*.proto后缀文件, 其定义是protobuf语法，类似json。&lt;/li&gt;
&lt;li&gt;2.2. 对于变量结构、类型等，我们可以参照&lt;code&gt;onnx-ml.proto&lt;/code&gt;里面的定义。这个文件有800多行，放心我们只要搞清楚里面的核心部分就行：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ModelProto&lt;/code&gt;:当加载了一个onnx后，会获得一个&lt;code&gt;ModelProto&lt;/code&gt;。它包含一个&lt;code&gt;GraphProto&lt;/code&gt;和一些版本，生产者的信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GraphProto&lt;/code&gt;: 包含了四个repeated数组(可以用来存放N个相同类型的内容，key值为数字序列类型.)。这四个数组分别是node(&lt;code&gt;NodeProto&lt;/code&gt;类型)，input(&lt;code&gt;ValueInfoProto&lt;/code&gt;类型)，output(&lt;code&gt;ValueInfoProto&lt;/code&gt;类型)和initializer(&lt;code&gt;TensorProto&lt;/code&gt;类型)；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeProto&lt;/code&gt;: 存node，放了模型中所有的计算节点,语法结构如下：
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;nodeproto&#34;
	
	
&gt;
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;avatar&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ValueInfoProto&lt;/code&gt;: 存input，放了模型的输入节点。存output，放了模型中所有的输出节点；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TensorProto&lt;/code&gt;: 存initializer，放了模型的所有权重参数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AttributeProto&lt;/code&gt;:每个计算节点中还包含了一个&lt;code&gt;AttributeProto&lt;/code&gt;数组，用来描述该节点的属性，比如Conv节点或者说卷积层的属性包含group，pad，strides等等；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2.3. 通过protoc编译&lt;code&gt;onnx-ml.proto&lt;/code&gt;，产生&lt;code&gt;onnx-ml.pb.cc&lt;/code&gt;文件
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;bash make-onnx-pb.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;create-onnx.py
&lt;ul&gt;
&lt;li&gt;3.1. create-onnx.py直接从构建onnx，不经过任何框架的转换。通过import onnx和onnx.helper提供的make_node，make_graph，make_tensor等等接口我们可以轻易的完成一个ONNX模型的构建。&lt;/li&gt;
&lt;li&gt;3.2. 需要完成对node，initializer，input，output，graph，model的填充&lt;/li&gt;
&lt;li&gt;3.3. 读懂creat-onnx.py以make_node为例：
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;make-node&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;edit-onnx.py
&lt;ul&gt;
&lt;li&gt;4.1. 由于protobuf任何支持的语言，我们可以使用[c/c++/python/java/c#等等]实现对onnx文件的读写操作&lt;/li&gt;
&lt;li&gt;4.2. 掌握onnx和helper实现对onnx文件的各种编辑和修改
&lt;ul&gt;
&lt;li&gt;增：一般伴随增加node和tensor
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;graph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;initializer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xxx_tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;graph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;insert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xxx_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;删：
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;graph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xxx_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;改：
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;input_node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;data&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;read-onnx.py
&lt;ul&gt;
&lt;li&gt;5.1 通过&lt;code&gt;graph&lt;/code&gt;可以访问参数，数据是以protobuf的格式存储的，因此当中的数值会以bytes的类型保存。需要用&lt;code&gt;np.frombuffer&lt;/code&gt;方法还原成类型为&lt;code&gt;float32&lt;/code&gt;的&lt;code&gt;ndarray&lt;/code&gt;。注意还原出来的&lt;code&gt;ndarray&lt;/code&gt;是只读的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;onnx-parser&#34;&gt;ONNX Parser
&lt;/h3&gt;&lt;p&gt;onnx解析器有两个选项，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;libnvonnxparser.so&lt;/code&gt;或者&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/onnx/onnx-tensorrt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;onnx-tensorrt parser&lt;/a&gt;(源代码)。&lt;/li&gt;
&lt;li&gt;使用源代码的目的，是为了更好的进行自定义封装，简化插件开发或者模型编译的过程，更加具有定制化，遇到问题可以调试&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;onnx-tensorrt parser&lt;/code&gt;代码使用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;什么是onnx:
&lt;ol&gt;
&lt;li&gt;先看名字：Open Neural Network Exchange(ONNX) 是一个开放的生态系统，使代码不被局限在框架和平台中。&lt;/li&gt;
&lt;li&gt;具体一点：onnx可以把你的神经网络模型(PyTroch, TF, Caffe)统统转为标准的ONNX格式(一种protobuf格式)，然后就可在各种平台(云平台, windows, linux)和设备(cpu, gpu, npu)上运行
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/6.onnx.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;onnx&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;先看文件&lt;code&gt;gen-onnx.py&lt;/code&gt;以pytorch构建的模型为例讲：pytorch模型转onnx格式
&lt;ol&gt;
&lt;li&gt;构建一个pytorch网络，并声明一个model对象&lt;/li&gt;
&lt;li&gt;如果进行推理，将模型设为推理状态：这一点很重要，因为像dropout, batchnorm这样的算子在推理和训练模式下的行为是不同的。&lt;/li&gt;
&lt;li&gt;导出为onnx模型：&lt;code&gt;torch.onnx.export()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;运行python脚本，生成onnx，在&lt;code&gt;main.cpp&lt;/code&gt;中会对其进行解析
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;python&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gen&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;onnx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;运行后的图示：
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/7.onnx-proto.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;onnx-proto&#34;
	
	
&gt;
&lt;ul&gt;
&lt;li&gt;Protobuf则通过onnx-ml.proto编译得到onnx-ml.pb.h和onnx-ml.pb.cc或onnx_ml_pb2.py&lt;/li&gt;
&lt;li&gt;然后用onnx-ml.pb.cc和代码来操作onnx模型文件，实现增删改&lt;/li&gt;
&lt;li&gt;onnx-ml.proto则是描述onnx文件如何组成的，具有什么结构，他是操作onnx经常参照的东西&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;再看文件&lt;code&gt;main.cpp&lt;/code&gt;讲解如何解析onnx格式
&lt;ol&gt;
&lt;li&gt;使用onnx解析器：&lt;code&gt;createParser&lt;/code&gt;的api在文件NvOnnxParser.h中&lt;/li&gt;
&lt;li&gt;在这里使用onnx的结果填充到network中，而手动构建网络则是将输入和算子填入network中，区别如图所示：
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/8.onnx-major-difference.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;onnx-major-difference&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;导出后，可以使用netron软件进行打开查看:https://github.com/lutzroeder/Netron&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;除了构建过程的区别，makefile中，库文件也需要加上nvonnxparser：
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/9.makefile-difference.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;makefile-difference&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;severity_string 和 log仅是工具函数，无需过分关注&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;导出trt模型&#34;&gt;导出TRT模型
&lt;/h4&gt;&lt;p&gt;为了使用onnx导出网络有三种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们使用自带的解析器，&lt;code&gt;libnvonnxparser.so&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;从源代码编译：&lt;a class=&#34;link&#34; href=&#34;https://github.com/onnx/onnx-tensorrt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;onnx-tensorrt&lt;/a&gt;，主要protobuf文件：
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/onnx/onnx/blob/main/onnx/onnx-ml.proto&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;onnx-ml.proto 来源&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/onnx/onnx/blob/main/onnx/onnx-operators-ml.proto&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;onnx-operators-ml.proto 来源&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;利用官方工具&lt;a class=&#34;link&#34; href=&#34;https://github.com/NVIDIA/TensorRT/tree/main/samples/trtexec&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;code&gt;trtexec&lt;/code&gt;&lt;/a&gt;，&lt;a class=&#34;link&#34; href=&#34;https://github.com/loveleaves/TensorRT-Quantization/tree/main/object_detection/YOLOv8/normal&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YOLOv8部署推理案例&lt;/a&gt;
Usage:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/usr/src/tensorrt/bin/trtexec &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--onnx&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;yolov8s.onnx &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--saveEngine&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;yolov8s.engine &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;--fp16
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# or --int8&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;plugin&#34;&gt;Plugin
&lt;/h2&gt;&lt;p&gt;1.如何在pytorch里面导出一个插件
2.插件解析时如何对应，在onnx parser中如何处理
3.插件的creator实现
4.插件的具体实现，继承自IPluginV2DynamicExt
5.插件的序列化与反序列化&lt;/p&gt;
&lt;h2 id=&#34;量化&#34;&gt;量化
&lt;/h2&gt;&lt;h3 id=&#34;int8量化&#34;&gt;int8量化
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;对于int8，需要配置setFlag nvinfer1::BuilderFlag::kINT8，并且配置setInt8Calibrator&lt;/li&gt;
&lt;li&gt;对于Int8EntropyCalibrator，则需要继承自IInt8EntropyCalibrator2&lt;/li&gt;
&lt;li&gt;Int8EntropyCalibrator的作用，是读取并预处理图像数据作为输入
&lt;ul&gt;
&lt;li&gt;标定的原理，是通过输入标定图像I，使用参数WInt8推理得到输出结果PInt8，然后不断调整WInt8，使得输出PInt8与PFloat32越接近越好&lt;/li&gt;
&lt;li&gt;因此标定时通常需要使用一些图像，正常发布时，一般使用100张图左右即可&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;常用的Calibrator
&lt;ul&gt;
&lt;li&gt;Int8EntropyCalibrator2
熵校准选择张量的比例因子来优化量化张量的信息论内容，通常会抑制分布中的异常值。这是当前推荐的熵校准器。默认情况下，校准发生在图层融合之前。推荐用于基于 CNN 的网络。
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/10.int8EntropyCalibrator2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;int8EntropyCalibrator2&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;Iint8MinMaxCalibrator
该校准器使用激活分布的整个范围来确定比例因子。它似乎更适合NLP任务。默认情况下，校准发生在图层融合之前。推荐用于NVIDIA BERT等网络。
&lt;img src=&#34;https://loveleaves.github.io/imgs/tensorRT/11.int8MinMaxCalibrator.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;int8MinMaxCalibrator&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;计算机中的float计算量是非常大的，而改成int8后，计算量相比可以提升数倍
&lt;ul&gt;
&lt;li&gt;对于实际操作时，input[float32], w[int8], bias[float32], output[float32]&lt;/li&gt;
&lt;li&gt;步骤如下：
&lt;ul&gt;
&lt;li&gt;input[int8] = to_int8(input[float32])&lt;/li&gt;
&lt;li&gt;y[int16] = input[int8] * w[int8]   # 此处乘法会由计算机转换为int16，保证精度&lt;/li&gt;
&lt;li&gt;output[float32] = to_float32(y[int16]) + bias[float32]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所以整个过程的只是为了减少float32的乘法数量以实现提速&lt;/li&gt;
&lt;li&gt;对于to_int8的过程，并不是直接的线性缩放，而是经过KL散度计算最合适的截断点（最大、最小值），进而进行缩放，使得权重的分布尽可能小的被改变
&lt;ul&gt;
&lt;li&gt;可以参照这个地址：https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
