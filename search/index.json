[{"content":"References Int8量化-介绍 量化方法汇总 从TensorRT与ncnn看CNN卷积神经网络int8量化算法 谷歌量化白皮书：Quantizing deep convolutional networks for efficient inference: A whitepaper、Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference ppq 神经网络 - 量化与部署 模型压缩：模型量化打怪升级之路 - 1 工具篇 神经网络加速基础知识 计算机体系结构/组成原理 主要了解以下部分：\n指令系统 计算机组成原理和结构 流水线技术 指令耗时/热点指令 现代处理器 经典CPU体系结构 x86架构（CISC） 胶水typo，多核心 部分组件公共化，提高集成度 GPU架构 共享指令译码和控制，ALU运行的指令相同（分支发散问题） GPU架构介绍 ASIC专用芯片架构 继续移除非必要指令（浮点、图形支持等） 特定领域设计 异构计算与主从设备交互 找到性能瓶颈（performance bottleneck） 高算力场景=》用ASIC等芯片，提高算力，高延迟 低延迟场景=》用FPGA等芯片，降低延迟，低算力 性能热点分析工具 torch Profiler Nsight Compute Nsight Compute 量化硬件实现 量化算子 基本公式：\n1 2 3 4 float value = 1.0; // 输入值 float scale = 0.1; // 用于缩放输入值（尺度因子） int32 qt_32 = round_fn(value/scale); // 取整 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 取整函数round_fn比较特别，在不同硬件上有不同的取整模式（主要对中间值，如1.5，-2.5等），常见取整模式：\nRound half to even，torch 、 C使用，向偶数方向取整 Round half away from zero，向正负无穷方向取整 Round half toward zero，向0方向取整 Round half down，向下取整 Round half up，向上取整 量化子图与全精度子图（quantized subgraph） 权重是可以直接计算出来的，推理的时候只要计算一下量化算子即可\n通常情况，量化算子全部支持场景： 存在不支持量化算子，可用子图分割分离不支持运算子图分开计算，但会导致访存开销为热点 反量化算子 基本公式：\n1 2 3 Char value = 1; // 量化算子/运算输出值 float scale = 0.1; // 用于缩放输入值（尺度因子） Float deq = (value * scale); 量化模式（量化与反量化） 对称量化：基本量化模式，分布对称 1 2 3 int32 qt_32 = round_fn(value/scale); // 取整 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 // 反量化对应量化反向操作，类似encode《=》decode 非对称量化：充分利用int8数值范围（如relu负数范围） 1 2 int32 qt_32 = round_fn(value/scale) + offset; // 取整 uint8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 整数量化（power of two）：部分硬件不支持浮点运算，用整数运算替换 1 2 int32 qt_32 = round_fn(value * (2 \u0026lt;\u0026lt; shift)); // 取整，shift-定点位 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 指数量化\u0026hellip; tensor量化与通道量化 以上对称/非对称量化、整数量化中的offset、shift可以整个数据为粒度进行量化（可能数值偏差大，量化差），也可以采用其他粒度进行量化：\ntensor量化（per-tensor）：以单个tensor为粒度 通道量化（per-channel）：以单个channel为粒度 量化计算怎么写 整数运算：在许多硬件上，整数运算的微指令条数和指令吞吐量等可能和浮点差不多甚至比浮点差 访存：量化后数据传输耗时少 向量化技术：SIMD/SIMT，代码向量化网站 量化计算一般是：量化+反量化，目的是为了保证量化计算的逻辑与原来一致 量化乘法（quantized mul） 正常int8计算会溢出，所以先反量化成float计算乘法再量化，即量化计算一般要加上rescale操作\n1 2 3 4 5 6 7 // 原本量化运算 ouput[i][j]=inputa[i][j]*inputb[i][j]; //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn(inputa[i][j]*scale_a * inputb[i][j] * scale_b / scale_c)); // scale 为float 即 ouput[i][j]=quantizied(inputa[i][j] * inputb[i][j] / scale_abc); // scale_abc 可提前算 // 同理，如果采用整数量化 即 ouput[i][j]=quantizied(inputa[i][j] * inputb[i][j] \u0026lt;\u0026lt; round(log2 scale_abc)); // scale_abc 可提前算 量化加法 加法要求两个操作数的scale必须一致 1 2 3 4 5 6 // 原本量化运算 ouput[i][j]=inputa[i][j]+inputb[i][j]; //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn((inputa[i][j]*scale_a + inputb[i][j] * scale_b) / scale_c)); // scale 为float // 这里加法要求scale_a和scale_b必须一致（两个操作数的scale） 即 ouput[i][j]=quantizied((inputa[i][j] + inputb[i][j]) / scale_ab); // scale_ab 可提前算 量化激活函数 要求输入输出的scale必须一致 1 2 3 4 5 6 7 // 原本clip量化运算 ouput[i][j]=max(inputa[i][j], min); //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn((inputa[i][j]*scale_in + min) / scale_out)); // scale 为float // 这里加法要求scale_in和scale_out必须一致 即 ouput[i][j]=inputa[i][j] + min / scale_in; // 注意这里没有round_fn、clip操作，min被动量化 // 这时这类算子被称为被动量化算子，如clip、relu、concat等 量化矩阵乘（quantized Gemm） int8输入=》int16/32计算乘法=》int32/64保存求和结果=》量化为int8输出 量化非线性运算 算子包含非线性运算。如：exp、tanh、sigmoid、softmax等 非线性运算：用int无法替代float计算求得结果 CPU、GPU上，不做量化，以全精度模式运行 FPGA、ASIC、DSP上，不支持浮点运算，需要更改算子计算逻辑，以线性运算拟合或直接查表 计算图 算子 常见算子：https://github.com/onnx/onnx/blob/main/docs/Operators.md 最小调度单位 算子融合加速：减少访存调用栈开销，优化计算逻辑 常见计算图优化（算子融合） 计算图优化实践：https://www.bilibili.com/video/BV1Kr4y1n7cy/\n激活函数融合：Computing Op -\u0026gt; Activation =\u0026gt; ConputAct 常见OP：Conv、ConvTranpose、Gemm 常见Act：Relu、Clip（relu6）、Prelu、Tanh、Sigmoid、Switsh 移除batchnorm和dropout 常量折叠：把常量融合进行计算 矩阵乘融合 conv-add融合：Conv + any =\u0026gt; Y = Wx + (Y2 + B) Conv：Y1=WX+B any：Y2 联合定点 用于支持多后端使用，保留原始计算图信息和量化后的计算图信息\n图调度（Graph Dispatching） 误差分析后发现部分算子的误差较大，可将其单独调度到非量化平台计算 图模式匹配 一个计算图可以表示为一个由节点、边集、输入边、输出边组成的四元组 C = {N, E, I, O}。\n我们往往需要在计算图中寻找指定结构。\n如何用一个严谨的方式定义结构？ 如何设计计算模式匹配法，使得其尽可能高效？ 图模式匹配是量化算法、算子融合、算子调度的基础。 图模式匹配可用方法：子图匹配、遍历模式匹配 例子 想象一个场景，onnx不支持swish算子，其可能用以下算子组合实现： 这样有一个问题，量化时会将这三个算子都量化一遍，但其实只需要量化最后一个mul算子即可。这里就可以利用图模式匹配匹配到这个替代的swish结构，并针对性进行处理。\n1 2 3 4 5 6 7 8 9 // 匹配swish，子图模式匹配 search_engine = SearchableGraph(graph) results = search_engine.pattern_matching( patterns = lambda x: x.is_computing_op(\u0026#39;Sigmoid\u0026#39;, \u0026#39;Mul\u0026#39;), edges = [[0, 1], [1, 2], [0, 2]], exclusive = True ) for computing_op, sigmoid, mul in results: ... 遍历模式匹配 匹配模式：起点表达式=》中继点..=》终点..，自动机 步骤：图拆成树，树拆成链，在每个链上进行模式匹配，期间可用动态规划优化 子图模式匹配 子图同构问题为NP-Hard问题，使用近似算法 避免模式pattern多义性，保持互斥 算子调度 SOI正向传播：从开始算子往后找，可能有多个匹配 正向传播的反方向，从终点算子开始往前找 调度争议区：既可以量化，又不可以量化 调度约束： 激活函数与计算节点保持同一平台 NMS、shape、TOPK、MAX与计算节点保持同一平台 参与图融合的算子保持同一平台 孤立计算节点不量化 多输入算子所有输入同平台 手动调度：权衡精度和速度，考虑硬件支持情况 神经网络部署 运行时（runtime） 实际硬件执行库，针对不同硬件有不同实现\n神经网络部署 各厂商的训练框架、推理框架、硬件厂商 部署流程：训练框架训练模型=》导出统一中间表达模型（可选）=》指定推理框架=》指定硬件执行 部署建议：\n确保你的网络可以被Onnx表示，避免其中出现复杂条件逻辑及循环逻辑。 学会自定义算子，以备不时之需，（包括自定义算子的推理实现）。 避免使用各种小Trick，额外加入的算子很可能会破坏图优化。 神经网络能跑多快是Runtime决定的，神经网络加速应当根据runtime进行。 用一下 Onnx Simplifier。 写一个固定的 batchsize大小（latency和吞吐）。 ONNX部署推理 onnxruntime TensorRT Develop Guide, docs、quantization 连贯量化区：不要在网络中过度使用不可量化算子 网络结构设计、量化点插入不能破坏图融合 Tensor对齐 Profiler工具分析：Nsight System 自定义算子，必要时自己写plugin：https://github.com/NVIDIA/TensorRT/tree/release/10.8/plugin 量化理论分析 量化参数选择 假设 Ln/s用比值来评估量化偏差，忽略实际值的大小 int8实际应为-128，这里为了对称写成-127 注意这里的截断边界条件为.5，如127.5，-127.5，为了尽可能保留原精度 最大值截断 也就是说最大值截断在元素值趋于无限时，会出现误差发散的情况。 分位数截断 实际运用时，结合3-sigma原则取近似sigma值 最优截断 Bernard Widrow公式 最优估计问题：\n最优截断要求pdf的三阶积分，并求导令上式为0，对于大部分分布而言，无法顺利求得解析解。 同时在很多情况下，局部的MSE最优并不是全局MSE最优的。 数据量小时，估计的方差很大。 枚举最优截断 梯度优化截断 量化误差分析 https://www.bilibili.com/video/BV1V94y117Ej/\n量化框架 PPQ PPQ框架介绍 大模型LLM推理加速 TensorRT pytorch-quantization NCNN NCNN Conv量化详解 ","date":"2025-02-10T00:00:00Z","permalink":"https://loveleaves.github.io/p/quantization/","title":"【量化】 神经网络量化介绍"},{"content":"设计模式简介 以下引用自菜鸟教程、design pattern\n设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。\n设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。\n什么是 GOF（四人帮，全拼 Gang of Four）？ 在 1994 年，由 Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 四人合著出版了一本名为 Design Patterns - Elements of Reusable Object-Oriented Software（中文译名：设计模式 - 可复用的面向对象软件元素） 的书，该书首次提到了软件开发中设计模式的概念。\n四位作者合称 GOF（四人帮，全拼 Gang of Four）。他们所提出的设计模式主要是基于以下的面向对象设计原则。\n对接口编程而不是对实现编程。 优先使用对象组合而不是继承。 设计模式之美-王争 知识概览图 课程目录 文章导览 简介 开篇词 | 一对一的设计与编码集训，让你告别没有成长的烂代码！ 01 | 为什么说每个程序员都要尽早地学习并掌握设计模式相关知识？ 02 | 从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？ 03 | 面向对象、设计原则、设计模式、编程规范、重构，这五者有何关系？ 04 | 理论一：当谈论面向对象的时候，我们到底在谈论什么？ 05 | 理论二：封装、抽象、继承、多态分别可以解决哪些编程问题？ 06 | 理论三：面向对象相比面向过程有哪些优势？面向过程真的过时了吗？ 07 | 理论四：哪些代码设计看似是面向对象，实际是面向过程的？ 08 | 理论五：接口vs抽象类的区别？如何用普通的类模拟抽象类和接口？ 09 | 理论六：为什么基于接口而非实现编程？有必要为每个类都定义接口吗？ 10 | 理论七：为何说要多用组合少用继承？如何决定该用组合还是继承？ 11 | 实战一（上）：业务开发常用的基于贫血模型的MVC架构违背OOP吗？ 12 | 实战一（下）：如何利用基于充血模型的DDD开发一个虚拟钱包系统？ 13 | 实战二（上）：如何对接口鉴权这样一个功能开发做面向对象分析？ 14 | 实战二（下）：如何利用面向对象设计和编程开发接口鉴权功能？ 15 | 理论一：对于单一职责原则，如何判定某个类的职责是否够“单一”？ 16 | 理论二：如何做到“对扩展开放、修改关闭”？扩展和修改各指什么？ 17 | 理论三：里式替换（LSP）跟多态有何区别？哪些代码违背了LSP？ 18 | 理论四：接口隔离原则有哪三种应用？原则中的“接口”该如何理解？ 19 | 理论五：控制反转、依赖反转、依赖注入，这三者有何区别和联系？ 20 | 理论六：我为何说KISS、YAGNI原则看似简单，却经常被用错？ 21 | 理论七：重复的代码就一定违背DRY吗？如何提高代码的复用性？ 22 | 理论八：如何用迪米特法则（LOD）实现“高内聚、松耦合”？ 23 | 实战一（上）：针对业务系统的开发，如何做需求分析和设计？ 24 | 实战一（下）：如何实现一个遵从设计原则的积分兑换系统？ 25 | 实战二（上）：针对非业务的通用框架开发，如何做需求分析和设计？ 26 | 实战二（下）：如何实现一个支持各种统计规则的性能计数器？ 27 | 理论一：什么情况下要重构？到底重构什么？又该如何重构？ 28 | 理论二：为了保证重构不出错，有哪些非常能落地的技术手段？ 29 | 理论三：什么是代码的可测试性？如何写出可测试性好的代码？ 30 | 理论四：如何通过封装、抽象、模块化、中间层等解耦代码？ 31 | 理论五：让你最快速地改善代码质量的20条编程规范（上） 32 | 理论五：让你最快速地改善代码质量的20条编程规范（中） 33 | 理论五：让你最快速地改善代码质量的20条编程规范（下） 34 | 实战一（上）：通过一段ID生成器代码，学习如何发现代码质量问题 35 | 实战一（下）：手把手带你将ID生成器代码从“能用”重构为“好用” 36 | 实战二（上）：程序出错该返回啥？NULL、异常、错误码、空对象？ 37 | 实战二（下）：重构ID生成器项目中各函数的异常处理代码 38 | 总结回顾面向对象、设计原则、编程规范、重构技巧等知识点 39 | 运用学过的设计原则和思想完善之前讲的性能计数器项目（上） 40 | 运用学过的设计原则和思想完善之前讲的性能计数器项目（下） 41 | 单例模式（上）：为什么说支持懒加载的双重检测不比饿汉式更优？ 42 | 单例模式（中）：我为什么不推荐使用单例模式？又有何替代方案？ 43 | 单例模式（下）：如何设计实现一个集群环境下的分布式单例模式？ 44 | 工厂模式（上）：我为什么说没事不要随便用工厂模式创建对象？ 45 | 工厂模式（下）：如何设计实现一个Dependency Injection框架？ 46 | 建造者模式：详解构造函数、set方法、建造者模式三种对象创建方式 47 | 原型模式：如何最快速地clone一个HashMap散列表？ 48 | 代理模式：代理在RPC、缓存、监控等场景中的应用 49 | 桥接模式：如何实现支持不同类型和渠道的消息推送系统？ 50 | 装饰器模式：通过剖析Java IO类库源码学习装饰器模式 51 | 适配器模式：代理、适配器、桥接、装饰，这四个模式有何区别？ 52 | 门面模式：如何设计合理的接口粒度以兼顾接口的易用性和通用性？ 53 | 组合模式：如何设计实现支持递归遍历的文件系统目录树结构？ 54 | 享元模式（上）：如何利用享元模式优化文本编辑器的内存占用？ 55 | 享元模式（下）：剖析享元模式在Java Integer、String中的应用 56 | 观察者模式（上）：详解各种应用场景下观察者模式的不同实现方式 57 | 观察者模式（下）：如何实现一个异步非阻塞的EventBus框架？ 58 | 模板模式（上）：剖析模板模式在JDK、Servlet、JUnit等中的应用 59 | 模板模式（下）：模板模式与Callback回调函数有何区别和联系？ 60 | 策略模式（上）：如何避免冗长的if-else/switch分支判断代码？ 61 | 策略模式（下）：如何实现一个支持给不同大小文件排序的小程序？ 62 | 职责链模式（上）：如何实现可灵活扩展算法的敏感信息过滤框架？ 63 | 职责链模式（下）：框架中常用的过滤器、拦截器是如何实现的？ 64 | 状态模式：游戏、工作流引擎中常用的状态机是如何实现的？ 65 | 迭代器模式（上）：相比直接遍历集合数据，使用迭代器有哪些优势？ 66 | 迭代器模式（中）：遍历集合的同时，为什么不能增删集合元素？ 67 | 迭代器模式（下）：如何设计实现一个支持“快照”功能的iterator？ 68 | 访问者模式（上）：手把手带你还原访问者模式诞生的思维过程 69 | 访问者模式（下）：为什么支持双分派的语言不需要访问者模式？ 70 | 备忘录模式：对于大对象的备份和恢复，如何优化内存和时间的消耗？ 71 | 命令模式：如何利用命令模式实现一个手游后端架构？ 72 | 解释器模式：如何设计实现一个自定义接口告警规则功能？ 73 | 中介模式：什么时候用中介模式？什么时候用观察者模式？ 74 | 总结回顾23种经典设计模式的原理、背后的思想、应用场景等 75 | 在实际的项目开发中，如何避免过度设计？又如何避免设计不足？ 76 | 开源实战一（上）：通过剖析Java JDK源码学习灵活应用设计模式 77 | 开源实战一（下）：通过剖析Java JDK源码学习灵活应用设计模式 78 | 开源实战二（上）：从Unix开源开发学习应对大型复杂项目开发 79 | 开源实战二（中）：从Unix开源开发学习应对大型复杂项目开发 80 | 开源实战二（下）：从Unix开源开发学习应对大型复杂项目开发 81 | 开源实战三（上）：借Google Guava学习发现和开发通用功能模块 82 | 开源实战三（中）：剖析Google Guava中用到的几种设计模式 83 | 开源实战三（下）：借Google Guava学习三大编程范式中的函数式编程 84 | 开源实战四（上）：剖析Spring框架中蕴含的经典设计思想或原则 85 | 开源实战四（中）：剖析Spring框架中用来支持扩展的两种设计模式 86 | 开源实战四（下）：总结Spring框架用到的11种设计模式 87 | 开源实战五（上）：MyBatis如何权衡易用性、性能和灵活性？ 88 | 开源实战五（中）：如何利用职责链与代理模式实现MyBatis Plugin？ 89 | 开源实战五（下）：总结MyBatis框架中用到的10种设计模式 90 | 项目实战一：设计实现一个支持各种算法的限流框架（分析） 91 | 项目实战一：设计实现一个支持各种算法的限流框架（设计） 92 | 项目实战一：设计实现一个支持各种算法的限流框架（实现） 93 | 项目实战二：设计实现一个通用的接口幂等框架（分析） 94 | 项目实战二：设计实现一个通用的接口幂等框架（设计） 95 | 项目实战二：设计实现一个通用的接口幂等框架（实现） 96 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（分析） 97 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（设计） 98 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（实现） 99 | 总结回顾：在实际软件开发中常用的设计思想、原则和模式 100 | 如何将设计思想、原则、模式等理论知识应用到项目中？ 加餐一 | 用一篇文章带你了解专栏中用到的所有Java语法 加餐二 | 设计模式、重构、编程规范等相关书籍推荐 春节特别加餐 | 王争：如何学习《设计模式之美》专栏？ 加餐三 | 聊一聊Google是如何做Code Review的 加餐四 | 聊一聊Google那些让我快速成长的地方 加餐五 | 听一听小争哥对Google工程师文化的解读 加餐六 | 什么才是所谓的编程能力？如何考察一个人的编程能力？ 加餐七 | 基础学科的知识如何转化成实际的技术生产力？ 加餐八 | 程序员怎么才能让自己走得更高、更远？ 加餐九 | 作为面试官或候选人，如何面试或回答设计模式问题？ 加餐十 | 如何接手一坨烂业务代码？如何在烂业务代码中成长？ 结束语 | 聊一聊机遇、方向、能力、努力！ MVC和DDD 两者对比：业务开发常用的基于贫血模型的MVC架构违背OOP吗\nMVC MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。这种模式用于应用程序的分层开发。 https://www.runoob.com/design-pattern/mvc-pattern.html 基于贫血模型的传统的开发模式，是一种彻彻底底的面向过程的编程风格 DDD 领域驱动设计（Domain Driven Design，简称DDD） 基于充血模型的开发模式，面向对象编程风格 软件建模 软件建模介绍 将想法通过模型可视化地表达出来，方便记忆和进一步分析，方便团队/同事交流，口语交流容易失真。 软件建模体现了软件设计的思想，在需求和实现之间架起了一座桥梁，通过模型指导软件系统的具体实现。 模型并不是软件系统的一个完备表示，而是所研究系统的一种抽象。 如何进行软件建模 软件建模原则\n1、选择正确的模型，模型要与现实相联系 2、从不同的视角，使用不同的模型去表示一个系统 3、模型是抽象的，是选取系统某个最显著的特征并进行简化表示，因此需要通过不同的视角采用不同模型表示： **外部视角：**对系统上下文或环境进行建模 **交互视角：**对系统及其环境或者系统的构件之间的交互进行建模，建立用例模型 **结构化视角：**对系统的组织或者系统所处理的数据的结构进行建模，建立静态模型 **行为视角：**对系统的动态行为以及系统如何响应事件进行建模，建立动态模型 软件建模方法 在不同的领域和场景下有不同的软件建模方法，其各自的建模思想和采用的建模工具也不尽相同，如：\n结构化方法（Structured Method） 面向对象方法（Object Oriented Method） 基于构件方法（Component Based Method） 面向服务方法（Service Oriented Method） \u0026hellip; 面向对象软件建模方法 UML介绍 UML：Unified Modeling Language（统一建模语言），是面向对象的软件建模工具，使用UML进行建模的作用：\n可以更好的理解问题 可以及早的发现错误或者被遗漏的点 可以更加方便的进行组员之间的沟通 支持面向对象软件开发建模，可以更好的描述显示编程的情景。 对于复杂的系统来说，如果概要模型做的好，那么整个系统的模型也就很清晰明了。 UML一共有10种图，可分为四大类： 用例图 静态图：类图、对象图、包图 行为图：状态图、活动图、交互图，交互图分为序列图和协作图。 实现图：部署图、构件图 主要包括4种关系: 关联关系(association) 依赖关系(dependency) 泛化关系(generalization) 实现关系(realization) 4种视角 References UML实战教程 UML教程 UML2.5笔记 ＵＭＬ基础与建模实践教程 Tools 在线免费：draw.io UML常用图介绍 假设用UML建模以下场景：\n“机票订购系统是一个允许用户在线查询航班、购票、管理行程及退票的平台。系统区分了访客（未登录用户）与注册用户的功能权限：访客仅能浏览航班信息，而注册用户在登录后，还能进行购票、查看已购票以及退订操作。此外，系统内置了与外部信用评分系统的接口，该接口用于监控用户退票行为，若用户一个月内退票超过两次，其在信用评分系统中的等级会下调，信用等级过低时，系统将限制其继续购票。”\n用例图（Use Case Diagram）\n用例图是用来描述客户的需求，从用户的角度描述系统的功能，并指出系统的执行者，强调谁在使用系统，系统执行者完成了哪些功能。用例图包括角色、用例和关系。 类图（Class Diagram）\n用来展示系统中的类、类之间的关系（如继承、关联、聚合等）。适用于系统设计阶段，帮助开发人员理解系统的数据结构和类之间的关系。 顺序图（时序图，sequence diagram）\n描述对象之间如何通过消息交互以完成特定任务。适用于详细设计阶段，用于展示操作的时间顺序。 状态图（State Diagram）\n描述对象或系统在不同状态之间的转移和条件。适用于描述对象生命周期，特别是在系统的状态变化较为复杂时。 活动图（Activity Diagram）\n描述工作流、业务流程或操作的顺序。适用于系统行为建模、业务流程建模等。 构件图（组件图, Component Diagram）\n用来展示系统的物理组件及它们之间的依赖关系。适用于高层设计阶段，帮助理解系统的模块化结构。 部署图（Deployment Diagram）\n描述系统的硬件架构及其部署情况，显示硬件节点、节点之间的通信和软件组件部署到硬件节点的情况。适用于系统部署和运维阶段。 ","date":"2025-02-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/design_pattern/","title":"【软件设计】 设计模式介绍"},{"content":"ARM SIMD ARM平台基于ARM v7-A架构的ARM Cortex-A系列处理器(Cortex-A5, Cortex-A7,Cortex-A8, Cortex-A9, Cortex-A15)上的NEON加速：\n针对C/C++语言：循环展开等编译优化，-O2启用 针对NEON intrinsics：NEOM SIMD C/C++语言接口，针对架构启用V向量扩展，选择浮点处理器和ABI（application Binary Interface）接口类型 针对汇编语言：内联汇编，直接操作neon指令和寄存器 路线：了解相应编译优化=》使用intrinsic接口，学习对应汇编代码=》内联汇编，在编译器汇编代码基础上（否则可能反优化）学习并优化 references NEON Programmer\u0026rsquo;s Guide Cortex-A Series Programmer\u0026rsquo;s Guide 算子源码 AI算子：腾讯ncnn 数据处理算子：numpy simd 图像处理算子：Nvidia carotene，OpenCV third party 理论学习 指令流水线 经典的五级流水线模型 1、取指（IF）\n以程序计数器（PC）中的内容作为地址，从存储器中取出指令并放入指令寄存器（IR）； PC值加4（假设每条指令占4字节），指向顺序的下一条指令。 2、指令译码/读寄存器周期（ID）\n对指令进行译码，并用IR中的寄存器地址去访问通用寄存器组，读出所需的操作数； 对IR中的立即数进行扩展 3、执行/有效地址计算周期（EX）\nALU对上一个周期中准备好的操作数进行运算或处理。在这个阶段，不同类型的指令进行的操作不同。\n（1）load和store指令：ALB把指令中所指定的寄存器的内容与偏移量相加，形成访存有效地址； （2）寄存器-寄存器 ALU 指令：ALU按照操作码指定的操作对从通用寄存器组中读出的数据进行运算； （3）寄存器-立即数 ALU 指令：ALU按照操作码指定的操作对从通用寄存器组中读出的操作数和指令中给出的立即数进行运算； （4）分支指令：ALU把指令中给出的偏移量与PC值相加，形成转移目标的地址。同时，对在前一个周期读出的操作数进行判断，确定分支是否成功。 4、存储器访问/分支完成周期（MEM）\n（1）load和store指令：load指令根据上一个周期计算出的有效地址从存储器中读出的相应的数据；store把指定的数据写入这个有效地址对应的存储单元。 （2）分支指令：如果分支“成功”，就把前一个周期中计算好的转移目标地址送入PC。分支指令执行完成；否则，就不进行任何操作。 5、写回周期（WB）\n把结果写入通用寄存器组。对于ALU运算来说，这个结果来自ALU，而对于load指令来说，这个结果来自存储器。 SIMD加速原理 《计算机体系结构：量化研究方法》。Neon是ARM平台的SIMD（Single Instruction Multiple Data，单指令多数据流）指令集实现，书中4.1~4.3讨论了SIMD，推荐阅读。 之所以能加速的原因总结：\n（1）通过加长的寄存器减少数据的读取/写入次数，从而减少将数据读入寄存器的时间开销。例如Neon可以一次性将16个int8（16*8=128bit）数据读入专用寄存器，这一次读取时间开销，明显少于16个int8数据一个一个地读入的时间之和。写入同理。（注意不要和cache的减少访存时间的原理混淆。从cache读取余下的第2~第16个int8数据到寄存器仍然是要花费时钟周期的）。 （2）执行SISD（single instruction, Single data，单指令流单数据流，这里可理解为标量计算）指令时，需要完成（时间开销大的）冒险（hazard）检查。既然使用SIMD指令计算，就暗示这些数据之间无依赖性，也就从指令集层面回避了不必要的时间开销。 了解硬件决定的速度极限：Software Optimization Guide 我们可能还要关心，我们所编写的Neon Intrinsics，可以将手头上硬件的性能发挥到多少水平？是否还有提升空间？这些是好问题。\n在讨论一个问题前，先插入一个使笔者拍案叫绝的相关案例：在另一本计算经典《深入理解计算机系统》 （一般简称 CS:APP）的第5章 优化程序性能 中，该书作者考虑若干计算机硬件特性，将矩阵乘法连续优化了6个版本，直至优化到了该x86 CPU的吞吐量上限（注：对于某种指令，延迟latency 主要关注单条该指令的最小执行时间，吞吐量throughout主要关注单位时间内系统（一个CPU核）最多执行多少条该指令。因为AI计算的数据量比较大，我们更关注吞吐量） 回到问题，我们需要知道我们的吞吐量上界是多少。ARM官方为每个CPU架构（手机CPU一般大核是A7X架构，小核是A5X架构）提供对应的Software Optimization Guide，里面有进行各种运算的latency和throughout。以A76架构（采用该架构作为大核架构的CPU例如骁龙855，麒麟980）为例子，从ARM官网下载对应的pdf（https://developer.arm.com/documentation/swog307215/a/?lang=en） 翻到ASIMD（Advance SIMD）那里，就能查阅各条Neon指令相应的latency和throughout。不同架构的吞吐量上界会有所不同，其他架构请自行在ARM官网文档中心下载。 理论数据有了，至于如何通过实验测试峰值，可参考BBuf的文章 如何判断算法是否有可优化空间？ （https://zhuanlan.zhihu.com/p/268925243）\n反汇编分析生成代码质量 可通过反汇编的方式查看Intrinsics 生成的汇编是否满足预期，如果不满足预期则进行手写汇编优化。具体操作可参考梁德澎的文章 移动端arm cpu优化学习笔记第4弹\u0026ndash;内联汇编入门（https://zhuanlan.zhihu.com/p/143328317）\nmaterials （1）研讨会视频 \u0026ldquo;Performance Analysis for Optimizing Embedded Deep Learning Inference Software,\u0026rdquo; a Presentation from Arm - Edge AI and Vision Alliance，建立优化分析思维 （2）研讨会视频 LCU14-504: Taming ARMv8 NEON: from theory to benchmark results （3）研讨会视频 HKG15-408: ARM v8-A NEON optimization （4）Ne10（ARM官方的计算库）：https://github.com/projectNe10/Ne10 （5）Arm Optimized Routines（ARM官方的计算、网络、字符串库）：https://github.com/ARM-software/optimized-routines （6）Neon优化Chromium的案例：https://developer.arm.com/documentation/101964/developer.arm.com NEON 介绍 ARM NEON 是 ARM 架构的一种 SIMD（Single Instruction, Multiple Data）扩展，旨在加速多媒体、数字信号处理（DSP）、图像处理、音视频编解码、加密算法等高并发计算任务。NEON 是 ARMv7 （ARMv7-A只支持单精度，32x64-bit寄存器；Armv8-A AArch64支持双精度，32x128-bit寄存器，针对浮点操作的Vector Floating Point，VFP）及之后版本的处理器的标准扩展，广泛用于智能手机、嵌入式设备、平板电脑以及其他移动设备中，尤其是处理需要并行化的计算密集型应用时，它能显著提高性能。\n重要概念 lane：如一个float32x4_t类型的变量float32x4_t v = {1.0f, 2.0f, 3.0f, 4.0f}，它占用 128 位，存储 4 个 32 位的浮点数，在这个向量寄存器 v 中，每个值依次存储在不同的lane序号为0、1、2、3中。 NEON 寄存器 定义：NEON 使用专门的寄存器来存储向量数据，这些寄存器通常用于处理多个数据元素，ARMv7-A只支持单精度，32x64-bit寄存器；Armv8-A AArch64支持双精度，32x128-bit寄存器。 作用：NEON 寄存器组包含了 128 （Q字母）或 64（D字母） 位宽的寄存器，可以存储多个 8 位、16 位、32 位、64 位整数或浮点数据。 例子： Q0-Q15：128 位宽的 NEON 寄存器，用于存储 8 位、16 位、32 位、64 位的数据（整数或浮点数）。 D0-D15：64 位宽的 NEON 寄存器，也用于存储 64 位数据。 向量和标量操作 定义：NEON 支持对向量（多个元素）和标量（单个元素）进行操作。 作用：标量操作是普通的逐元素操作，而向量操作则允许一次性处理多个数据元素。 例子： vadd.f32：向量浮点加法操作。 vadd.i32：向量整数加法操作。 NEON 数据类型 定义：NEON 支持多种数据类型，包括整数、浮点数、双精度浮点数和混合类型数据。 作用：不同的数据类型适应不同的应用需求，如 8 位整数、32 位浮点数等。 例子： i8, i16, i32, i64：不同宽度的整数类型。 f32, f64：浮点数类型，支持单精度和双精度浮点数。 NEON 指令集 定义：NEON 提供了一组专门的指令来处理数据并执行并行计算。NEON 指令包括加法、乘法、减法、移位、汇聚（归约）、比较、选择、数据类型转换等。 作用：这些指令能够加速处理向量数据，尤其是应用于图像处理、音频处理、视频编解码、加密算法等领域。 例子： vadd：向量加法指令。 vmul：向量乘法指令。 vsub：向量减法指令。 vmax：向量最大值选择指令。 扩展数据类型 定义：NEON 提供了扩展数据类型的支持，如高/低16位扩展、饱和算术、向量数据类型转换等。 作用：这种扩展数据类型用于在计算过程中执行高效的数据操作和转换，避免数据溢出或精度丢失。 例子： vshl：向左移位操作。 vqadd：饱和加法指令，防止数据溢出。 数据载入和存储指令 定义：NEON 提供了一些专门的加载（load）和存储（store）指令，用于从内存中加载数据到寄存器，或将寄存器中的数据存储回内存。 作用：这些指令能够优化内存访问，支持从多个内存地址加载和存储数据。 例子： vld1：加载向量数据指令。 vst1：存储向量数据指令。 数据汇聚和归约操作 定义：NEON 提供了对向量数据的汇聚（归约）操作，例如求和、最大值、最小值等。 作用：这些操作通常用于计算总和、平均值、最大值等统计量，广泛应用于信号处理和数据分析中。 例子： vaddv：对向量元素进行加法归约，返回所有元素的和。 vmaxv：对向量元素进行最大值归约，返回最大值。 条件执行 定义：NEON 支持条件执行，通过设置条件码（flags），可以对某些指令的执行进行条件限制。 作用：可以根据特定的条件执行指令，避免不必要的计算，提高性能。 例子： vsel：根据掩码（mask）选择性地执行指令。 SIMD 聚合指令（广播操作） 定义：NEON 支持广播操作，允许单一标量值扩展到整个向量中。广播操作使得标量与向量的数据处理更加简便。 作用：通过广播操作，标量可以与向量中的每个元素进行计算，提高了指令的灵活性。 例子： vdup：将一个标量值复制到整个向量中。 NEON 浮点数运算 定义：NEON 支持单精度浮点数和双精度浮点数的运算，符合 IEEE 754 标准。 作用：这些浮点数运算指令可用于科学计算、图像处理等应用。 例子： vadd.f32：单精度浮点数向量加法。 vmul.f32：单精度浮点数向量乘法。 数据类型转换 定义：NEON 支持多种类型之间的转换操作，如浮点与整数类型之间的转换。 作用：这种转换对于不同数据类型之间的运算非常重要，可以确保类型匹配并避免数据丢失。 例子： vcvt.f32.s32：将 32 位整数转换为 32 位单精度浮点数。 vcvt.s32.f32：将 32 位单精度浮点数转换为 32 位整数。 向量掩码 定义：NEON 支持通过掩码控制哪些向量元素应该被操作。掩码机制允许在处理多个数据时根据特定条件选择性地操作某些元素。 作用：掩码可以控制并行操作的粒度，提高计算的灵活性。 例子： vmla：向量乘加指令，根据掩码控制哪些元素参与计算。 NEON Intrinsic 兼容armv7和v8（部分指令可能不兼容），所以不同架构之间迁移方便，不需要改代码\nReferences NEON-Intrinsics Neon Programmer Guide for Armv8-A Coding for Neon intrinsics检索，用来查看接口和支持架构 ARM Neon Intrinsics 学习指北：从入门、进阶到学个通透 numpy simd 数据和计算指令类型的格式 1、向量数据类型格式：\u0026lt;type\u0026gt;\u0026lt;size\u0026gt;x\u0026lt;number of lanes\u0026gt;_t\n比如float32x4_t，=float,=32,=4 向量数据类型： 2、向量数组类型：\u0026lt;type\u0026gt;\u0026lt;size\u0026gt;x\u0026lt;number of lanes\u0026gt;x\u0026lt;length of array\u0026gt;_t\n比如 1 2 3 4 struct int16x4x2_t { int16x4_t val[2]; }; 向量指令格式：\u0026lt;opname\u0026gt;\u0026lt;flags\u0026gt;_\u0026lt;type\u0026gt;\n比如vmulq_f32，=vmul，=q,=f32 Note 普通计算逻辑考虑优化编译器优化、类型量化等 循环一般用do-while的形式 对于非整数倍元素个数的解决方法： leftovers 使用 NEON 的广播操作，避免显示复制数据 使用 NEON 的饱和操作，避免数据溢出 利用数据类型转换操作，并合理进行量化 利用shift、insert、mask等 计算机组成结构运行相关（通用） 并行\n充分利用计算机流水线：去除数据依赖 逻辑操作代替分支选择（分支预测） 数据预加载（预取/并行） 资源利用\n充分利用寄存器资源，分块处理数据，但避免寄存器溢出(Register Spilling）（测试时开启O2优化使编译器允许寄存器存储临时变量） 内存合理对齐分配，按对应寄存器长度读取 多线程处理，如OpenMP（并行/数据共享） 利用数据连续特性、利用cache NEON 汇编 可用__aarch64__宏区分是armv8，否则armv7，针对性编写代码\nReferences 移动端arm cpu优化学习笔记第4弹\u0026ndash;内联汇编入门 arm 内联汇编使用 arm内联汇编的一般格式，detail、docs\n1 2 3 4 5 6 7 8 __asm__ qualifiers ( // 汇编代码部分 : OutputOperands //在内联汇编代码中被修改的变量列表 : InputOperands //在内联汇编代码中用到的变量列表 : Clobbers //在内联汇编代码中用到的寄存器列表 ); Note 先写intrinsic代码反汇编，学习编译器优化后的汇编代码，再优化 重点关注指令流水线排布，避免CPU的Hazard ","date":"2025-02-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/arm-neon/","title":"【SIMD】 ARM SIMD指令集NEON等介绍"},{"content":"References The RISC-V Instruction Set Manual Volume II: Privileged Architecture RVV spec Xuantie+900+Series+RVV-0.7.1+Intrinsic+Manual 算子源码 ARM-software/CMSIS, CMSIS-DSP Nuclei-software/NMSIS Note illegal instruction：修改CSR的mstatus标志位 important concepts VLEN (Vector Length) 定义：向量寄存器的长度，表示每个寄存器可以存储的最大元素数量，通常是硬件设定的，例如 128 位、256 位或 512 位。 作用：决定向量寄存器的容量和能处理的数据量。 例子： 如果 VLEN 为 256 位且每个元素为 32 位整数，则每个寄存器最多存储 8 个元素（256 / 32 = 8）。 SLEN (Stride Length) 定义：元素在内存中的步长，即两个连续元素之间的内存偏移量。 作用：影响内存访问模式，特别是在访问非连续内存时，SLEN 决定了元素之间的间隔。 例子： 假设一个向量寄存器存储 4 个元素，每个元素大小为 32 位，而 SLEN 设置为 2，这意味着每个向量元素在内存中的位置间隔为 2 个 32 位单元。 ELEN (Element Length) 定义：每个向量元素的大小（单位：比特），决定了每个元素占用多少内存。 作用：影响向量中每个元素的数据类型大小，在指令中用e表示，如e32。 例子： 如果 ELEN 设置为 32 位，则每个向量元素为 32 位宽，可以是一个 32 位整数或 32 位浮点数。 如果 ELEN 为 64 位，则每个元素占 64 位，适用于较大数据类型（如 64 位整数或浮点数）。 LMUL (Vector Register Grouping Factor) 定义：向量寄存器的分组因子，控制每个向量寄存器内元素的数量，决定寄存器的并行度。 作用：LMUL 会影响每个向量寄存器中包含的元素数量，从而影响并行性，在指令中用m表示，如m1。 例子： LMUL = 1：每个寄存器存储最大数量的元素（假设 VLEN = 256 位，ELEN = 32 位，则每个寄存器存储 8 个元素）。 LMUL = 2：每个寄存器只存储 4 个元素，寄存器总数增加，适合提高并行度。 LMUL = 4：每个寄存器只存储 2 个元素。 VL (Vector Length Register) 定义：VL 是一个寄存器，用来控制当前向量指令的长度，即当前指令能处理的元素数量。 作用：在 RVV 指令中，VL 决定了向量运算的迭代次数，向量操作将执行 VL 次。 例子： 如果 VL = 4，那么该指令将对前 4 个向量元素执行操作，用setvl(max)指令可以得到指令类型的最大元素数量，其中每个指令指定vl可处理不同数量的元素。 VTYPE (Vector Type Register) 定义：VTYPE 控制向量操作的类型，如元素长度 (ELEN) 和 LMUL 的配置。 作用：配置向量操作的具体参数，帮助硬件理解如何处理向量指令。 例子： VTYPE 设置为 ELEN = 32 位，LMUL = 1，表示每个向量寄存器存储 32 位元素，且每个寄存器的并行度为 1。 Vector Mask (vmsk) 定义：向量掩码用于控制哪些向量元素应该被操作，哪些应该被忽略。 作用：掩码机制使得程序能够选择性地执行向量操作。 例子： 若 vmsk = 11110000（二进制），则只有前 4 个向量元素会被操作，后 4 个元素将被忽略。 Vector Registers (v0 - vn) 定义：向量寄存器用于存储向量数据，RISC-V 定义了 v0 到 v31 的向量寄存器。 作用：这些寄存器用于存储和处理向量数据，数量和大小可由硬件决定。 例子： v0 和 v1 可以分别存储 256 位的向量数据，适用于不同长度的数据类型。 Vector Load/Store Instructions 定义：向量加载和存储指令，用于将数据从内存加载到向量寄存器，或将向量寄存器中的数据存储回内存。 作用：支持各种内存访问模式，如连续或非连续访问。 例子： vlb：加载字节数据到向量寄存器。 vsb：将字节数据存储回内存。 Vector Arithmetic Instructions 定义：向量算术指令用于执行向量加法、减法、乘法、除法等算术运算。 作用：向量算术指令在多核处理器中并行执行运算。 例子： vadd：向量加法，执行两个向量的逐元素加法。 vmul：向量乘法，执行两个向量的逐元素乘法。 Vector Compare Instructions 定义：向量比较指令用于比较向量中的元素，返回布尔掩码结果。 作用：常用于条件判断和控制流。 例子： vseq：判断两个向量的元素是否相等，结果返回掩码。 vsgt：判断向量元素是否大于另一个向量，返回布尔掩码。 Vector Reduction Instructions 定义：向量归约指令用于将向量中的多个元素归约为一个单一结果，如求和、求最大值等。 作用：常用于矩阵运算、图像处理等应用。 例子： vredsum：求和，将向量中所有元素相加。 vredmax：求最大值，返回向量中的最大元素。 Vector Scatter/Gather Instructions 定义：用于从非连续的内存地址中加载数据或将数据存储到非连续的内存地址。 作用：提高对非连续内存的访问效率。 例子： vscatter：将向量元素存储到不连续的内存位置。 vgather：从不连续的内存位置加载数据到向量寄存器。 Vector-Scalar Operations 定义：向量与标量之间的操作，允许标量与每个向量元素进行逐一运算。 作用：通过标量与向量元素的结合，处理常数数据。 例子： vaddvi：将一个标量与向量中的每个元素相加。 vmulvi：将一个标量与向量中的每个元素相乘。 Vector Predication 定义：根据掩码或布尔条件选择性执行向量操作。 作用：通过掩码决定哪些元素进行计算，哪些跳过。 例子： vmand：与掩码进行与运算，满足条件的元素进行计算。 Vector Tail \u0026amp; Masking 定义：当 VL 不能完全填充向量寄存器时，通过尾部掩码控制哪些元素需要操作。 作用：避免浪费计算资源，确保运算的有效性。 例子： 如果 VL = 5，而寄存器有 8 个元素，掩码将控制只操作前 5 个元素。 Vector Unit (VU) 定义：向量单元是硬件中的计算单元，负责执行向量指令。 作用：处理向量计算，提高处理器的并行度。 例子： 在支持 RVV 的处理器中，向量单元可以同时处理多个向量运算。 Note 常见使用方式 以float32类型dot计算为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 void riscv_dot_prod_f32( const float32_t * pSrcA, const float32_t * pSrcB, uint32_t blockSize, float32_t * result) { float32_t sum = 0.0f; size_t blkCnt = blockSize; size_t l; vfloat32m8_t v_A, v_B; vfloat32m8_t vsum; l = __riscv_vsetvlmax_e32m8(); vsum = __riscv_vfmv_v_f_f32m8(0.0f, l); for (; (l = __riscv_vsetvl_e32m8(blkCnt)) \u0026gt; 0; blkCnt -= l) { v_A = __riscv_vle32_v_f32m8(pSrcA, l); pSrcA += l; v_B = __riscv_vle32_v_f32m8(pSrcB, l); pSrcB += l; vsum = __riscv_vfmacc_vv_f32m8(vsum, v_A, v_B, l); } l = __riscv_vsetvl_e32m8(1); vfloat32m1_t temp00 = __riscv_vfmv_v_f_f32m1(0.0f, l); l = __riscv_vsetvlmax_e32m8(); temp00 = __riscv_vfredusum_vs_f32m8_f32m1(vsum, temp00, l); sum = __riscv_vfmv_f_s_f32m1_f32(temp00); *result = sum; } ","date":"2025-02-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/rvv/","title":"【SIMD】 Risc-v SIMD指令集RVV介绍"},{"content":"环境准备 1.1 Git下载 前往【Git官网】，下载安装程序 一直点下一步，默认安装即可\nHugo下载 前往【Hugo Github Tags】，选择对应版本下载，下载后解压即可 Windows下载版本：hugo_extended_xxxxx_windows_amd64.zip\n搭建博客 创建博客 （1）在hugo.exe所在文件夹的地址栏敲打cmd，然后Enter唤起命令行\n（2）敲打命令hugo new site xxxx创建hugo文件\n（3）敲打命名cd xxxx切换目录，并把hugo.exe复制到刚生成的文件夹中\n（4）敲打命令hugo server -D启动服务，访问http://localhost:1313，Ctrl+C停止服务 （hugo默认是没有主题的，需要进行主题配置）\n配置主题 （1）前往【Hugo Themes】，查找自己喜欢的主题，进行下载\n（2）这边以【Stack主题】为例，将下载好的主题解压，放到/themes文件夹中\n（3）将exampleSite样例数据中的 Content 和 hugo.yaml 复制到主文件夹中，并删掉hugo.toml和content/post/rich-content\n（4）修改 hugo.yaml 中的 theme，将他修改为跟主题文件夹同名\n（5）再次启动hugo服务，查看主题，具体主题配置修改 hugo.yaml，这里不细说，感兴趣可自行查找相关文章\n启用 Giscus 评论 Giscus 是利用 GitHub Discussions 实现的评论系统，开源、无跟踪、无广告、永久免费。\nHugo 对 Giscus 有很好的支持，在 hugo-theme-jane 主题中配置启用Giscus 很简单。\n要启用 Giscus 请先确保：\n仓库是公开的，否则访客将无法查看 discussions。 giscus app 已安装，否则访客将无法评论和回应。 Discussions 功能已在你的仓库中启用。 前面搭建的博客仓库就是公开的，满足了第一点，接下来要做的就是安装 Giscus app 和启用 Discussions。\nReferences https://www.codeaer.com/post/enable-giscus-comments-in-hugo/ 配置 Giscus 根据版本有所不同，0.143.1版本可使用以下模板\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # repoId、categoryId参考网址修改：https://giscus.app/zh-CN giscus: repo: \u0026#34;xxx/xxx.github.io\u0026#34; repoId: \u0026#34;xxx\u0026#34; category: \u0026#34;General\u0026#34; categoryId: \u0026#34;xxx\u0026#34; mapping: \u0026#34;pathname\u0026#34; # comment value is the default value strict: 0 reactionsEnabled: 1 # emitMetadata: 0 inputPosition: \u0026#34;top\u0026#34; theme: \u0026#34;dark\u0026#34; lang: \u0026#34;zh-CN\u0026#34; lazyLoading: true crossorigin: \u0026#34;anonymous\u0026#34; Github部署 常规部署 （1）前往【Github官网】，创建仓库 {github用户名}.github.io\n（2）前往Setting -\u0026gt; Pages -\u0026gt; Branch选择main分支，然后保存，会自动开启 https://{github用户名}.github.io 的地址，这地址也是以后访问博客的地址\n（3）回到hugo文件中，执行命令hugo -D，会生成 public 静态资源文件夹\n（4）在 public 执行以下命令上传到github仓库上，第一次上传可能需要输入账号密码\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main （5）上传成功后访问 https://{github用户名}.github.io，成功搭建属于自己的Hugo博客\nGithub Action自动部署 （1）Github创建一个新的仓库，用于存放Hugo的主文件\n（2）前往Setttings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens，创建一个token(classic)\n（3）token选择永不过期，并勾选 repo 和 workflow 选项\n（4）为保证安全，将生成的token，保存的仓库的变量中，前往Settings -\u0026gt; Secrets and variables -\u0026gt; Actions中设置\n（5）在hugo主文件创建一个.github/workflows/xxxx.yaml文件，将以下内容复制进去，想具体了解更多，可查看【Github Action文档】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: deploy # 代码提交到main分支时触发github action on: push: branches: - main jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;latest\u0026#34; extended: true - name: Build Web run: hugo -D - name: Deploy Web uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.你的token变量名 }} EXTERNAL_REPOSITORY: 你的github名/你的仓库名 PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy （6）在hugo主文件创建.gitignore文件，来避免提交不必要的文件\n1 2 3 4 5 6 7 # 自动生成的文件 public resources .hugo_build.lock # hugo命令 hugo.exe （7）将hugo的主文件上传到仓库，上传成功后会触发Github Action，来自动部署你的静态页面\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main Reference https://letere-gzj.github.io/hugo-stack/p/hugo/custom-blog/ ","date":"2025-02-05T00:00:00Z","permalink":"https://loveleaves.github.io/p/hugo-blog/","title":"Hugo + Github 免费部署自己的博客"},{"content":"References 现代 C++ 大典 cs106b C++知识总结 C++ 语言参考 优秀开源 Abseil Abseil 是一个由 Google 开源的 C++/python 库，提供了一组常用的工具和基础设施，用于补充 C++ 标准库中缺失的功能或提高效率。 abseil-cpp Dlib Dlib 是一个流行的 C++ 库，主要用于机器学习、计算机视觉和图像处理。它提供了丰富的机器学习功能，支持多种算法和优化方法。 dlib XGBoost XGBoost 是一个高效的机器学习库，特别适用于梯度提升决策树（GBDT）算法，广泛用于回归、分类和排序任务。 xgboost Google\u0026rsquo;s glog (Google Logging Library) 功能：glog 是一个 C++ 日志库，提供了强大的日志记录功能，包括日志级别（DEBUG、INFO、WARNING、ERROR 和 FATAL）、日志输出到文件、以及日志格式化。 特点：简单易用，支持日志级别设置、日志输出的细粒度控制，还可以在生产环境中非常高效地记录日志。 链接：glog GitHub spdlog 功能：spdlog 是一个非常快速的 C++ 日志库，旨在提供低延迟、高性能的日志记录功能。 特点：spdlog 提供线程安全的日志记录支持，能够输出到控制台或文件，支持日志级别、日志格式等功能。 链接：spdlog GitHub folly (Facebook Open-source Library) 功能：folly 是 Facebook 开发的一个 C++ 库，包含了许多高性能的组件和工具，适用于大规模系统的开发。它包括内存管理、并发、容器、算法、IO等多个方面的扩展。 特点：folly 提供了大量与系统底层交互的工具，具有很高的性能，适用于对性能要求极高的应用。 链接：folly GitHub Boost 功能：Boost 是一个广泛使用的 C++ 库集合，提供了许多扩展标准库的功能，包括智能指针、正则表达式、线程、文件系统、算法等。 特点：Boost 提供了丰富的功能，经过多年的开发和优化，成为了 C++ 生态中非常重要的工具库之一。很多 C++ 标准库中的特性都源自 Boost（如 std::shared_ptr 和 std::filesystem）。 链接：Boost官网 fmt 功能：fmt 是一个现代化的、快速的格式化库，提供了类似 Python 中的 f-string 或 C# 中的 string interpolation 的功能。 特点：它允许开发者使用更加简洁和类型安全的方式进行字符串格式化。fmt 库的速度非常快，而且 API 设计符合现代 C++ 风格。 链接：fmt GitHub gflags 功能：gflags 是一个 Google 提供的命令行参数解析库，广泛用于解析应用程序启动时的命令行选项。 特点：gflags 提供了易于使用的命令行选项定义和管理功能，支持复杂的命令行解析需求，例如布尔值选项、枚举类型选项等。 链接：gflags GitHub tbb (Threading Building Blocks) 功能：tbb 是 Intel 提供的一个 C++ 并行编程库，旨在帮助开发者利用多核处理器，简化并行编程。 特点：提供了线程池、并行算法和数据结构，能够方便地进行并行化计算，且通过自动负载平衡使多核资源得到高效利用。 链接：TBB GitHub cppcoro 功能：cppcoro 是一个支持 C++20 协程的 C++ 库，提供了多种并发控制结构，如 task 和 awaiter，用于协程的高效实现。 特点：使 C++ 开发者能够高效地编写异步代码，同时保持代码简洁和易于理解。适合需要异步操作的场景。 链接：cppcoro GitHub Eigen 功能：Eigen 是一个高效的 C++ 数学库，专门用于矩阵运算、线性代数和数值计算。 特点：Eigen 提供了一个高性能的模板库，支持多维数组、矩阵操作以及高级的线性代数功能，广泛用于科学计算、机器学习等领域。 链接：Eigen GitHub C++语言参考 类和结构（class and struct） 类成员 override：重写父类虚函数 final：表示一个虚函数不能被进一步重写，或者表示一个类不能被继承 delete：禁用某个函数，如默认构造 default：明确地请求编译器为类生成默认实现 explicit：防止隐式转换调用其他函数 纯虚函数：virtual void doStep() = 0; // 要求派生类必须实现，否则派生类也将变成抽象类，无法实例化。 常成员函数const：只能调用其他常成员函数，不能修改成员变量（除mutable） static静态成员函数：不用实例化，可被直接调用 inline：内联请求，将代码插入调用函数处，较少调用栈开销 noexcept：表示该函数不会抛出异常 mutable：修饰变量可在常成员函数中修改 constexpr：表示该函数在编译时计算结果 friend：友元函数/类，允许外部函数或类在需要时访问类的私有实现 operator ：用于定义或重载类的运算符 自定义迭代器类：通常需重载==、!=、++、*解引用，实现begin、end 对象生存期和资源管理 (RAII) 与托管语言不同，C++ 没有自动回收垃圾机制，易导致内存泄露 善于利用析构特性进行自动内存回收管理，如std::lock_guard、Std::make_unique、Std::make_share等 用于编译时封装的 Pimpl Pimpl（Pointer to Implementation）是一种设计模式，常用于C++编程中以隐藏类的实现细节。Pimpl模式通过将实现细节移到一个私有的实现类中，从而提高代码的可维护性、降低编译时间以及实现二进制兼容性。\n编译依赖项的最小化。 接口和实现的分离。 可移植性。 一般实现： 1 2 3 4 5 6 7 // 头文件定义private类指针，源文件进行实现类impl // my_class.h class my_class { // ... all public and protected stuff goes here ... private: class impl; unique_ptr\u0026lt;impl\u0026gt; pimpl; // opaque type here }; 匿名函数 lambda表达式 引用 reference 指针 异常 模板 template 变长参数模板： 1 2 3 4 5 template \u0026lt;typename... Modules\u0026gt; explicit Sequential(Modules \u0026amp;\u0026amp;...modules) { modules_.reserve(sizeof...(Modules)); pushBack(std::forward\u0026lt;Modules\u0026gt;(modules)...); } // 递归展开，调用基础pushBack方法 完美转发：std::forward，保留原来值类型（左值/右值） std::optional：处理可能为null等值情况 std::enable_shared_from_this：在对象的成员函数中获取指向自身的智能指针，增加对象的引用计数，确保对象在异步操作或回调过程中不会被销毁 STL（Standard Template Library，标准模板库） 容器（Containers） vector.reserve 和 resize Vecotr.emplace_back和push_back std::reference_wrapper存储引用 std::initializer_list 轻量级初始化列表，不可修改; 算法（Algorithms） 迭代器（Iterators） 函数对象（Function Objects） ","date":"2025-01-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/c_plus_plus/","title":"【编程语言】 C++高级特性及实战"},{"content":"References HPC/ML/OS/SW性能工具总结 热点分析 热点分析通常通过使用 性能分析工具 来实现，工具会提供每个函数、方法、代码块的执行时间、调用次数、CPU 占用率等信息，帮助开发人员识别耗时最多的部分。\n常见的热点分析方法 调用图（Call Graph）：通过调用图分析函数之间的调用关系，找到调用最频繁的部分。 性能剖析（Profiling）：通过工具生成程序运行时的性能数据，分析哪些函数或代码块占用了最多的时间或资源。 热代码路径（Hot Code Path）分析：关注那些频繁执行的路径或分支，优化这些路径的性能。 内存热点分析：分析程序中哪些数据结构或对象频繁创建、销毁，导致内存管理不善或频繁的垃圾回收。 实际操作 函数级分析：分析程序中的每个函数，找出耗时最多的函数并进行优化。 多线程/并发分析：对于并发程序，热点分析还要考虑线程的执行时间、锁竞争和同步问题，识别线程间的性能瓶颈。 内存分析：分析内存的分配和释放，找出内存泄漏或频繁的内存分配导致的性能瓶颈。 性能分析工具 gprof：GNU profile工具 适用语言：C、C++、Pascal、Fortran 介绍：用于程序的性能优化以及程序瓶颈问题的查找和解决。通过分析应用程序运行时产生的“flat profile”，可以得到每个函数的调用次数，每个函数消耗的处理器时间，也可以得到函数的“调用关系图”，包括函数调用的层次关系，每个函数调用花费了多少时间。 缺点：对并行程序支持较差，不能提供细粒度的分析，主要适用于函数级别的性能分析。 使用步骤：\n1、用gcc、g++、xlC编译程序时，使用-pg参数，如：g++ -pg -o test test.cpp。编译器会自动在目标代码中插入用于性能测试的代码片断，这些代码在程序运行时采集并记录函数的调用关系和调用次数，并记录函数自身执行时间和被调用函数的执行时间。 2、执行编译后的可执行程序，如：./test。该步骤运行程序的时间会稍慢于正常编译的可执行程序的运行时间。程序运行结束后，会在程序所在路径下生成一个缺省文件名为gmon.out的文件，这个文件就是记录程序运行的性能、调用关系、调用次数等信息的数据文件。 3、使用gprof命令来分析记录程序运行信息的gmon.out文件，如：gprof test gmon.out。则可以在显示器上看到函数调用相关的统计、分析信息。 Perf 适用语言： C, C++ 平台： Linux 特点： Perf 是 Linux内置的性能分析工具，可用于分析 CPU 使用率、内存访问、系统调用等。它是一个命令行工具。适用于深度的 Linux 系统级性能分析。 缺点：需要一定的学习成本，报告可能较为复杂。 Perf是一个很大的工具，此处仅展示分析某个应用的的用法。 使用步骤（使用gprof的那个可执行文件）：\n1、perf record ./test，部分性能参数需要root权限 2、perf report References\nhttps://www.brendangregg.com/perf.html perf tutorial WSL2安装perf perf原理及火焰图 perf分析c热点函数 perf简单例子-程序调用栈火焰图\n1 2 3 4 5 6 7 8 9 10 11 perf record -F 99 -p 2347 -g -- sleep 30 # perf record表示采集系统事件, 没有使用 -e 指定采集事件, 则默认采集 cycles(即 CPU clock 周期), -F 99 表示每秒 99 次, -p 2347 是进程号, 即对哪个进程进行分析, -g 表示记录调用栈, sleep 30 则是持续 30 秒. # 统计每个调用栈出现的百分比, 然后从高到低排列 perf report -n –stdio # 解析perf收集的信息 perf script -i perf.data \u0026amp;\u0026gt; perf.unfold # 生成折叠后的调用栈 # 使用开源软件：https://github.com/brendangregg/FlameGraph.git ./stackcollapse-perf.pl perf.unfold \u0026amp;\u0026gt; perf.folded # 生成火焰图 ./flamegraph.pl perf.folded \u0026gt; perf.svg perf简单例子-分析热点函数、指令\n1 2 3 4 5 6 7 8 # 通过-g选项保留源代码信息 gcc -g test.c -o test # 通过perf record命令对test程序采样，-g表示采样调用栈 perf record -F 999 ./test # 查看热点分布 perf report # 查看热点函数testA中的热点指令及语句 perf annotate --stdio --symbol=testA Intel VTune Profiler 适用语言： 多语言支持 平台： Windows、Linux 特点： Intel VTune Profiler 是一个功能强大的性能分析工具，可用于分析 CPU 使用率、内存访问、多线程性能等。适用于 Intel 处理器。 可以看到 perf 看不到L3cache 等硬件特性 references\nhttps://www.cnblogs.com/bandaoyu/p/16751995.html https://zhuanlan.zhihu.com/p/12642264312 https://blog.csdn.net/yaojingqingcheng/article/details/120335335 TAU 适用语言： C、C++、python 官网：https://www.cs.uoregon.edu/research/tau/home.php 特点： 是一个面向MPI与OpenMP并行程序的profiler，在目前看到的OpenMPI的Profiler中算是比较健全的一个。相比于Intel的vtune面向OpenMPI的时候会有些限制，TAU可以根据不同的MPI发行版重新编译。 references\nTAU Profiler安装 python 使用性能测试工具TAU测试MPI程序记录 深入解析TAU工具 GPU 分析工具 全部工具：https://developer.nvidia.com/tools-overview\ncuda-gdb cuda-gdb -g -G编译选项 Nsight Compute nvprof，计算能力8.0以下使用 注意系统要求（如win11 ws2才支持）：system-requirements、unknown-error-on-device-0-when-running-ncu-on-wsl 使用方案：\n1、用户界面：https://docs.nvidia.com/nsight-compute/NsightCompute/index.html 2、CLI方式：https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html ComputeSanitizer https://docs.nvidia.com/compute-sanitizer/ComputeSanitizer/index.html#id1\n功能正确性检查工具，包含：memcheck、racecheck、initcheck、synccheck等 cuda12.0以下内存检查使用CUDA-MEMCHECK，以上使用ComputeSanitizer HPCtoolkit 适用语言： C、C++、CUDA 官网：HPCToolkit 特点：支持CUDA 内存分析工具 gdb：-g源码调试 tsan TSan（ThreadSanitizer）是一个用于检测多线程程序中的 数据竞争 和 线程安全问题 的工具。它是由 Google 开发的，用于帮助开发者发现并修复多线程程序中的并发问题，这些问题可能导致难以复现的错误和难以调试的行为。\n1. 什么是数据竞争？ 数据竞争是指多个线程并发地访问同一块内存区域，并且至少有一个线程在写入该内存区域，而其他线程可能在读或写该内存。数据竞争通常会导致不可预测的程序行为，比如程序崩溃、结果错误等。数据竞争的问题尤其难以发现，因为它们通常依赖于程序执行的特定时序和上下文。\n2. TSan 的功能 ThreadSanitizer 是一种 动态检测工具，它能够监测并发程序中的线程交互，并在检测到数据竞争时，给出详细的报告。它通过 **插桩（Instrumentation） **方式，插入检查代码，追踪每个线程对共享内存的访问，以此来检测潜在的数据竞争。\n具体功能包括：\n检测数据竞争：在多线程程序中，TSan 能够发现不同线程对同一内存位置的并发访问（读-写或写-写），并且报告潜在的数据竞争。 报告细节：当 TSan 检测到数据竞争时，会提供详细的错误报告，包含竞争发生的栈信息、线程信息、访问的内存位置等，帮助开发者定位问题。 跨平台支持：TSan 支持 Linux、macOS、Android 和其他平台，通常与 Clang 和 GCC 编译器兼容。 3. 如何使用 TSan TSan 是通过编译器插件实现的，因此需要在编译程序时启用它。以下是启用 TSan 的基本步骤：\n1 2 3 4 5 6 7 8 9 10 # 1、编译时启用 TSan，使编译器将 TSan 插桩到代码中，在程序运行时启用线程安全检查。 g++ -fsanitize=thread -g test.cpp -o test # 2、运行时，程序将被 TSsan 监控，检测线程间的竞争。 ./test # 如果程序中有数据竞争，TSan 会输出类似以下的报告： ThreadSanitizer: data race in function \u0026#39;foo\u0026#39; at address 0x601000000020 #0 0x7f89b5cb5e6f in foo #1 0x7f89b5cb5e79 in bar #2 0x7f89b5cb5f89 in main TSan 会提供详细的栈跟踪，指出哪些线程、哪些内存地址、在哪些函数中发生了数据竞争。 4. TSan 的工作原理 TSan 通过对程序进行 插桩，在程序中每次内存访问（读/写）时插入检查代码，追踪每个线程对内存的访问。它会记录每个线程对共享内存的访问并进行比较，以判断是否存在数据竞争。\n主要机制：\n内存访问追踪：TSan 会追踪每个线程对内存地址的访问情况，记录访问的时间戳和线程标识。 同步原语检测：TSan 会检查线程之间的同步操作（如 mutex、lock、atomic）是否正确使用，确保线程安全。 数据竞争检测：如果两个线程访问同一内存位置，并且至少一个是写操作，TSan 会标记为潜在的数据竞争。 5. TSan 检测的线程安全问题 除了检测数据竞争，TSan 还可以帮助识别以下并发编程中的常见问题：\n死锁：如果两个线程因相互等待而导致死锁，TSan 也可以通过检测锁的顺序和依赖关系来帮助识别死锁。 非原子操作：在多线程环境中，如果某些操作不是原子的，可能会导致竞态条件。TSan 可以通过对同步操作的检查，帮助发现这些问题。 不当的内存同步：如果线程没有适当的同步机制（如 mutex 或 atomic）来协调对共享数据的访问，可能会出现竞态条件，TSan 会标记这些不安全的内存访问。 6. TSan 的优点和限制\n优点：能够捕获到很难复现的多线程问题，提供详细的报告，包括访问的内存位置、线程栈、数据竞争的上下文，帮助开发者快速定位并修复问题。 限制：会有一定的性能开销（开发阶段使用），可能不会检测所有类型的并发问题，特别是某些边缘情况或者深度依赖于硬件的并发问题。 AddressSanitizer (ASan) ASan（AddressSanitizer）是一个用于检测 内存错误 的强大工具，特别是针对 缓冲区溢出、堆栈溢出、使用后释放（use-after-free）等常见内存问题。ASan 是由 Google 开发的，作为一个 编译时检测工具，它可以在程序运行时检测出许多类型的内存错误，并提供详细的错误报告。ASan 可以用于 C 和 C++ 等语言，广泛应用于开发和测试阶段，帮助开发者发现和修复难以调试的内存错误。\nASan 的功能 ASan 的核心功能是通过 内存访问跟踪 来检测程序中的各种内存错误。它能有效检测以下几类常见的内存问题： 缓冲区溢出（Buffer Overflow）：当程序写入超出分配内存的区域时，会导致数据损坏或程序崩溃。 堆栈溢出（Stack Overflow）：当程序的栈内存超出预定范围时，可能会覆盖局部变量或函数返回地址。 使用后释放（Use-After-Free）：指在内存被释放后，程序仍然访问该内存。 内存泄漏（Memory Leak）：指程序分配了内存但没有释放，导致内存消耗不断增加。 双重释放（Double Free）：指在释放内存后再次释放该内存，可能导致程序崩溃。 未初始化内存读取（Use of Uninitialized Memory）：程序读取未初始化的内存内容，可能导致不可预测的行为。 ASan 的工作原理 ASan 通过 编译器插桩（Instrumenting Compiler）和 运行时库（Runtime Library）的配合工作来检测内存错误。 编译时插桩：在程序的源代码编译过程中，ASan 会插入额外的检查代码，这些代码会在程序运行时检查每个内存访问，确保它们在合法的内存范围内。 内存分配替换：ASan 会替换程序的 内存分配函数（如 malloc、free、new、delete）来监控内存的分配和释放操作。 内存红区（Redzones）：ASan 在每个内存块的前后插入一些特殊的 \u0026ldquo;红区\u0026rdquo;（Redzones），这些区域用于检测 越界访问。如果程序试图访问红区，ASan 会报告错误。 运行时检测：当程序访问非法内存时，ASan 会触发 运行时错误检测，并输出详细的错误信息（如错误的内存地址、堆栈信息等）。 如何使用 ASan 要启用 AddressSanitizer，您需要在编译时添加 -fsanitize=address 选项，并启用调试信息 -g（以便于调试）。 1 g++ -fsanitize=address -g -o test test.cpp ASan 错误报告 当 ASan 检测到内存错误时，它会生成详细的错误报告。该报告通常包含以下信息： 错误类型：如 use-after-free、buffer overflow、stack overflow 等。 错误位置：报告发生错误的内存地址，指出程序在哪里进行非法内存访问。 调用栈：ASan 会提供程序的调用栈信息，帮助开发者快速定位问题。 内存布局：显示内存分配情况，包括程序访问的内存区域和红区位置。 ASan 检测的内存问题 ASan 可以检测的内存问题包括： 堆栈溢出（Stack Overflow）：当局部变量超出栈边界时，ASan 会报告堆栈溢出。 缓冲区溢出（Buffer Overflow）：当访问超出数组或缓冲区的范围时，ASan 会检测到缓冲区溢出。 使用后释放（Use-After-Free）：在内存被释放后，如果程序继续使用该内存，ASan 会报告此错误。 内存泄漏（Memory Leak）：ASan 可以检测到程序中未释放的内存（通过启用 -fsanitize=address 和使用 ASAN_OPTIONS=detect_leaks=1）。 双重释放（Double Free）：当程序尝试两次释放同一块内存时，ASan 会报告此问题。 未初始化内存访问（Use of Uninitialized Memory）：当程序访问未初始化的内存时，ASan 会报告此错误。 ASan 的优点和缺点 优点：高效的内存错误检测、易于使用、详细的错误报告、广泛支持。 缺点：性能开销、仅支持动态检测、依赖编译器。 valgrind 平台：Linux / macOS / Windows（通过 Cygwin） 用途：Valgrind 是一款开源的动态分析工具，广泛用于 内存分析，如查找内存泄漏、内存越界等问题。 功能： Memcheck：用于检测内存泄漏、越界访问和未初始化的内存读取。 Cachegrind：用于缓存行为分析，评估 CPU 缓存的命中率。 Callgrind：支持函数级别的性能分析，提供详细的 CPU 性能数据。 Helgrind：用于检测并发程序中的数据竞争。 适用场景：适用于内存优化、程序调试和多线程程序的性能分析。 使用方式：通过命令行运行程序时加上 valgrind，比如 valgrind \u0026ndash;leak-check=full ./my_program。 优点：强大的内存分析功能，能够检测很多潜在的错误。 缺点：运行时开销较大，程序执行速度可能会减慢。 eBPF (Extended Berkeley Packet Filter) 类型：内核性能分析工具 功能：eBPF 可以用于监控系统的 CPU 使用情况、内存分配、I/O 性能、网络流量 等。 使用场景：eBPF 适用于 Linux 系统的全栈性能分析，特别是在容器化环境中（如 Kubernetes、Docker）。 优点：能够高效且低开销地进行性能分析，实时提供系统各个层次的性能数据。 缺点：需要一定的学习成本，并且工具的设置可能比较复杂。 在现代计算中，性能优化是提高程序效率、响应时间、资源利用率等重要方面的核心工作。不同类型的性能瓶颈可以通过不同的优化策略来解决，常见的优化策略包括并行度优化、数据传输优化、存储器访问优化、向量化优化、负载均衡优化和多线程扩展性优化。下面将详细介绍每个优化策略。\n性能优化策略 1. 并行度优化（Parallelism Optimization） 并行度优化是指将计算任务拆分成多个独立的子任务，利用多核处理器或多台机器的计算能力来加速计算过程。并行度优化主要关注如何高效地将任务分解并利用多个计算资源。\n核心策略： 任务划分：将计算任务划分为多个相对独立的子任务，确保每个子任务都能并行执行。划分可以基于数据分割或功能划分。 并行模型选择：选择合适的并行编程模型，如多线程、分布式计算、SIMD（单指令多数据）等，依赖于硬件架构和应用的需求。 粒度控制：控制任务的划分粒度，避免过多的细小任务带来的上下文切换开销。任务太小可能引发更多的线程启动和调度开销，反而会降低性能。 避免线程同步问题：在并行化时，尽量减少线程间的同步需求，如锁的竞争等，因为锁竞争会增加线程等待时间，影响性能。 实例： 多核处理器利用：将计算密集型任务分配给不同的 CPU 核心。 GPU 加速：使用图形处理单元（GPU）进行并行计算，例如深度学习中广泛使用的并行训练。 2. 数据传输优化（Data Transfer Optimization） 数据传输优化关注的是如何减少计算过程中数据的传输开销，尤其是在多核、多节点或大规模并行计算环境中，数据传输的延迟和带宽限制可能成为性能瓶颈。\n核心策略： 减少数据传输量：尽量减少进程之间、计算节点之间的通信量。可以通过局部计算、减少数据的复制或压缩数据传输来减少带宽消耗。 数据预取：根据访问模式预测数据的需求，提前加载数据到缓存中，从而减少等待时间。 内存映射与共享内存：使用共享内存或内存映射文件来避免频繁的进程间通信，特别是在多进程或多线程的应用程序中。 局部性优化：将数据分配到物理内存的本地区域，减少跨节点或跨芯片的数据传输。 实例： 在多节点集群中，避免每次计算都从主存储器加载大量数据，而是通过缓存和局部数据共享来减少传输。 在 GPU 和 CPU 之间，使用较小的批次数据传输，以减少 GPU 与主机之间的通信开销。 3. 存储器访问优化（Memory Access Optimization） 存储器访问优化主要目的是减少内存访问延迟，提高内存带宽的利用率。内存访问模式的不合理会造成严重的性能瓶颈，尤其是对于大规模数据的计算密集型任务。\n核心策略： 数据局部性优化：通过优化数据访问模式，提高数据在缓存中的命中率。可分为时间局部性（重复访问相同数据）和空间局部性（访问数据时的空间邻近性）。 缓存优化：优化程序数据结构，使数据在缓存中更容易命中，从而减少访问主内存的次数。使用预取技术和合理的缓存对齐可以显著提高缓存命中率。 避免不必要的内存访问：减少冗余的内存访问，如不必要的内存复制或多次访问相同的数据。 非一致性存储模型优化：在多处理器系统中，保持各个缓存一致性可能导致额外的开销，优化缓存一致性协议和访问策略可以提升性能。 实例： 优化矩阵运算时，按行或按列的顺序访问数据，以提高缓存命中率。 使用 NUMA（Non-Uniform Memory Access）架构时，避免频繁地访问远程内存，尽量保持计算和数据存储在同一个节点的本地内存中。 4. 向量化优化（Vectorization Optimization） 向量化是指将标量操作转换为向量操作，在单条指令中处理多个数据元素。现代处理器，尤其是具有SIMD（单指令多数据）指令集的处理器，能够通过向量化提升计算效率。\n核心策略： 利用SIMD指令：使用 SIMD 指令集（如 AVX、SSE、NEON 等）对数据进行向量化操作，在单个指令周期内处理多个数据元素。 编译器自动向量化：现代编译器（如 GCC、Clang、Intel Compiler）能够自动识别可以向量化的循环，并进行相应优化。 手动优化：在一些复杂的场景中，可以手动编写 SIMD 代码，通过内联汇编或编写特定的 SIMD 库来实现向量化优化。 数据对齐：确保数据存储在合适的内存地址对齐，以便在向量化时避免额外的开销。 实例： 在图像处理、科学计算等应用中，使用 SIMD 向量化技术对每个像素或数据点执行并行操作（如加法、乘法等）。 5. 负载均衡优化（Load Balancing Optimization） 负载均衡优化是指在多处理器、多核心或分布式系统中，合理分配计算任务，以避免某些处理器过载或闲置，从而提高计算资源的利用率。\n核心策略： 任务划分：合理划分任务，将计算负载均匀地分配给不同的计算单元。划分粒度要合适，避免过细的划分导致调度开销。 动态负载均衡：在运行时动态调整任务的分配，以应对负载变化和计算资源的不均衡。例如，在多核环境中，动态地将任务从负载较重的核心转移到空闲的核心上。 数据局部性和负载均衡的结合：在多核或多节点环境中，除了考虑负载均衡，还要考虑任务和数据的局部性，避免数据传输引发的性能瓶颈。 实例： 在分布式计算中使用负载均衡策略，避免某些计算节点过载，其他节点空闲。 在多核处理器上，使用调度算法动态调整任务负载。 6. 多线程扩展性优化（Multithreading Scalability Optimization） 多线程扩展性优化关注的是如何使程序在多核或多处理器系统上运行时能够保持良好的性能提升，尤其是在线程数增加时，如何避免性能的下降。\n核心策略： 避免线程竞争：合理设计程序，减少线程间的资源竞争。过多的锁、临界区和线程同步会导致线程间的阻塞，从而影响程序的扩展性。 线程数的调优：选择合适的线程数，避免过多线程带来的上下文切换开销。通常，线程数不应超过处理器核心数。 工作窃取（Work Stealing）：在多线程应用中，可以使用工作窃取算法，通过让空闲线程从负载较重的线程中窃取任务，平衡负载，提升扩展性。 任务划分粒度：避免过小或过大的任务粒度，过小的任务会增加线程调度开销，过大的任务则可能导致资源利用率不足。 实例： 在多核机器上，动态调整线程数，以适应任务的计算需求和机器的硬件能力。 在并行计算中，使用线程池和任务队列来有效管理线程的创建和销毁。 环境模拟 docker qemu docs\nqemu安装ARM QEMU启动ARM64 Linux内核 大致思路是： 安装qemu-system-aarch64（ARM-64bit）模拟器； 安装aarch64-linux-gnu（ARM-64bit）交叉编译器； 交叉编译linux源码，得到ARM64 Linux内核镜像； 交叉编译busybox源码，使用busybox制作initramfs； 最后使用qemu-system-aarch64启用ARM64 Linux内核； 环境管理/运维 微服务 k8s python conda 其他 内容比较compare Beyond Compare 代码调用关系 cflow：静态分析工具，用来生成 C/C++ 程序的调用图。 Callgrind：动态函数分析 ","date":"2025-01-05T00:00:00Z","permalink":"https://loveleaves.github.io/p/tool/","title":"【Tool】 记录各种用到的工具"},{"content":"介绍 CUDA（Compute Unified Device Architecture，统⼀计算架构）是由 NVIDIA 开发的并行计算平台和编程模型，旨在利用 NVIDIA GPU（图形处理单元）强大的并行计算能力来加速计算密集型任务。CUDA 提供了一种编程接口，让程序员能够直接访问 GPU 上的计算资源。通过并行化计算任务，可以显著提升执行效率。GPU 相较于 CPU，在处理大量并行任务时具有显著的优势，通常拥有成百上千的处理核心（CUDA 核心），能够同时执行大量的操作。\n核心指标：核心数、GPU显存容量、GPU计算峰值、显存带宽 GPU不能单独计算，CPU+GPU组成异构计算架构：CPU起到控制作用，一般称为主机（Host）；GPU可以看作CPU的协处理器，一般称为设备（Device）；主机和设备之间内存访问一般通过PCIe总线链接。 CUDA 提供两层API接口：CUDA驱动(driver)API和CUDA运行时(runtime)API References 《CUDA 并行程序设计-GPU 编程指南》 第5、6、9章 https://github.com/loveleaves/ML_CPP/tree/main/ParallelFramework/CUDA cuda docs、programming-guide、best-practices-guide CIS 5650-GPU Programming and Architecture CUDA笔记 CUDALibrarySamples CUDA框架 基础编程框架 单文件example.cu编程框架\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 header inclusion const or macro definition declarations of C++ functions and CUDA kernels int main() { allocate host and device memory initialize data in host memory transfer data from host to device launch (call) kernel to do calculations in the device transfer data from device to host free host and device memory } definitions of C++ functions and CUDA kernels 编译指令\n1 nvcc -arch=sm_XY -code=compute_XY -o example example.cu nvcc编译工作原理 host code（standard C/C++ compiler）、device code（compiled into PTX/cubin） CUDA程序兼容性考虑：在将源代码编译为 PTX 代码时，需要用选项-arch=compute_XY指定一个虚拟架构的计算能力，用以确定代码中能够使用的CUDA功能。在将PTX代码编译为cubin代码时，需要用选项-code=sm_ZW指定一个真实架构的计算能力，用以确定可执行文件能够使用的GPU。 https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html Deep Dive into Triton Internals GPU设备设置 1、获取GPU设备数量 1 2 int iDeviceCount = 0; cudaGetDeviceCount(\u0026amp;iDeviceCount); 2、设置GPU执行时使用的设备 1 2 int iDev = 0; cudaSetDevice(iDev) 内存管理 主设内存管理 Note：GPU内存管理runtime接口传入的是双重指针。\n内存分配：malloc、cudaMalloc 数据传递：memcpy、cudaMemcpy 内存初始化：memset、cudaMemset 内存释放：free、cudaFree 主设内存传递\n1 cudaError_t cudaMemcpy(dst, src, count, kind); 枚举类型kind可取值：\ncudaMemcpyHostToHost，表示从主机复制到主机。 cudaMemcpyHostToDevice，表示从主机复制到设备。 cudaMemcpyDeviceToHost，表示从设备复制到主机。 cudaMemcpyDeviceToDevice，表示从设备复制到设备。 cudaMemcpyDefault，表示根据指针dst和src所指地址自动判断数据传输的方向。这要求系统具有统一虚拟寻址（unifiedvirtualaddressing）的功能（要求64位的主机）。 数据同步Synchronize 调用输出函数时，输出流是先存放在缓冲区的，而缓冲区不会自动刷新。只有程序遇到某种同步操作时缓冲区才会刷新。所以当要打印某个数据时，要先使用函数cudaDeviceSynchronize显式地同步主机与设备，促使缓冲区刷新。 核函数（Kernel function） 1、核函数在GPU上进行并行执行 2、注意： （1）限定词__global__ 修饰（可在void前后） （2）返回值必须是void （3）对于N是非blockSize整数倍时，必要时添加if，即使导致条件分支 注意事项：\n1、核函数只能访问GPU内存 2、核函数不能使用变长参数 3、核函数不能使用静态变量 4、核函数不能使用函数指针 5、核函数具有异步性 6、其他：核函数不支持C++的iostream 自定义设备函数 用__global__修饰的函数称为核函数，一般由主机调用，在设备中执行。如果使用动态并行，则也可以在核函数中调用自己或其他核函数。 用__device__修饰的函数叫称为设备函数，只能被核函数或其他设备函数调用，在设备中执行。 用__host__修饰的函数就是主机端的普通C++函数，在主机中被调用，在主机中执行。对于主机端的函数，该修饰符可省略。之所以提供这样一个修饰符，是因为有时可以用__host__和__device__同时修饰一个函数，使得该函数既是一个C++中的普通函数，又是一个设备函数。这样做可以减少冗余代码。编译器将针对主机和设备分别编译该函数。 不能同时用__device__和__global__修饰一个函数，即不能将一个函数同时定义为设备函数和核函数。 也不能同时用__host__和__global__修饰一个函数，即不能将一个函数同时定义为主机函数和核函数。 线程模型 线程的组织结构是由执行配置（executionconfiguration）\u0026laquo;\u0026lt;grid_size,block_size\u0026raquo;\u0026gt;决定的。这里的grid_size（网格大小）和block_size（线程块大小），对应核函数内部的内建变量 gridDim、blockDim、blockIdx、threadIdx 注意GPU系列对应框架最大允许的线程块大小，如1024 线程束：线程调度、管理 CUDA错误检查 运行时错误检测 所有CUDA运行时API函数都是以cuda为前缀的，而且都有一个类型为cudaError_t的返回值，代表了一种错误信息。只有返回值为cudaSuccess时才代表成功地调用了API函数。\n功能正确性检查 内存检查、越界访问、异常检查等 checktool 获得GPU加速的关键 CUDA事件计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start)); cudaEventQuery(start); // 此处不能用 CHECK 宏函数，对处于TCC 驱动模式的 GPU 来说可以省略，但对处于 WDDM 驱动模式的GPU来说必须保留。 需要计时的代码块 CHECK(cudaEventRecord(stop)); CHECK(cudaEventSynchronize(stop)); float elapsed_time; CHECK(cudaEventElapsedTime(\u0026amp;elapsed_time, start, stop)); printf(\u0026#34;Time = %g ms.\\n\u0026#34;, elapsed_time); CHECK(cudaEventDestroy(start)); CHECK(cudaEventDestroy(stop)); 程序性能分析 Nsight Compute，详见tools.md\n影响GPU加速的关键因素 数据传输的比例：主设数据传输 算术强度（arithmeticintensity）：计算相比于数据传输耗时的占比 并行规模：数据规模要尽量匹配SM等计算资源 因此, 在编写与优化CUDA程序时，一定要想方设法（主要是指仔细设计算法）做到以下几点\n减少主机与设备之间的数据传输。 提高核函数的算术强度。 增大核函数的并行规模。 CUDA中的数学函数库 https://docs.nvidia.com/cuda/cuda-math-api/\n单精度浮点数内建函数和数学函数（singleprecisionintrinsics and math functions）。使用该类函数时不需要包含任何额外的头文件。 双精度浮点数内建函数和数学函数（doubleprecisionintrinsicsandmathfunctions）。使用该类函数时不需要包含任何额外的头文件。 半精度浮点数内建函数和数学函数（halfprecisionintrinsicsandmathfunctions）。使用该类函数时需要包含头文件\u0026lt;cuda_fp16.h\u0026gt;。 整数类型的内建函数（integerintrinsics）。使用该类函数时不需要包含任何额外的头文件。 类型转换内建函数（typecasting intrinsics）。使用该类函数时不需要包含任何额外的头文件。 单指令-多数据内建函数（SIMDintrinsics）。使用该类函数时不需要包含任何额外的头文件。 内存组织 分层思想，平衡成本和效率（在编码中体现为高内聚、低耦合） https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-variable-specifier 不同硬件架构的内存编排不一定相同 全局内存（global memory） 核函数中的所有线程都能够访问其中的数据，容量是所有设备内存中最大的。基本上就是显存容量。 主要为核函数提供数据，并在主机与设备及设备与设备之间传递数据。 host端访问数据：使用runtime接口cudaGetSymbolAddress() / cudaGetSymbolSize() / cudaMemcpyToSymbol() / cudaMemcpyFromSymbol() 同步函数__syncthreads()：只是针对同一个线程块中的线程的，不同线程块中线程的执行次序依然是不确定的（不同线程块数据要保证不依赖）。 在CUDA中还有一种内部构造对用户不透明的（nottransparent）全局内存，称为CUDAArray。CUDAArray使用英伟达公司不对用户公开的数据排列方式，专为纹理拾取服务。 动态全局内存\n生命周期（lifetime）不是由核函数决定的，而是由主机端决定的（cudaMalloc、cudaFree） 静态全局内存\n静态全局内存变量由以下方式在任何函数外部定义： 1 2 __device__ T x; // 单个变量 __device__ T y[N]; // 固定长度的数组 在核函数中，可直接对静态全局内存变量进行访问，并不需要将它们以参数的形式传给核函数。 常量内存（constant memory） 有常量缓存的全局内存，一共仅有64KB，位于常量内存空间，核函数外部用__constant__定义。 它的可见范围和生命周期与全局内存一样，host端访问数据与全局内存一样。 由于有缓存，常量内存的访问速度比全局内存高，但得到高访问速度的前提是一个线程束中的线程（一个线程块中相邻的32个线程）要读取相同的常量内存数据。 纹理内存（texture memory）和表面内存（surface memory） 类似于常量内存，也是一种具有缓存的全局内存，有相同的可见范围和生命周期，而且一般仅可读（表面内存也可写）。不同的是，纹理内存和表面内存容量更大，而且使用方式和常量内存也不一样。 对于计算能力5.0以上的GPU来说，将某些只读全局内存数据用__ldg()函数通过只读数据缓存（read-onlydatacache）读取，既可达到使用纹理内存的加速效果，又可使代码简洁。对帕斯卡架构和更高的架构来说，全局内存的读取在默认情况下就利用了__ldg()函数，所以不需要明显地使用它。 寄存器（register）和 局部内存（local memory） 存储函数入参、内建变量和临时变量等，32位。 计算能力5.0~9.0的GPU，每个中都是64K的寄存器数量，Fermi架构只有32K； 考虑：每个线程块使用的最大数量、每个线程的最大寄存器数量 局部内存是全局内存的一部分，寄存器溢出是保存在局部内存中。 共享内存（shared memory） 和寄存器类似，存在于芯片上，具有仅次于寄存器的读写速度，extern __shared__ float shared[]定义，数组大小在运行时确定,或__shared__ float shared[100]。 共享内存对整个线程块可见，其生命周期也与整个线程块一致。 一个线程块中的所有线程都可以访问该线程块的共享内存变量副本，但是不能访问其他线程块的共享内存变量副本。 注意避免n路bank冲突（n很大场景，类似TLB组相联）：共享内存在物理上被分为32个（刚好等于一个线程束中的线程数目，即内建变量warpSize的值）同样宽度的、能被同时访问的内存bank。在所有其他架构中，每个bank的宽度为4字节。当同一线程束内的多个线程不同时访问同一个bank中不同层的数据，该线程束对共享内存的访问就只需要一次内存事务（memory transaction）,就会发生bank冲突。 L1 和 L2 缓存 从费米架构开始，有了SM层次的L1缓存和设备（一个设备有多个SM）层次的L2缓存 SM及其占有率 SM（Streaming MultiProcessor）构成\n一个GPU是由多个SM构成的。一个SM包含如下资源（不同架构不一定相同）：\n一定数量的寄存器。 一定数量的共享内存。 常量内存的缓存。 纹理和表面内存的缓存。 L1缓存。 两个（计算能力6.0）或4个（其他计算能力）线程束调度器（warpscheduler），用于在不同线程的上下文之间迅速地切换，以及为准备就绪的线程束发出执行指令。 执行核心，包括： 若干整型数运算的核心（INT32）。 若干单精度浮点数运算的核心（FP32）。 若干双精度浮点数运算的核心（FP64）。 若干单精度浮点数超越函数（transcendentalfunctions）的特殊函数单元（Special Function Units，SFUs）。 若干混合精度的张量核心（tensorcores，由伏特架构引入，适用于机器学习中的低精度矩阵计算）。 SM管理\nGPU中每个SM都可以支持数百个线程并发执行 以线程块block为单位，向SM分配线程块，多个线程块可被同时分配到一个可用的SM上 当一个线程块被分配好后，就不可以在分配到其他上了 线程束（warp）\nCUDA 采用单指令多线程架构管理执行线程，每32个为一组，构成一个线程束。同一个线程块中相邻的 32个线程构成一个线程束 每个线程束中只能包含同一线程块中的线程 线程束是GPU硬件上真正的做到了并行 ** SM 的占有率**\n一般来说，要尽量让SM的占有率不小于某个值，比如%，才有可能获得较高的性能。 SM的理论占有率（theoreticaloccupancy）的两个指标: 一个SM中最多能拥有的线程块个数 一个SM中最多能拥有的线程个数 根据寄存器、共享内存等具体架构具体分析 高效正确地并发并行 原子函数（atomic function） cuda提供原子函数来进行控制数据一致性读写。其中atomicCAS函数是比较特殊的，所有其他原子函数都可以用它实现（指定架构不支持时，但性能可能较差）。\nAtomic APIs with _system suffix (example: atomicAdd_system) are atomic at scope cuda::thread_scope_system if they meet particular conditions. compute capability must greater than 7.2. Atomic APIs without a suffix (example: atomicAdd) are atomic at scope cuda::thread_scope_device. Atomic APIs with _block suffix (example: atomicAdd_block) are atomic at scope cuda::thread_scope_block. 线程束（warp）基本函数 一个SM以32个线程为单位产生、管理、调度、执行线程。这样的32 个线程称为一个线程束。 SM执行属于单指令-多线程（single instruction, multiple thread，SIMT）的执行模式：在同一时刻，一个线程束中的线程只能执行一个共同的指令或者闲置。 在伏特架构之前，一个线程束中的线程拥有同一个程序计数器（programcounter），但各自有不同的寄存器状态（registerstate），从而可以根据程序的逻辑判断选择不同的分支。因此当同一个线程束（不同的不会）中的线程顺序地执行判断语句中的不同分支时，会发生分支发散（branch divergence）。 从伏特架构开始，引入了独立线程调度（independentthreadscheduling）机制。每个线程有自己的程序计数器。这使得伏特架构有了一些以前的架构所没有的新的线程束内同步与通信的模式，但导致： 增加了寄存器负担：单个线程的程序计数器一般需要使用两个寄存器。 独立线程调度机制使得假设了线程束同步（warpsynchronous）的代码变得不再安全：必须显式同步。 线程束内的线程同步函数：都在一个线程束内时，可以将线程块同步函数__syncthreads 换成一个更加廉价的线程束同步函数__syncwarp。 其他基本函数： 线程束表决函数（warpvotefunctions） 线程束匹配函数（warpmatchfunctions） 线程束洗牌函数（warp shuffle functions） 线程束矩阵函数（warp matrix functions） 协作组（cooperativegroups） 类似线程块和线程束同步机制的推广，它提供了更为灵活的线程协作方式，包括线程块内部的同步与协作、线程块之间的（网格级的）同步与协作及设备之间的同步与协作。 https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction-cg CUDA流（CUDA stream） CUDA流介绍 主要用cuda流解决核函数外部的并行：\n核函数计算与数据传输之间的并行。 主机计算与数据传输之间的并行。 不同的数据传输（回顾一下cudaMemcpy函数中的第4个参数）之间的并行。 核函数计算与主机计算之间的并行。 不同核函数之间的并行。 任何CUDA操作都存在于某个CUDA流中，要么是默认流（default stream），也称为空流（null stream），要么是明确指定的非空流。\n在主机端产生与销毁。一个CUDA流由类型为cudaStream_t 的变量表示，cudaStreamCreate和cudaStreamDestroy创建和销毁。 为了实现不同CUDA流之间的并发，主机在向某个CUDA流中发布一系列命令之后必须马上获得程序的控制权，不用等待该CUDA流中的命令在设备中执行完毕。这样，就可以通过主机产生多个相互独立的CUDA流。 检查一个CUDA流中的所有操作是否都在设备中执行完毕：cudaStreamSynchronize同步、cudaStreamQuery查询 默认流（default stream）/ 为空流（null stream） 1 2 3 两种调用方式： my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block\u0026gt;\u0026gt;\u0026gt;(函数参数); my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block, N_shared\u0026gt;\u0026gt;\u0026gt;(函数参数); 核函数的启动是异步的（asynchronous），或者说是非阻塞的（non-blocking），所以会host会立即执行下一条语句。该命令如果是CUDA操作不会被device立即执行，因为这是默认流中的CUDA操作，必须等待前一个CUDA操作（即核函数的调用）执行完毕才会开始执行。 可以在核函数启动后放置host操作，利用前面CUDA操作完成时间。 非默认流/非空流 1 2 3 4 调用方式： my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block, N_shared, stream_id\u0026gt;\u0026gt;\u0026gt;(函数参数); my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid,N_block, 0 ,stream_id\u0026gt;\u0026gt;\u0026gt;(函数参数); // 不使用动态共享内存 # stream_id是CUDA流的编号，N_shared是核函数中使用的动态共享内存的字节数。 用非默认CUDA流重叠核函数的执行与数据传递\n要实现核函数执行与数据传输的并发（重叠），必须让这两个操作处于不同的非默认流，而且数据传输必须使用cudaMemcpy函数的异步版本，即cudaMemcpyAsync函数。异步传输由GPU中的DMA（directmemoryaccess）直接实现，不需要主机参与。 在使用异步的数据传输函数时，需要将主机内存定义为不可分页内存（non-pageable memory）或者固定内存（pinned memory），在程序运行期间，其物理地址将保持不变，由cudaMallocHost和cudaFreeHost申请和释放。 统一内存（unifiedmemory）编程 介绍 统一内存是一种逻辑上的概念，一种系统中的任何处理器（CPU或GPU）都可以访问，并能保证一致性的虚拟存储器。这种虚拟存储器是通过CPU和GPU各自内部集成的内存管理单元（memorymanagementunit）实现的。 使用统一内存对硬件有较高的要求：不低于开普勒架构等。 好处：不用手动内存传输管理；相比手动内存操作可能会有更好的性能；超量分配，类似虚拟内存策略。 基本使用 统一内存在设备中是当作全局内存使用的，而且必须在主机端定义或分配内存，而不能在设备端（核函数和__device__函数）定义或分配内存。 动态申请：cudaMallocManaged 静态申请： __device____managed__int ret[1000]; 数据预取：cudaMemPrefetchAsync 多GPU编程 CUDA标准库 cuda所以接口及库详见官网：cuda docs、cuda developer\nThrust 类似于C++的标准模板库（standard template library）\nthrust、NCCL 数据结构：容器thrust::host_vector\u0026lt;typename\u0026gt;和thrust::device_vector\u0026lt;typename\u0026gt; 算法： 变换（transformation）。本书多次讨论的数组求和计算就是一种变换操作。 规约（reduction）。这是本书重点讨论过的算法。 前缀和（prefixsum）。下一节将详细讨论该算法。 排序（sorting）与搜索（searching）。 选择性复制、替换、移除、分区等重排（reordering）操作。 cuBLAS（basic linear algebra subprograms） 基本线性代数子程序，矩阵在内存中的存储是列主序（column-major order）的Fortran 风格，而不是像C语言中是行主序（row-majororder）的。\ncublas、blas cuBLAS 库包含3个API： cuBLAS API：相关数据必须在设备。 cuBLASXTAPI：相关数据必须在主机。 cuBLASLt API：一个专门处理矩阵乘法的API。 cuFFT 快速傅里叶变换（fast Fourier transforms）\ncufft cuSPARSE 稀疏（sparse）矩阵\ncusparse cusparse提供了一些稀疏矩阵、向量和稠密矩阵、向量的运算函数。 cuSolver 稠密（dense）矩阵和稀疏（sparse）矩阵计算库\ncuSolver 专注于一些比较高级的线性代数方面的计算，如矩阵求逆和矩阵对角化，类似LAPACK库。基于cuBLAS和cuSPARSE两个更基础的库实现。 cusolver、lapack cuSolver 库由以下3个相互独立的子库组成： cuSolverDN（DeNse, DN）：一个处理稠密矩阵线性代数计算的库。 cuSolverSP（SParse, SP）：一个处理稀疏矩阵的线性代数计算的库。 cuSolverRF（ReFactorization, RF）：一个特殊的处理稀疏矩阵分解的库。 cuSolver 库函数倾向于使用异步执行。为了保证一个cuSolver函数的工作已经完成，可以使用cudaDeviceSynchronize() 函数进行同步。 cuRAND 与随机数生成有关的库,包含伪随机数（pseudorandom numbers）和准随机数（quasirandom numbers）。\ncurand cuRand是后向兼容（backward compatible）的，注意cuRAND 和 the CUDA runtime的版本对应 提供了两种API：主机API和设备API。 cuDNN 深度神经网络（deep neural networks）\n是一个用于深度神经网络的 GPU 加速基元库。cuDNN 为标准例程（如前向和后向卷积、注意力、matmul、池化和规范化）提供高度优化的实现。 cudnn docs、cudnn developer ","date":"2025-01-03T00:00:00Z","permalink":"https://loveleaves.github.io/p/gpu/","title":"【GPU】 GPU架构及使用介绍"}]