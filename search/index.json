[{"content":"3D建模 常用软件 Fusion360 教程 2023年最新 Fusion 360 教程 fusion360教程 SolidWorks 3D打印 ","date":"2025-10-13T00:00:00Z","permalink":"https://loveleaves.github.io/p/3d_modeling/","title":"【建模】 3D建模、打印"},{"content":"基础知识 零基础入门PCB设计PPT 嘉立创EDA设计教程 原理图\u0026amp;PCB设计教程 PCB设计流程 硬件设计从需求到PCBA 专业pcb设计流程 资料准备 原理图：硬件工程师提供的原理图设计文件结构图 DXF文件：用于确认板框大小，是否存在限高、禁布的信息 设计说明：PCB Layout设计要求、设计问题记录表等信息 器件手册：进行封装绘制，以及推荐布局或走线参考 网表导入\u0026amp;结构导入 网表导入：将原理图网表导入到pcb中，确保原理图中的网络连接性、器件完全导入成功。 结构导入：将结构文件导入到pcb中，确保板框大小、结构器件信息、禁布区、限高区等信息，默认1：1导入，单位mm 模块抓取 按功能或者模块将器件进行抓取，确认主控的位置和方向，将各个模块根据飞线情况放置在主控芯片的周围。 立创EDA快捷键：ctrl+shift+x 器件布局和布局优化 器件布局：优先进行结构器件布局—特殊器件—主要器件，布局采取先大后小的原则，主要IC器件按飞线流向放置合适位置，滤波器件靠近滤波管脚。 布局优化：对预布局文件进行布局优化，器件中心对齐，大器件尽量对齐原则，相同模块必须一致，保证PCB布局合理、美观。 叠层设置和规则设置 叠层设置：确定每层对应的放置层标识 规则设置：常用规则（线宽、线距、过孔） PCB扇孔 通常对于引脚多的芯片：先扇孔，再走线。\nPCB走线和PCB修线 PCB走线：走线优先对重要信号走线，优先参考GND层走线。对重要信号线进行包地打孔处理，如差分信号，时钟信号。电源信号最后处理。 PCB修线：对走线进行优化调整、检查，不存在信号跨分 割，满足载流要求，回流路径短，不存在环形、U形路径。走线需美观，尽量耦合。 PCB等长\u0026amp;布线优化 PCB等长：对高速信号，有时序要求的信号线进行等长，3W原则。差分信号等长尽量在不耦合处等长。 布线优化：对整板走线进行优化，检查关键信号、电源信号载流，路径、过孔是否合理，让其走线更加美观、合理。 DRC检查\u0026amp;丝印处理\u0026amp;光绘输出 DRC检查：对整板进行DRC检查，检查信号是否全部连通， 是否存在开短路。检查是否未避开禁布区、限高区。检查规则优先级是否正确 丝印处理：进行丝印调整，丝印方向一致，丝印清楚，不 能上阻焊。座子丝印添加是否正确。版本号、L0G0是否添加。 光绘输出： ASM:装配图文件夹 CAM:Gerber文件夹，用于制版 SMT:贴片文件夹，用于贴片 PRJ:工程文件夹 XXX.docx:制版工艺说明文件 元器件选型 立创商城（也可大部分数据手册查看） 电子设计选型 pcb版一般包含以下模块：\n单片机最小系统：是指用最少的元件组成的单片机可以工作的系统。对于51系列单片机来说，单片机+晶振电路+复位电路,便组成了一个最小系统。晶振电路是单片机的振荡电路，通过晶振来放大输出信号。复位电路则用于重置单片机的系统状态，使其重新初始化。 电源电路：单片机最小系统中的电源是指能量的来源，其中VCC(40脚)将电源的正极和GND(20脚)视为电源的输入和输出。接地端(电源负极)则用于与地面形成电气连接。 外围功能电路：包括按键检测，Led指示灯，排针引出等 PCB布局要求 PCB设计布局指导 如何设计 PCB 布局 1、必须根据元器件的电气特性和使用特点来布局（这点非常重要），举例如下：对于各种接口、按键和排针，需要放在板子边缘，方便插接，对于屏幕和主控芯片等，一般放在板子中央，对于电源电路，一般放在板子的电源输入旁边并且要注意电流路径和滤波电容位置（非常重要），对于晶振需要靠近单片机晶振引脚摆放等 2、不要把元器件看成二维物体，而是应该看成三维物体，有时空间有干涉的情况需要考虑 3、元件的布局应该采用模块化，也就是同一个模块电路的元件应该放同一个区域，按照就近原则来布局，不能东一个西一个 PCB布线要求 PCB设计走线指导 【硬件设计】布线篇\u0026mdash;\u0026ndash;超实用的PCB布局布线规则 线宽、过孔大小如何计算 布线顺序： 关键元件优先、关键信号线优先、密度优先\n(1) 密度优先原则：从单板上连线最密集的区域开始布线。 (2) 优先关键元器件：如DDR、射频等核心部分应优先布线，类似信号传输线应提供专层、电源、地回路。其他次要信号要顾全整体，不可以和关键信号相抵触。 (3) 关键信号线优先：电源、模拟小信号、高速信号、时钟信号和同步信号等关键信号优先布线。 布线要求：\n1.顶层优先原则：尽量在顶层布线 2.电源线原则上要加粗：因为电源线是要给电路板各个模块供电的，电源线加粗有利于电流在主干道上流通；在日常PCB设计中，在25℃时，对于铜厚为10z(盎司)的导线，10mil线宽能够承载0.65A电流，40mil线宽能够承载2.3A电流。 3.同一层内走线大于90°：同一层走线禁止90°或者走锐角，从原理上讲，锐角直角走线会造成走线阻抗不连续，对于信号的传输有影响，推荐走线135° 4.注意电流路径和电容的摆放位置：电源要先经过电容滤波再给后级，去耦电容要贴近芯片引脚放置，并就近接地。 5.高频信号线尽可能短，并做好与其他信号的屏蔽隔离。为了降低相邻走线之间的串扰，尽量避免相邻层平行走线，走线应遵循3W原则：相邻层信号线应采用正交方向。差分线布线尽量等距等长。 6.PCB布线要尽量远离安装孔与电路板边缘：在PCB钻孔加工中，很容易会切掉一部分导线，为了电路板功能，应尽量远离这些位置。 7.需要添加泪滴。 原件符号绘制 对于元件库中没有的但需要使用的原件，进行元件符号绘制与封装。\nPCB设计常用知识点 PCB设计常用知识点\n电子设计常用知识点\n数据手册（Datasheet） 组成部分 元器件的数据手册一般包含以下部分：\n功能简述 电气特性 功能描述 外观与封装 应用示例电路 查阅网站 芯查查 立创商城 芯片封装类型 芯片封装类型简介\n选择芯片的封装影响到PCB的布局及布线，所以在元件选型时就应该考虑。\n芯片封装是半导体产业中重要的一环，它不仅保护着脆弱的半导体芯片，还承担着散热、电气连接和信号传输等多重功能。从最早的通孔封装（如DIP）到表面贴装封装（如QFP），再到区域阵列封装（如BGA）和晶圆级封装（如WLCSP），芯片封装技术向着小型化、高性能的方向发展。\n差分信号 单端信号是相对于差分信号而言的，单端输入指信号有一个参考端和一个信号端构成，参考端一般为地端。当耦合噪声时，接收数据无法正常还原。\n差分信号是一种信号传输技术，区别于传统的一根信号线一根地线的做法，差分传输在两根数据线上都传输信号，这两个信号的振幅相等，相位相差180°（即相位相反）。在这两根线上传输的信号就是差分信号，而承载差分信号的那一对走线就称为差分走线。\n差分信号的优点有哪些？ 1、抗干扰能力强 共模干扰抑制：差分信号对外界噪声具有很强的抗扰能力，因为两条信号线上的噪声是相同的（共模），接收端通过计算差值有效消除了共模噪声。 磁场耦合小：差分信号线之间的电流方向相反，产生的电磁场互相抵消，因此对外部设备的电磁干扰（EMI）小。 2、信号完整度高 抑制信号反射：两条线之间的特性阻抗匹配更容易实现，从而减少信号反射，保证信号完整性。 减少地回路问题：差分信号不完全依赖地作为电流的回流路径，减少了地回路的干扰，对于差分信号而言，最大的影响是对地阻抗是否一致，也就是对地平衡度，它们之间相对的阻抗影响并不特别重要，之间分布电容大了只会衰落信号强度，不会引入噪声和干扰，也就是对信噪比不会产生很大影响。 3、支持信号高速传输 差分信号在高速传输中表现优异，能够更好地保持波形，减少信号失真和抖动，适合用于高速数据总线（如PCIe、USB、HDMI等）。 4、电磁辐射低 差分信号的电流方向相反，形成的磁场互相抵消，大大降低了电磁辐射，符合更高的EMC（电磁兼容性）要求。 5、传输距离远 在相同的条件下，差分信号比单端信号能传输更长的距离，同时保持良好的信号质量。 差分信号在PCB中的设计要求有哪些？ 认识差分信号，在PCB设计中，差分信号的命名通常有“+、-、P、N”等标识 差分信号往往是速度较快、且在整个项目中比较重要的，在布局走线时要重点考虑，尽量保证差分信号顺畅以及距离短。 差分信号在走线时，非必要不换层，若一定要换层，在换层的附近添加回流地过孔 差分信号内不能有其余走线，若有匹配电阻或上拉电阻，也应该对称摆放。一般差分线间距较小，在电阻的选择上一般不大于0603，否则器件本身尺寸就会导致差分线耦合效果差，影响信号完整性。 差分信号在走线时，不可避免会有拐弯或打孔导致线长不一致，差分信号是接收两根信号的差值，需要保证相位的同步，同组差分信号一般不超过±5mil误差，在进行差分等长时，尽量满足小于3W间距（3倍线宽）以及小于2H（2倍间距）规则。 特性阻抗 特性阻抗是电磁波在传输线中传播时遇到的阻抗，反映了信号传输的质量和效率。在PCB设计中，控制特性阻抗对确保信号完整性和减少反射至关重要。\n特性阻抗（Z₀）是传输线上电压波与电流波的比值。\n计算公式为：\n其中：\nR 为单位长度电阻； L 为单位长度电感； G 为单位长度电导； C 为单位长度电容； ω 为角频率（ω=2πf，f是频率）； j 为虚数单位（j²=-1）； 1、单端阻抗 单端阻抗（Single-Ended Impedance）是指信号线与参考平面（通常是地平面或电源平面）之间的阻抗，适用于单端信号传输。\n常见的单端阻抗值有50Ω、75Ω等。 在高频下，单端特性阻抗可简化为：\n其中：\nL 是单位长度的电感； C 是单位长度的电容； 2、差分阻抗 差分阻抗（Differential Impedance）是指一对差分信号线之间的阻抗，适用于差分信号传输。差分阻抗可分为差模阻抗和共模阻抗，其中差模阻抗用于描述正负差分信号之间的阻抗，而共模阻抗则用于描述这两个信号与地之间的阻抗。常用于高速信号传输（如USB、HDMI、PCIe、以太网等）。\n常见的差分阻抗值有90Ω、100Ω等。 在高频下，差分特性阻抗可简化为：\n其中：\nZ₀是单端阻抗； k 是两条差分线之间的耦合系数（通常为0.1~0.3）； 3、阻抗控制作用 在PCB设计中，如果不控制阻抗，可能会对信号完整性、系统性能和可靠性产生严重影响。\n当信号在传输线中遇到阻抗不连续点时（如阻抗不匹配），部分信号会被反射回源端。 阻抗不匹配会增加信号之间的电磁耦合，导致相邻信号线之间的干扰。 阻抗不匹配会导致信号能量损失，信号衰减，可能使得信号在到达接收端时，无法被正确识别。 阻抗不匹配会影响信号的传播速度和时序，时序偏差错乱，导致数据错误，系统无法同步。 阻抗不匹配会引起时钟信号的反射和失真，时钟信号不稳定或抖动，会导致系统时序紊乱，降低系统性能。 阻抗不匹配会影响电源分布网络，导致信号能量通过电源或地线传导，增加电源噪声，影响系统稳定性。 阻抗匹配 阻抗匹配是指在电路中，将负载的阻抗与信号源的输出阻抗调整为相等或接近相等，以实现信号能量的最大传输或减少信号反射的过程。\n造成阻抗不匹配的原因 电路设计不当，比如导线时宽时窄，或GND平面不完整。 器件特性不一致，走线以及PCB板会带有寄生电容、电感、电阻等，导致实际阻抗偏离 系统参数变化，比如从外接线缆到PCB板，器件本身材质不一致导致阻抗不一致。 阻抗不匹配的后果 在高频电路中，当传输线与发送端阻抗不匹配时，会产生反射、振荡、过充等现象，并叠加至原本的信号被接收端收到，此时可能会导致接收端数据异常。 在模拟信号中，若阻抗不匹配，同样容易造成电压抖动、过充等现象，导致ADC转换数据抖动或异常。 如何计算阻抗 影响阻抗的因素有很多，导线宽度、PCB板材、PCB层叠、GND平面等等，在进行阻抗匹配计算时，通常会使用专门的工具来进行计算。比如：嘉立创阻抗计算神器\n根据输入参数的不同，计算的结果也不相同，在进行阻抗计算时，首先需要清楚所需的阻抗，其次是传输线的传输方式（差分、单端），根据参考平面与阻抗线所在平面的区别分为共面或隔层参考。（共面参考主要影响是阻抗线到参考平面的距离、隔层参考主要影响是参考层与阻抗层的层叠）。\n阻抗计算结果可能不符合实际生产设计需要，此时需要不断调整相关参数，选择一个价格、设计折中的方案。\n常见高速信号阻抗计算 USB传输线阻抗要求：差分90欧姆，差分对内长度误差≤5mil；传输线长度尽量不超过1800mil； 网口传输线阻抗要求：差分100欧姆，差分对内长度误差≤5mil；传输线长度尽量不超过1500mil； HDMI传输线阻抗要求：差分100欧姆，单端50欧姆，差分对内长度误差≤5mil；传输线长度尽量不超过500mil； 射频天线阻抗要求：单端50欧姆，走线周围要有良好的接地平面，尽可能保证射频信号区域内净空无其他干扰。 PCB 层压结构 PCB叠层的基本组成 PCB 叠层（PCB Stack-up）通常由导电铜箔（信号层和电源/地层）和绝缘材料（介质层）交替组成。合理的叠层设计对PCB的电气特性、物理性能、机械性能、可靠稳定性和制造成本等至关重要。\n叠层设置的基本原则 主芯片相邻层为地平面，在布线时提供良好的参考地平面； 信号层尽量避免直接相邻，以减少串扰； 所有信号层最好与地平面相邻，以保证完整信号的回流； 主电源尽可能与地平面相邻，降低电源平面阻抗； 常见的叠层结构 以下是一些典型的PCB叠层结构，实际设计可根据实际应用情况进行调整。\n双层板：包含两层导电铜箔层，中间是绝缘介电层。 四层板：包含四层导电铜箔层，每两层铜箔中间夹一层绝缘介电层。通常在靠近元器件多的内层里铺一层完整的GND。 六层板及以上：增加了更多的导电铜箔层，每两层铜箔中间夹一层绝缘介电层，提供更好的电源分配和信号隔离。 3W \u0026amp; 20H 规则 高速板中3W规则和20H规则说明 高速设计中 3W 规则指的是什么？ 3W 规则是指：信号线的中心间距不少于 3 倍线宽时，则可保证 70%的电场不互相干扰，称为 3W 规则。使用原因是一般信号线间距足够大时，可以减少信号线之间的串扰。当满足 2W 间距时，可保证 50%的电场不互相干扰。如果要达到 98%的电场不互相干扰，则需使用 10W 间距。 注意 3W 指的是俩根信号线的中心距。例：嘉立创 EDA 软件规则设计中，例如：导线是 5mil，对应 3W 间距，线与线之间的中心距是 15mil,这里安全间 距也就是线与线之间最近的边缘间距是 10mil。图片所示均为中心间距。 在 PCB 设计中一般时钟线，差分线，视频信号线，音频信号线，复位信号等需满足 3W 规则；普通的信号线一般满足 2W 规则即可。 为什么要做 3W 处理？ 可以减少串扰：满足3W原则能使信号间的串扰减少70%。串扰是信号线之间的电场和磁场相互作用而产生的干扰，它会影响信号的完整性。通过增大线间距，可以降低这种干扰从而提高信号质量。 提高信号完整性：减少串扰有助于保持信号的完整性，降低噪声对信号的影响。这对于高速信号传输尤为重要，因为高速信号对噪声和干扰更为敏感。 优化PCB布局：遵循3W规则有助于优化PCB布局，使得信号线之间的距离更加合理，从而提高PCB的可靠性和稳定性。 高速板中常说的20H指的是什么？ 20H规则：将电源层相对于地层内缩，使电场只在接地层的范围内传导。其中，一个H（电源和地之间的介质厚度）为单位，内缩20H可将70%的电场限制在接地层边沿内。若内缩100H则可将98%的电场限制在内。 内缩原因是电源层和地层之间的电场是变化的，在板子的边缘会向外辐射电磁干扰，将电源层内缩，可以让电场只在接地层的范围内传导，有效提高了EMC。 一般，在PCB设计时把电源层比地层内缩1mm，或者必须≥20mil，优先40mil，基本就可以满足20H的原则。 PCB 铺铜 PCB铺铜是指在电路板上未布线的空白区域铺设一层铜箔（通常称为“铜皮”）的操作，目的是：\n为了减小地线阻抗，提高抗干扰能力； 降低压降，提高电源效率； 与地线相连，还可以减小环路面积； 提高散热性能及抗干扰能力； 增强板材的机械强度和稳定性等。 数字电路中存在大量尖峰脉冲电流，因此降低地线阻抗显得更有必要，普遍认为：\n对于全由数字器件组成的电路，应该大面积铺地； 但对于一些模拟电路，铺铜所形成的地线环路，反而会引起电磁耦合干扰得不偿失。因此，不是所有电路都需要铺铜操作的。 铺铜的连接形式 全填充铺铜：正常的实体铺铜填充样式，可以承载较大的电流，适用于需要大电流的电路‌。例如，在电源模块、地线连接等需要稳定电流和电磁屏蔽的场合，实体铺铜能够提供更好的性能表现‌。实体铺铜在过波峰焊时，由于热胀冷缩的拉力，可能会导致铜箔起泡或板子翘起‌。 网格铺铜：主要起到屏蔽作用，网格铺铜可以减少铜箔的使用量，从而降低制造成本‌，有助于提升散热性能，特别适用于需要良好散热的场合‌。由于铜箔呈网格状分布，其导电性能相对全填充会有所降低，适用于对导电性能要求不高的场合‌。 铺铜的注意事项 避免出现孤岛/游离/悬空铜，如果铺铜区域未连接到电源、信号或地，出现孤岛铜，会形成天线效应，引入干扰信号。 GND铺铜的尺寸应该足够覆盖整个电路板，并且尽可能均匀分布电流负载，使得PCB的散热分布均匀。 高多层板，为确保信号完整性，需要有完整的GND参考平面铜，多层铺铜可以提供更好的信号完整性。 在天线等高频信号区域，铺铜容易导致信号弱，容易受到干扰，铺铜的阻抗会影响到放大电路的性能，一般不会铺铜或者及放置禁止铺铜区域净空处理。 GND过孔 PCB设计时板边为什么要打地过孔？\n在PCB设计中，板边打地过孔是一种常见做法，目的是为了抑制电磁干扰（EMI）、提供接地路径、屏蔽与抗干扰、增强PCB的机械强度、增强PCB板的散热能力。这种设计方法对电路的整体性能和元件的稳定性有显著影响，具体原因如下：\n抑制电磁干扰（EMI） 板边的地过孔形成屏蔽，抑制电磁辐射的散射，有效减少电磁干扰（EMI），保证PCB的电磁兼容性。\n提供接地回流路径 地过孔为电路中的接地信号提供了一个直接的路径，有助于降低接地阻抗，确保电路中的接地信号能够稳定、高效地传递到地层，这有助于改善电路的整体性能，特别是在高频和高速电路中，降低接地阻抗能够减少信号干扰和噪声，提高信号的完整性和稳定性。\n屏蔽与抗干扰 地过孔在板边形成连续的接地网络，能够阻挡或减弱外部电磁场对电路内部信号的干扰。同时，它们还能将电路内部的干扰信号引导至地层，防止其干扰其他电路部分。\n增强 PCB 的机械强度 在 PCB 板边打地过孔还可以增强电路板各层之间的电气连接，使电路更加稳定可靠，避免在插拔、震动等情况下对电路造成机械损坏。\n增强 PCB 板的散热能力 板边打地过孔的设计不仅能提升 PCB 的电磁兼容性和机械强度，还能提供额外的散热路径，有效缓解高功率和高频电路的过热问题，提升电路的热稳定性和使用寿命。\n回流路径 回流路径 回流路径（return current path）设计是PCB设计中的核心问题之一，涉及信号完整性、电源完整性和EMI性能。\n回流路径是电流从负载返回电源的路径。当信号从驱动器传输到接收器时，电流会通过信号线流向负载，然后通过地平面、电源平面或其他导体返回电源，形成完整的回路。回流路径并不是“地”的专属概念，它可以是地平面、电源平面，甚至是相邻的信号线（例如差分信号的回流路径）。\n回流类型 地回流路径：电流通过地平面返回电源，适用于单端信号传输，地平面通常具有较低的阻抗，能够提供稳定的回流路径，需注意地平面完整，避免分割导致回流路径不连续。 电源回流路径：电流通过电源平面返回电源，适用于差分信号或某些高速信号，电源平面和地平面之间可以通过去耦电容形成高频回流路径，需要注意电源平面的噪声问题。 设计原则 最小回流路径：回流路径应尽可能短，以减小环路面积，降低辐射和感应噪声。 连续平面：尽量使用连续的地平面或电源平面，避免分割平面导致回流路径不连续。 避免跨分割：信号线不应跨越平面分割区，否则回流路径会绕行，增加环路面积和EMI。 差分信号：差分信号的回流路径相互抵消，能有效减少EMI。 跨平面分割 在PCB设计中，参考平面可能会被分割（例如模拟地和数字地的分割），此时，信号线跨越参考平面的分割区域，会导致回流路径不连续，回流路径被迫绕行，路径变长，环路面积增大，可能产生辐射噪声。\n解决方案：\n尽量避免参考平面的分割。 如果必须分割，确保信号线不跨越分割区域。 高速信号在分割区域附近放置桥接电容，一般采用100nF，不可使用0Ω电阻。在高频下，电容的阻抗非常低，能够有效传递高频信号。为高频回流电流提供低阻抗路径。 两层板设计规范 两层板设计规范\n对于两层板的设计，两层板的设计难点在于没有完整的GND参考平面和没完整的电源平面，对于电源和地的处理，在两层板当中尤为重要，其中高密度两层板的布线难度也相对较大，需要在有限的布线空间内完成所有信号的连接，同时还得保证信号的质量和完整性；那么如何去设计两层板，可以根据两层板设计规范去设计。\n布局设计 布局建议是进行单面布局，这样子可以在设计合理的情况下更好的节省成本而且没有层间信号干扰的问题，这有助于提高信号的稳定性和可靠性。如果不能保证，最起码主要的元器件要和主控芯片放在同一面，合理布局可以方便走线不拥挤，而且信号走线间距保持等距减少线间串扰。\n布线设计 优先考虑关键信号的布线，确保它们有最短、最直接的路径。 顶层尽量去处理大部分的信号线，能直接连接的条件下，就进行网络顶层直连。 合理利用顶层和底层的空间进行布线，必要时可以通过打孔来实现层间的连接。 对于关键信号可进行包地线处理，以提高关键信号的抗干扰能力。 电源设计 两层板的电源布线，建议是在顶层去进行布线，能在顶层处理完成最好，如不能满足，也可以通过打孔走线在地层，要注意避免大面积分割问题，尽量保持底层平面完整。 电源线应尽可能宽以满足电源载流，减少电源波动对电路的影响。 避免电源线与信号线交叉，电源线和敏感信号线要保持一定的安全间距，必要时候可以适当包地隔离处理，以减少干扰。 地层设计 底层一般是用于处理地网络，底层进行地铜全铺，提供一个完整的地参考平面有助于确保信号能够顺畅地回流，减少电磁干扰。 注意地平面跨分割免问题，因为分割会破坏回流路径的连续性，导致信号回流时产生不必要的绕行，增加电磁辐射，如不能保证平面跨分割问题，可以在跨分割的区域，使用地孔来连接分割的地层，确保回流路径的连续性。 顶层空白区域也可以进行一个铺地铜进行处理，同时打孔将顶层和底层的地网络连接起来，为信号提供一个更直接的回流路径。 两层板如何控制阻抗 两层板如何控制阻抗\n在 PCB 设计当中，两层板控阻抗是一个具有难度的问题，因为和多层板去相比，两层板没有一个专门的参考平面层构成地返回路径，那么两层板应该如何去控制阻抗？以下是关键的控制方法和控制阻抗验证：\n1、共面阻抗法（包地法） 设计方式：由于两层板没有专门的参考平面，因此需要人为地构造一个电流返回路径，即共面阻抗。这通常通过“包地”的方式实现，即在信号线的周围加上地线，以形成共面结构。 走线宽度：走线宽度对阻抗有直接影响。在两层板上，为了获得所需的阻抗值，可能需要调整走线的宽度。一般来说，走线越宽，阻抗越小；走线越窄，阻抗越大。但需要注意的是，走线宽度过窄可能会导致加工难度增加和可靠性降低。 包地间距：包地间距是指信号线与地线之间的距离。这个距离对阻抗也有重要影响。包地间距越小，分布电容越小，阻抗越大。因此，在设计时需要仔细调整包地间距以获得所需的阻抗值。 保持连贯性：为了保证阻抗的均匀性，包地应该保持连贯，不应出现断裂或不规则的情况。这有助于减少信号的反射和失真。 2、阻抗控制和验证 获取材料参数：与 PCB 厂家合作，获取实际使用的电路板材料的详细参数。这些参数对于阻抗计算至关重要，因为它们直接影响阻抗值的计算结果。 生产工艺咨询：了解厂家的生产工艺和限制，以便在设计时考虑到这些因素。例如，某些生产工艺可能会对阻抗值产生影响，需要在设计时进行补偿或调整。 阻抗测量与验证：在生产前，可以要求厂家进行阻抗测量，以确保设计的阻抗值与实际生产的电路板相符。这有助于及时发现并解决问题，提高电路板的可靠性和性能。 PCB设计中电流与线宽的关系 PCB设计中电流与线宽的关系 在 PCB 设计里，电流和线宽的关联十分紧密。通常情况下，线宽越宽，其能够承载的电流也就越大。不过，这个关系并非简单的线性关系，还会受到铜箔厚度、环境温度以及允许温升等诸多因素的综合作用。\n线宽增加 增加线宽，电流承载能力会有一定程度的提升。但这种提升并非呈线性，而是遵循类似指数的规律。比如，线宽从 1mm 增加到 2mm，电流承载能力大概会提高 40%，而不是翻倍。\n铜箔厚度 铜箔厚度一般用盎司（oz）来表示，常见的有1盎司（厚度约35um）、1.5盎司（厚度约50um）、2盎司（厚度约70um），在相同线宽条件下，铜箔越厚，载流能力越强，但加厚铜箔会导致成本上升较大，当电流较大且线宽加宽不了的情况时，一般常见的处理是在PCB顶底层共同处理电源或在表面开窗镀锡操作。对于多层板电源处理，需要注意默认内层铜厚仅为0.5盎司（约为17.5um），若需要在内层进行电源处理，需要保证较大面积的接触或增加铜厚。\n温升限制 导体温升（高出环境温度的温度增量）是影响PCB导体载流能力的决定性因素，PCB温升与导线电流、走线宽度、走线厚度、PCB板材、相邻走线、层间距离、有无涂层、环境条件等诸多因素的关系。相同条件下，电流越大，温升越高，载流能力下降（温度升高导致导线内阻增加）；加宽导线/铜箔变厚/改变板材可以带来更好的散热与载流能力。\n可前往嘉立创EDA微信公众号/实用工具/电子硬件助手/PCB走线宽度计算器进行相关计算，通常实际值会将其增加1.3被进行应用。\n过孔与电流的关系 在PCB设计中，连接顶底层的方式通常是使用过孔来进行，过孔内壁镀铜支持电流传输；过孔内径越大，单个过孔传输电流越大，常用过孔20/10mil（0.8A电流）、24/12mil（1A）、32/16mil（1.3A）；注意，过孔越大，占用空间越大，对平面分割越严重。\n同时，过孔传输电流,与导线一致，不是倍数递增，且电流传输并不是均匀分配到每一个过孔，比如2个24/12mil过孔理论上传输2A没问题，实际可能一个过孔走了1.4A，1个过孔只走了0.6A，这导致部分过孔存在载流风险，所以通常会增加过孔数量且均匀分布。\nPCB设计中的安全间距 ‌ 在PCB设计中，考虑到可制造性、电气安全性、可使用性等方面，会有各类间距要求需要遵守；包括导线到导线、导线到焊盘、过孔到导线、过孔到焊盘、电源爬电距离、铜皮到板框距离等等；\n‌ 下方是嘉立创EDA设计规则中默认的安全间距要求；在日常器件不密、板框较大的场合，通常都不需要修改规则；但当板框较小、器件较多且密集的适合，默认的间距规则就会成为设计阻碍，导致拉不出来线、产生drc报错。此时，可以尝试减少设计规则中安全间距、导线默认线宽等规则。注意，此时的修改一定是要在板厂的生产要求内，且留有一定余量，否则最终设计出来不能生产或次品率过高。\n常规PCB通常是2层、4层且铜厚1oz居多，此时最小线宽线距为4mil或3.5mil；注意，这里是“最小”，在实际项目设计过程中，不应挑战工艺极限，通常≤6mil；已经足够满足绝大多少项目设计需求了； 常规PCB设计中，常用过孔孔径有，8/16mil，10/20mil，12/24mil，11.8/19.7mil，13.8/27.6mil，23.6/39.4mil；在实际项目实际过程中，不建议随意改变过孔尺寸，因为工厂钻头都是有固定大小的，当设计尺寸不符合实际钻头尺寸时，切割就会有误差，可能影响不良率；同时免费打样过孔应大于11.8/17.7mil。 20H规则：将电源层相对于地层内缩，使电场只只在接地层的范围内传导。其中，一个 H（电源和地之间的介质厚度）为单位，内缩 20H 可将 70%的电场 限制在接地层边沿内。若内缩 100H 则可将 98%的电场限制在内。一般，在 PCB 设计时把电源层比地层内缩 1mm，或者必须≥20mil，优先 40mil，基本就可以满足 20H 的原则。当然，这是建立在内缩后GND平面仍然完整的前提下，若内缩后导致GND平面不完成或有割裂，则需减少内缩距离。 PCB常见丝印标识 PCB常见丝印标识\n1 元件位号标识 ANT：天线（Antenna）； B ：电池（Battery）； BT：蓝牙模块（Bluetooth）； BZ：蜂鸣器（Buzzer）； C : 电容（Capacitor）； D : 二极管（Diode）； DS：显示器件（Display）; F : 保险丝（Fuse）； FB：磁珠滤波器（Ferrite Bead）； FS：快速熔断保险丝（Fast Blow Fuse）; H : 排针排母（Header）； IR：红外二极管（Infared Diode）； JP：跳线（Jumper）； K : 继电器（Relay）； KEY：按键（Key）； L ：电感（Inductance）； M ：电机（Motor）； MIC：麦克风（Microphone）； NTC: 负温度系数热敏电阻（Negative Temperature Coefficient Thermistor）; LDR：光敏电阻（Light Dependent Resistor）； LED：发光二极管（Light Emitting Diode）； Q ：晶体管/三极管/场效应管（Transistor）； R : 电阻（Resistor）； RP：电位器/可调电阻； RN：排阻（Resistor Network）； RT：热敏电阻（Thermistor）； S ：开关（Switch）； T ：变压器（Transformer）； TP：测试点（Test Point）； U ：集成电路（IC）； USB：USB接口； X : 晶振（Crystal Oscillator）； ZD：稳压二极管/齐纳二极管（Zener Diode） 2 常见认证标识 3 常见符号标识 PCB开尔文走线 ‌开尔文走线（Kelvin Connection）是一种用于高精度测量低电阻的布线技术，通过分离电流传输路径和电压检测路径，消除引线电阻和接触电阻的影响，实现毫欧级甚至微欧级电阻的精确测量。\n‌ 首先，先了解采样电阻（也称为电流检测电阻），是一种专门用于将电流信号转换为可测量电压信号的低阻值精密电阻。它是电流测量电路中的核心元件，串联在待测电流路径中，通过测量电阻两端的压降（根据欧姆定律 U=I×R），间接计算出流经电路的电流值，采样电阻的阻值一般不会超过1Ω，典型范围在0.1mΩ ~ 100mΩ（毫欧级），精度比较高，一般在1%以内。\n‌ 在测量电流时，电流检测技术分为高侧（边）检测和低侧（边）检测。将测量采样电阻放置在电源与负载之间的检测方法称为高侧检测，将测量采样电阻放置在负载与接地端之间的检测方法称为低侧检测。这两种用于检测负载中电流的方法，如图1所示。\n图1 高/低边电流检测采样 ‌ 在普通的两线测量法中，测量电流和测量电压共用同一对引线，引线本身的电阻会叠加在被测器件的电阻上，导致测量值偏大。通过开尔文走线（四线检测法）是提高测量精度的关键，主干道用粗线或宽铜箔，大部分电流都是从主干道流过，电流测试支路用细线，测量通过采样电阻两端的压降，计算出流过的电流，显著提高采样电阻的采样精度。\n在电路板设计中，开尔文走线需遵循以下规则：\n采样电阻焊盘分离电流焊盘区和电压检测焊盘区，电流路径使用宽铜箔，电压测量线用细线连接；\n两条电压线应尽可能长度相等、线宽相同、保持对称布线，并远离噪声源，最好使用差分对布线规则，这有助于抑制共模噪声；\n采样电阻到电流检测芯片的布线长度应尽可能近，以减少测量误差；\n电压线从电阻焊盘中心直接引出，避开电流路径分支点，远离功率元件、大电流走线等热源，温度变化会影响测量精度；\n图2 开尔文走线接法 图3 开尔文走线接法（双通道） PCB常见模块设计参考 PCB常见模块设计参考\nLDO模块 LDO（low dropout regulator，低压差线性稳压器）。\n注意点：AMS1117一般输出电容使用钽电容而非陶瓷电容。 常用款型：1117（如AMS1117）、除了1117，还有哪些更好用的线性稳压器？ 优点： LDO外围器件少，电路简单，成本低，通常只需要加一两个旁路电容 LDO负载响应快，输出纹波小，噪声小 缺点： 效率低，输入输出压差不能太大 体积大、不支持mlcc、只能降压 静态电流过高、发热温度高 布局参考 LDO虽然电路结构简单，但其效率不高，工作时输入输出的电压差都被转换成热能消耗了。所以在进行LDO布局时需考虑散热问题，部分芯片还可添加散热片辅助散热。输入/输出电容尽量靠近输入/输出引脚摆放，滤波电容从大到小依次摆放，LDO两边的电容数量需要保持一致，这样才能保证电源的输入/输出端流入地的电流平衡，布局要点如下：\n按照电源信号的输入/输出路径，布局时按一字型或者L型摆放； 电容按先大后小顺序摆放，就近输入/输出管脚； 输入/输出电容GND引脚尽量朝一个方向，保持GND方向一致，减少回流路径。 走线参考 LDO走线时由于电路连接比较简单，走线时沿着信号方向引出即可，一般只需要考虑线宽是否能够承载整个系统的电流即可。在单面板设计时保持GND信号的完整性，输入输出部分可直接用铜皮填充；当使用双面板以及多层板设计时，需在GND焊盘附近整齐放置一些GND过孔。注意事项如下：\n电源输入输出信号可直接全填充或粗导线连接，确保铜皮宽度能够过系统最大电流； 走线尽可能直，避免不必要拐弯，必须拐弯时走钝角或圆弧； 走线时根据信号流向，输入信号先经过电容再到芯片，输出走线也需先过电容再输出； 双多层板设计时在加一些整齐统一的过孔保证各层间GND的连接； 走线后在板子上可根据电路需要添加必要丝印信息提示，避免焊错或接线错误。 DC-DC模块 DC/DC转换器一种是开关电源稳压器，指利用电容、电感的储能的特性，通过可控开关（MOSFET等）进行高频开关的动作，将输入的电能储存在电容（感）里，当开关断开时，电能再释放给负载，提供能量。\nDC-DC转换器（非隔离式DC-DC）根据其功能可分为三种基本拓扑结构：\n降压转换器(Buck Converter)：当输入电压高于所需输出电压时使用 升压转换器(Boost Converter)：当输入电压低于所需输出电压时使用 升降压转换器(Buck-Boost Converter)：当输入电压可能高于或低于输出电压时使用 优缺点：\n缺点： 外围器件多，电路复杂，成本高 负载响应比LDO慢，输出纹波大，噪声大 优点： 效率高，输入电压范围宽泛 支持降压和升压 输出电流高，功率大 布局参考 PCB的良好布局对DCDC电源非常至关重要，他能直接影响到产品的稳定性和转换的效果。总结规则如下：\n旁路去耦电容靠近输入/输出端摆放（如图4-15） 从数据手册中看出PH引脚是电源IC的开关节点，那么电感和环流二极管应尽量靠近PH引脚摆放，尽可能的缩小PCB的导体面积，防止电容过度耦合和减小电流环路面积（如图4-16所示） 在电源整体布局时，尽量横平竖直的摆放，不要将器件摆放的过于杂乱，避免增加电源路径（如图4-17所示） DC-DC电源芯片在工作时会产生一些热量，所以布局时，应提前注意是否有对热源敏感的器件，避免影响到其他器件的工作（如图4-19所示） 走线参考 DC-DC模块常用于大电流使用，且走线对其效果影响较大，注意事项如下：\n输入和输出的电源走线一定要计算好走线宽度，大电流/电压可以使用铺铜方式或者全填充 方式进行连接； 所有的走线尽可能的短和直，减少电源路径 GND焊盘使用铺铜或全连接连接，输入输出GND尽可能位于一块铜皮上，同时在底层铺铜（注意避开电感区域），在GND焊盘处打上过孔进行连通，缩短电源的回流路径； DC-DC反馈走线不能直接走在电感、二极管、大电容、IC芯片散热焊盘下面，也不能被大电流环包围，反馈线不是电源走线，不需要加粗，正常信号线宽度（10mil/15mil）即可）； 如果芯片下方有热焊盘，则需要使用多个过孔连接到底层，增强散热性 电感器件底部尽量不走线，避免电感产生的电磁信号影响到信号线的传输； USB接口 USB接口PCB设计全攻略\n为什么Type-c接口要加5.1K电阻下拉\nCC引脚不使用时，一般连接1个5.1K下拉电阻接地。\n晶振 布局参考 晶振电路布局需要优先考虑，整体紧凑摆放，晶振尽量靠近 IC，负载电容放置于晶振与 IC 之间，以减少时钟信号传输的延迟和干扰； 晶振摆放尽量远离板边和接口器件，减少其受外部物理因素干扰的风险，如物理撞击等； 晶振需远离干扰源，如电感、大功率驱动器、RF天线等； 晶振区域的底层不可放置其余器件，需保证晶振区域的净空； 布线参考 晶振电路的时钟信号走线越短越好，可以按照类差分走线，晶振的时钟走线不可打过孔走线连接； 在晶振走线周围通过GND过孔进行包地，每隔50-100mil间距整齐放置屏蔽地过孔，用以隔离吸收晶振辐射的噪声； 晶振区域同层需要净空处理，可以使用禁止铺铜区域进行隔离，晶振本体相邻层最好不要走线，保证地的完整性； USB 接口 实际项目参考：基于VL813的USB3.0-HUB设计 布局参考 USB接口应该靠近板边或按照结构定位摆放，方便插拔； USB输入接口和输出接口分开放置，便于分区和使用； 端接匹配电阻、ESD、共模电感、阻容器件靠近USB接口摆放； USB接口远离RF天线、摄像头等高电磁辐射EMI源摆放； 在布局时，尽量使差分线路最短，以缩短差分线距离； 布线参考 USB走线优先权高于其它器件和信号，优先考虑对高速USB差分（D+/D-、RX/TX）的布线； USB要走差分，阻抗控制为90Ω，并包地处理，包地线与差分线距离应大于20mil，每隔一段距离，打上一个回流地过孔，总长度最好不要超过1800mil，尽量缩短走线长度； USB的差分对需要做等长处理，长度一旦相差太多，将会影响时序偏差，引起共模干扰，降低信号质量，USB组内等长误差建议控制在±5mil以内； 差分对尽量少换层打过孔，过孔会造成阻抗改变和信号反射问题，若无法避免使用过孔，需要在打孔换层处加一对回流地过孔，用于信号回流换层，过孔建议不超过2个； 如果使用了外部终端电阻匹配阻抗时，请确保端接匹配电阻与主控制器信号输出引脚之间的距离小于200mil，以便更好地控制阻抗，避免信号反射； USB差分信号布线时，应远离板边或铺地边缘，至少保证90mil以上距离；远离电源网络、大电流信号、DDR、HDMI等高速信号，保证至少50mil的距离，以减小串扰； 电子设计常用知识点 0Ω电阻的功能 0Ω电阻又称跨接电阻，是一种标称阻值为0的特殊电阻，实际阻值通常在10-50mΩ（毫欧）之间，下面介绍0Ω电阻的用法和功能。\n1 方便调试与兼容设计 当电路引脚功能不确定时，可以通过0Ω电阻临时连接不同模块，待调试后确定出最终方案。\n2 参数匹配 在不确定电路参数时，用0Ω电阻作为过渡元件，待调试后更换为实际电阻值。 ‌\n3 模数电路单点接地 在模拟电路和数字电路等混合电路中，往往要求地分开，避免信号干扰，不同地线可以通过0Ω电阻单点连接在一起。\n4 跨接跳线 ‌ 在PCB布线时，可能会出现布线走不通的情况，如铝基板单层布线，不允许打过孔，可以使用0Ω电阻充当跳线进行连接。\n5 保护与熔断 ‌ 作为低成本熔丝使用，当电路过流时，优先熔断0Ω电阻，以保护其他元件。 ‌\n上拉电阻和下拉电阻 上拉电阻：将一个不确定的信号，通过一个电阻与电源VCC相连，固定在高电平。作用：上拉是对器件注入电流；灌电流；当一个接有上拉电阻的IO端口设置为输入状态时，它的常态为高电平。 下拉电阻：将一个不确定的信号，通过一个电阻与地GND相连，固定在低电平。作用：下拉是从器件输出电流；拉电流。当一个接有下拉电阻的IO端口设置为输入状态时，它的常态为低电平。 上拉电阻和下拉电阻2者共同的作用是：避免电压的“悬浮”，造成电路的不稳定。\n上拉（Pull Up ）或下拉（Pull Down）电阻（两者统称为“拉电阻”）**最基本的作用是：将状态不确定的信号线通过一个电阻将其箝位至高电平（上拉）或低电平（下拉）。**无论它的具体用法如何，这个基本的作用都是相同的，只是在不同应用场合中会对电阻的阻值要求有所不同，从而也引出了诸多新的概念。\n芯片IO口为什么需要接上拉电阻？ P0为什么需要上拉\nMCU的IO引脚在处于输出模式时，在硬件层面通常可以分为两种输出方式：\n推挽输出/推拉输出（push pull）： 开漏输出： 可以看到，但使用开漏输出时，无法输出高电平状态，可以在引脚上接一个上拉电阻，这样开漏输出的引脚就可以输出高电平了。\n为什么Type-c接口要加5.1K电阻下拉 usb official docs\nUSB是主从模式的结构，设备与设备之间、主机与主机之间是不能互联的，所有的数据传输都是由主机发起，而设备只能被动的负责应答，在USB-Typec接口中，是没有ID引脚来标识当前是主机或设备的，此时CC引脚就可以充当一个检测作用了。\n在主机和设备连接上后，主机的cc引脚检测到设备CC引脚的下拉电阻，表示接入到设备，此时主机可以打开Vbus的FET开关，输出Vbus电源给设备。\n事实上，CC引脚的作用远不止于此，在usb协议规范中指出，cc引脚用于连接检测、接口配置与Vconn功能；\nCC引脚的简要概述中指出，cc引脚主要用于一下目的：\n检测USB端口的连接，例如源端到接收端的连接； 解决电缆方向和扭转连接问题，以建立USB数据总线路由 在两个连接端口之间建立数据角色 发现并配置Vbus：USB Type-C电流模式或USB Power Deliver 配置Vconn 发现并配置可选的备用和辅助模式； 由于USB-Typec接口指出正反插，对于USB2.0标准，主机和设备接口的两组USB_DP/DM信需要各种短接以实现这一功能；在USB3.2超高速或USB4双通道传输方案中，主机和设备需要配置对应的传输通道，需要自行解决通道顺序问题，此时将单个CC引脚和1组TX/RX进行匹配，通过检测cc引脚的方向来实现正反插功能，从而判断使用哪组tx/rx信号进行传输，如果是双通道，也同样可以根据cc引脚判断通道序号，为0/1通道。\n为什么IC电源引脚旁边的电容的作用、选择和放置 芯片IC每个电源引脚旁边的电容的作用、选择和放置？\n在电源输入和IC引脚处，一般会加两个比如10uF和0.1uF的电容，进行滤波，大电容靠近电源，小电容靠近元件。一般不会直接放置一个电容，因为对于实际电容来说，它有等效串联电阻（ESR）和等效串联电感（ESL），从频率响应曲线来看，呈现V子形。一般电容越小，能过滤的频率越大，反之越小。\n电容尽量放到靠近IC引脚处，并且要经过电容再到IC 引脚，而且电源分支尽量在进电容前进行，因为如果摆放很远的话，电容滤除噪声后的电源会在这个段路径上又串扰进新的噪声，那么这个电容的作用就没有太大的意义。\nADC分压电阻的选择 \u0026amp;\u0026amp; ADC电量检测电路 ADC电量检测电路\nADC是模拟到数字转换器（Analog-to-Digital Converter）缩写，主要用于将连续传输的模拟信号转换为数字信号，便于数字系统（如中央处理器CPU、微控制器MCU等）对传输信息进行快速处理和分析。\n在实际使用过程中，adc分压检测常用于检测外部输入电压的变化，用于将一个外部电压分压到0~3.3V被adc采集到，一般用于低功耗设备或对电压敏感设备中，此时会有精度以及耗散电流的要求。虽然电阻分压简单易懂，但事实上，外部的输入电阻的选择会直接影响采样的精度和耗散电流的大小，它是搭配内部的adc电路一起工作的，这就要求我们需要对其adc检测原理进行一定的了解。\nADC 转换包括采样、保持、量化、编码四个步骤。采样阶段需要在规定的采样时间内将外部信号的电压完整无误的采样到 ADC 的采样电容上，即在采样开关 SW 关闭的过程中，外部输入信号通过外部的输入电阻 RAIN 和以及 ADC 采样电阻 Radc 对采样电容 Cadc 充电；每次采样过程可以简化为外部信号通过输入阻抗以及采样电阻对采样电容的充电。\n从上方的原理分析中可知，adc采集电路本质上是一个rc延迟电路，我们需要在使信号在规定的时间内被达到一个平稳的值。其中内部adc电阻以及内部adc电容是固定不变的，在数据手册中都能找到，那我们能改变的就只有外部的电阻值，也就是输入阻抗了。\n蓝牙模块 蓝牙模块\u0026amp;蓝牙串口小程序 使用教程\n元器件选型知识点 PCBA电子工程师必须要知道的元器件选型完全指南 电子元器件+模拟电路硬件零基础入门\n刚入门时应优先考虑：\n封装：封装与pcb板相关，封装不对会导致无法焊接使用 电气属性：比如电容等支持最大电压，如果设计的电路超过选型的电容，会导致击穿风险。 性价比和可重用：满足目前pcb的所需功能，并考虑后续可能的扩展复用。 电阻 电阻类型 固定电阻器：通过内部材料的特性来设定阻值，适用于稳定电流的场合。 可变电阻器（如电位器）：可调节电阻值，用于调节电路中的电流和电压。 热敏电阻（NTC、PTC）：其阻值随温度变化，广泛用于温度补偿与电流保护。 光敏电阻：其阻值受光照强度影响，主要用于光传感器电路。 电阻器的选型考虑因素 阻值：根据电路的工作要求选择合适的阻值。 功率：电阻器需要根据电路中流过的电流和电压承受相应的功率。过高的功率负载可能会导致电阻器过热，甚至损坏。功率单位是瓦特（W）。 精度：对于一些高精度电路（如测量电路），需要选择精度高的电阻器。电阻的精度通常以“±”表示，例如±1%、±5%等。 温度系数：电阻的阻值可能随温度的变化而变化，温度系数越小，电阻的稳定性越好，适合对温度变化敏感的电路。 耐用性与环境适应性：不同类型的电阻器适用于不同的环境，例如高温、高湿或腐蚀性环境。 电容 电容类型 电容器是用来储存电能并在需要时释放的电子元件。电容器的基本功能包括滤波、平滑电流、信号耦合等。根据其构造和材料的不同，电容器的类型也有所差异。\n常见的电容器种类有：\n陶瓷电容器：广泛用于高频电路，具有稳定的性能。 电解电容器：通常用于电源滤波电路，具有较大电容值，但需要注意极性。 薄膜电容器：适用于精密电路，具有较高的稳定性和低损耗。 铝电解电容器：主要应用于直流电源的滤波、去耦等方面，具有较大电容值。 钽电容器：与铝电解电容器类似，但具有更小的体积和更高的可靠性。 电容器的选型考虑因素 电容值：电容器的容量通常以法拉（F）为单位，常见的单位有微法（µF）、皮法（pF）等。电容值决定了电容器储存电能的能力，需要根据电路的需求来选择合适的电容值。 耐压值：电容器的耐压值需要高于电路中所施加的电压，避免电容器损坏。一般来说，选择一个比电路最大工作电压高20%-30%的耐压值是比较安全的。 ESR（等效串联电阻）：ESR是电容器的一个重要参数，影响电容器的效率和性能。低ESR值适用于高频电路。 温度范围与稳定性：对于高温或特殊环境下使用的电容器，需要选择具有较高温度稳定性的产品。 极性：部分电容器（如电解电容器）具有极性，在电路设计时需要特别注意极性连接。 电感 电感类型 电感器主要用于存储电能和限制电流的变化。电感器的基本功能包括滤波、耦合、储能和信号传输等。其工作原理是基于电流变化产生的磁场。\n常见的电感器类型有：\n固定电感器：用于稳定电流和滤波的电路中。 可调电感器：能够调节电感值，适用于频率调节电路。 铁氧体磁芯电感器：用于高频滤波和电源管理。 线圈电感器：多用于信号处理和电磁兼容性控制。 电感器的选型考虑因素 电感值：电感值的单位是亨利（H），常见的单位有毫亨（mH）和微亨（µH）。选择时需要考虑电路的工作频率以及电流大小。 工作频率：不同类型的电感器适用于不同频率范围的电路。高频电路通常需要选择小型化、低损耗的电感器。 电流承载能力：电感器的电流承载能力需要高于电路中流过的电流，否则可能会导致过热甚至损坏。 饱和电流：饱和电流是指电感器在工作时，电流超过一定值后其电感性能急剧下降的现象。选择时需要考虑电感器的饱和电流值，以确保其在工作过程中稳定性。 DC电阻（DCR）：电感器的DC电阻决定了其直流电流损耗，选择时需要确保DCR尽可能低，以提高电路的效率。 晶振 有源晶振和无源晶振该怎么选择\n晶振中的有源和无源到底有什么不同? 晶振是一种电子元件，它在电子设备中提供精确和稳定的时钟信号。晶振根据其工作原理的不同，可以分为有源晶振和无源晶振。\n**有源晶振( Oscillator)**是一种带有放大器的晶振，它可以提供更高的输出功率和更好的信号质量。有源晶振通常由振荡器、放大器和输出级组成。振荡器提供基本的振荡信号，放大器放大振荡信号的幅度，输出级将放大后的信号输出。有源晶振通常用在需要高信号质量和长距离传输的应用中，例如无线电通信、广播电视等。\n**无源晶振(Crystal)**是一种没有放大器的晶振，它的输出功率较低，但也具有精确和稳定的时钟信号。无源晶振通常由振荡器和输出级组成，没有放大器。无源晶振通常用在需要低功率和小体积的应用中，例如计算机、手机等。\n有源晶振和无源晶振在使用时需要注意以下几点：\n有源晶振通常需要使用外部电源，而无源晶振则可以直接使用被控设备的电源。 有源晶振的输出功率较高，可以传输更远的距离，但也需要更多的功耗。无源晶振的输出功率较低，但功耗也更小。 有源晶振的信号质量更好，但也更复杂，需要更多的电路来实现。无源晶振的信号质量较好，但也更简单，可以更容易地集成到电路中。 总之，有源晶振和无源晶振都是提供精确和稳定的时钟信号的重要元件。它们的区别在于工作原理的不同，有源晶振带有放大器可以提供更高的输出功率和更好的信号质量，而无源晶振没有放大器，功率较低，但更适合需要低功耗和小体积的应用。\n以下是一些选择有源晶振和无源晶振的建议：\n稳定性要求： 如果需要高精度、高稳定性的时钟信号，或者用于频率合成等要求较高的应用，建议选择无源晶振。因为无源晶振的稳定性更高，可以提供更加精确和稳定的输出信号。\n输出功率要求： 如果需要较高的输出功率和较低的输出阻抗，建议选择有源晶振。因为有源晶振具有较高的输出功率和较低的输出阻抗，可以满足一些需要高输出功率的应用场景。\n工作电压和电流要求： 有源晶振需要外部电源或电池等能量源来驱动，因此需要考虑其工作电压和电流要求是否符合实际应用需求。而无源晶振则无需外部电源驱动，因此不需要考虑其工作电压和电流要求。\n贴片晶振四个脚与两个脚的区别 类型的区别\n无源晶振\n两个脚的无源晶振：这种类型的晶振没有内置振荡电路，需要依赖外部电路来产生振荡信号。这种类型的晶振主要用于提供稳定的时钟信号，以确保电路的正常运行。 四个脚的无源晶振：尽管有四个脚，但真正称之为功能脚位的只有两个，即脚1和脚3。另外两个脚则起固定作用。这类无源晶振同样需要外部电路来产生振荡信号。 有源晶振\n四个脚的有源晶振：有源晶振是一种内部集成了振荡电路的晶振，不需要额外的外部元件就能产生振荡信号。它通常用于要求更高稳定性的场合，如GPS、蓝牙、WIFI等应用。 功能的区别\n无源晶振需要外部的时钟电路来产生振荡信号，而有源晶振内部集成了振荡电路，可以自行产生振荡信号。此外，有源晶振通常具有更高的稳定性和精度，但也需要额外的电源输入。\n使用方式的区别\n无源晶振在四脚的情况下，只有两个脚是功能脚，另外两脚是悬空的，用于接GND。而对于有源晶振，一般情况下有源晶振印字上面会标注脚位方向，即在左下角一个点，有点的代表引脚1。按逆时针(管脚向下)通常的用法是：一脚悬空，二脚接地，三脚接输出，四脚接电压。在安装有源晶振时，应当确保正确的脚位方向。如果安装错误，可能会导致晶振无法正常工作，甚至可能被电流击穿\nLED 结构： 发光二极管的核心部分是由P型半导体和N型半导体组成的晶片，在 P 型半导体和 N 型半导体之间有一个过渡层，称为PN结。在有些半导体材料的PN结中，注入的少数载流子与多数载流子复合时会把多余的能量以光的形式释放出来，从而把电能直接转换为光能。 发光原理： 当在LED即两端加上正向电压，电流从LED阳极流向阴极时，半导体晶体就发出从紫外到红外不同颜色的光线。光的强弱与电流有关，电流越大，发的光越强。 一般压降为2V（颜色不同不一样），安全电流20mA，所以一般需要串联一个限流电阻。Led计算器 排针 通常注意与pcb的以下参数对应：\n排针间距：一般为2.54mm 排针类型：圆针/方针 结构：一般为1 x N P，也可以掰开使用 MOS管 mos管的普遍实现为Nmos管，G输出高电平，D、S导通，G输出低电平，D、S关闭。Pmos管反之。\n关注参数：\n封装 Vgsth：打开nmos的GS电压，Vgsth应该小于高电平的电压值 Rdson：mos管被完全打开时的DS电阻值，越小越好，但价格越高、体积越大 Cgs：G、S之间的寄生电容，影响nmos的打开速度，容值大小一般与Rdson成反比 电子设计常用电路 电子设计常用电路\n外围电路 MCU（微控制单元，Microcontroller Unit）是嵌入式系统的\u0026quot;大脑\u0026quot;，但需通过外围电路实现供电、信号输入/ 输出、通信、存储等功能，才能构成完整的工作系统。外围电路的设计直接决定 MCU 的稳定性、功能扩展性和适用场景，入门需先掌握核心电路模块的作用与设计逻辑。\nMCU 与外围电路的关系 MCU 芯片内部集成了 CPU、RAM、ROM（或 Flash）、定时器、ADC 等核心模块，但存在两个关键局限：\n内部资源有限：如 IO 口驱动能力弱（通常仅能驱动 LED、小型传感器，无法直接驱动电机）、无外部供电接口、无远距离通信物理层等； 需外部交互：需接收传感器信号（如温度、按键）、控制外部执行器（如电机、继电器）、与其他设备（如电脑、模块）通信。 外围电路的核心作用：弥补 MCU 内部资源缺陷，搭建\u0026quot;大脑\u0026quot;与外部世界的连接桥梁，保障系统稳定运行。\n必学外围电路模块（按功能分类） 供电电路：MCU 的\u0026quot;能量来源\u0026quot; MCU 无法直接使用 220V 市电或锂电池（3.7V）等非标准电压，需供电电路将外部电压转换为 MCU 的核心工作电压（常见 3.3V 或 5V，需严格匹配芯片手册），同时滤除电压波动，避免 MCU 死机或损坏。\n核心组件与设计逻辑\n组件类型 作用 典型场景 线性稳压器（LDO） 输入电压＞输出电压，输出稳定、纹波小 对电压稳定性要求高的场景（如传感器采集），如 AMS1117-3.3V（输入 4.75-12V，输出 3.3V） DC-DC 转换器 输入电压可高于/ 低于输出电压，效率高 对功耗敏感的场景（如电池供电设备），如 MP1584（输入 4-28V，输出可调至 3.3V） 滤波电容 滤除电源线上的高频噪声，稳定电压 每个稳压器输出端并联 1 个 100nF 陶瓷电容（滤高频）+ 1 个 10μF 电解电容（滤低频） 电源指示灯\n直观判断供电是否正常 串联 1 个 1kΩ限流电阻+LED（电流＜20mA，避免烧毁） 入门注意：\n必须参考 MCU 手册的\u0026quot;供电参数\u0026quot;：如最大输入电压、工作电流，避免过压烧毁； 若系统有大功率模块（如电机），需单独为其设计供电电路，避免电流波动干扰 MCU。 复位电路：让 MCU\u0026quot;重启归零\u0026quot; 复位电路用于在系统上电、死机或异常时，强制 MCU 回到初始状态（类似电脑重启），保障程序正常运行。常见复位方式有上电复位 和手动复位。\n两种复位电路设计\n复位类型 核心组件 工作原理 适用场景 上电复位 电容（10μF）+ 电阻（10kΩ） 上电时电容充电，复位引脚（如 RST）短暂保持高电平，电容充满后变为低电平，MCU 开始运行 系统上电时自动复位，无需手动操作 手动复位 复位按键 + 电阻（10kΩ） 按下按键时，复位引脚接高电平，松开后恢复低电平，触发 MCU 复位 需要手动重启的场景（如程序调试） 入门注意：\n复位引脚电平需匹配 MCU 要求（多数 51 单片机为高电平复位，STM32 部分型号为低电平复位）； 复位时间需足够（通常＞1ms），避免电容/ 电阻参数过小导致复位不彻底。 时钟电路：MCU 的\u0026quot;心跳\u0026quot; MCU 的 CPU、定时器、UART 等模块需依赖 时钟信号 同步工作（类似人的心跳节奏），时钟频率决定 MCU 的运行速度（如 11.0592MHz 时钟下，51 单片机指令执行速度约 1MHz）。常见时钟源有__外部晶振__ （精准）和__内部 RC 振荡器__（便捷）。\n时钟信号 是 MCU 的 \u0026ldquo;电子节拍器\u0026rdquo; \u0026mdash;\u0026mdash; 它定义了 \u0026ldquo;时间单位\u0026rdquo;，让所有模块的动作在 \u0026ldquo;统一时间基准\u0026rdquo; 下有序执行，避免因 \u0026ldquo;动作不同步\u0026rdquo; 导致的功能混乱或错误\n两种时钟电路对比\n时钟类型 核心组件 优点 缺点 适用场景 外部晶振 晶振（如 11.0592MHz）+ 两个电容（22pF） 频率精准、稳定，适合串口通信（需精准波特率） 需额外焊接元件，占 PCB 空间 对时序要求高的场景（如 UART、SPI 通信） 内部 RC 振荡器 MCU 内部集成（无需外部元件） 无需外部元件，设计简单，成本低 频率误差较大（±5%），稳定性差 对精度要求低的场景（如 LED 闪烁） 入门注意：\n晶振频率需在 MCU 支持范围内（如 STM32F103 支持 4-16MHz 晶振）； 晶振与电容需靠近 MCU 时钟引脚（X1、X2），避免引线过长导致信号干扰。 IO 口扩展与驱动电路：连接外部设备 MCU 的 IO 口（输入/ 输出引脚）是与外部设备交互的\u0026quot;接口\u0026quot;，但存在两个核心限制：\n输出驱动能力弱：多数 IO 口最大输出电流仅 20-50mA，无法直接驱动电机、继电器等大功率设备； 输入信号敏感：需处理传感器的弱信号（如光敏电阻）或避免高压信号烧毁 IO 口。 因此需通过__驱动电路__扩展 IO 口能力，常见场景如下：\n典型 IO 口驱动场景\n外部设备 驱动电路设计 原理说明 注意事项 LED 指示灯 IO 口 → 限流电阻（1kΩ）→ LED → GND IO 口输出高电平时，电流通过 LED 发光（电流＜20mA） 电阻不可省略，否则 LED 过流烧毁；LED 正负极不可接反 按键（输入） IO 口 → 上拉电阻（10kΩ）→ VCC；按键另一端接 GND 未按按键时，IO 口通过上拉电阻接高电平；按下时接地，IO 口变为低电平，MCU 检测到按键动作 可使用 MCU 内部上拉电阻（如 STM32 的 PU 模式），减少外部元件 继电器/ 电机 IO 口 → 三极管（如 S8050）→ 继电器/ 电机；续流二极管（保护三极管） IO 口输出高电平驱动三极管导通，继电器/ 电机得电工作；续流二极管吸收电机断电时的反向电动势 三极管需匹配负载电流（如 S8050 最大集电极电流 1.5A）；大功率电机需加 MOS 管 通信接口电路：让 MCU\u0026quot;联网对话\u0026quot; MCU 需通过通信接口与其他设备（如电脑、传感器模块、显示屏）交换数据，常见通信协议有__UART（串口）__ 、I2C 、SPI，不同协议对应不同外围电路。\n三种常用通信接口对比\n通信协议 引脚数量 核心电路设计 特点 典型应用 UART（串口） 2（TX 发送、RX 接收） 电脑端需 USB 转串口模块（如 CH340），MCU 端直接接 TX/RX 异步通信，波特率需一致（如 9600bps），距离短（＜10m） 电脑与 MCU 通信（如程序下载、数据打印） I2C 2（SDA 数据线、SCL 时钟线） 两根线均需接 4.7kΩ上拉电阻到 VCC 同步通信，多主多从（可挂多个设备），距离短（＜1m） 连接传感器（如温湿度传感器 SHT30）、OLED 显示屏 SPI 4（SCK 时钟、MOSI 主发从收、MISO 主收从发、CS 片选） 无需上拉电阻，通过 CS 引脚选择通信设备 同步通信，速度快（＞10Mbps），距离短（＜1m） 连接 Flash 存储芯片（如 W25Q64）、LCD 显示屏 入门注意：\n通信引脚需\u0026quot;交叉连接\u0026quot;：MCU 的 TX 接 USB 转串口模块的 RX，MCU 的 RX 接模块的 TX； I2C 的上拉电阻不可省略，否则信号传输不稳定； SPI 的 CS 引脚需单独控制（同一时刻仅一个设备被选中）。 存储电路：保存数据\u0026quot;不掉电\u0026quot; MCU 内部 Flash/RAM 容量有限（如 51 单片机仅 4KB Flash、128B RAM），需外部存储电路扩展容量，用于保存程序、日志或参数（如设备配置信息）。常见存储芯片有__SPI Flash__ （存程序/ 大文件）和__EEPROM__（存小参数）。\n两种存储电路设计\n存储类型 核心芯片 通信协议 特点 典型应用 SPI Flash W25Q64（64MBit=8MB） SPI 容量大、擦写次数多（＞10 万次）、掉电不丢失 存储固件、图片、日志文件 EEPROM AT24C02（2KB） I2C 容量小、可字节级擦写、掉电不丢失 存储设备参数（如校准值、用户设置） 入门注意：\n存储芯片需通过对应通信协议（SPI/I2C）与 MCU 连接，程序中需调用相应驱动函数； EEPROM 擦写次数有限（通常 100 万次），避免频繁写入同一地址。 入门实践建议 从最小系统开始：先搭建 MCU 的\u0026quot;最小系统\u0026quot;（供电+ 复位+ 时钟），确保 MCU 能正常上电运行（如点亮一个 LED），再逐步扩展其他模块； 参考经典电路：新手可直接复用成熟设计（如 51 单片机最小系统、STM32 核心板电路），避免从零设计导致错误； 重视 datasheet：所有外围电路参数（如稳压器输入电压、晶振频率）需严格参考 MCU 和元件的 datasheet（芯片手册），这是设计的核心依据； 先仿真后焊接：使用 Proteus、Multisim 等软件仿真电路，验证功能正常后再实际焊接，减少硬件损坏风险。 电源防反接电路 在日常电子设计过程中，经常会使用排针、电池等容易插反的接口进行供电，此时一旦电源接反，会导致短路，通常芯片内部也无法承受反向电流，可能会导致芯片损坏。\n二极管防反接 使用一个二极管串联在电路中，当电源正常接入时，二极管导通,当电源反接时，二极管反向截止，整个系统不会有电流经过，但是此时二极管需要承担整个电路的电流，且自身会有压降，输出电压与实际输入电压会有一个二极管压差，建议综合电路负载电流情况选择不同型号的肖特基二极管。\n自动冷启动电路 自动冷启动电路\n有些MCU只会在冷启动（彻底掉电再启动）的某个阶段才会去检测RXD是否有合法的下载信号，然后下载烧录用户程序（如STC89C52RC）。如果要频繁下载程序，就需要频繁去手动冷启动，所以利用自动冷启动电路实现。\n开源项目 入门（2层板） 嘉立创-USB2.0拓展坞 基于VL813的USB3.0-HUB设计 Exlink最好用的嵌入式多功能调试器 EDA-Robot机器狗 STM32手表教程 进阶（4层板） 四层板PCB设计保姆级教程 3.0集线器 立创·梁山派开发板、立创梁山派4层PCB实战教程 工具 https://www.eetree.cn/tools 电路仿真 CircuitJS 电路分析工具 PCB走线载流计算器 PCB过孔载流计算器 嘉立创阻抗计算神器、Si9000 References 【教程】零基础入门PCB设计 【教程】大师篇-零基础入门PCB设计 Expert电子实验室 eda教程 pcb联盟网 嵌入式硬件知识 ","date":"2025-09-21T00:00:00Z","permalink":"https://loveleaves.github.io/p/embedded_programing_pcb/","title":"【Hardware】硬件设计与选型"},{"content":"References 分布式系统架构设计原理与实战：理解分布式系统的基本概念 https://cloud.tencent.com/developer/article/1905374 https://zhuanlan.zhihu.com/p/375847349 《Designing Data-Intensive Applications》，DDIA，设计数据密集型应用 DDIA解读 一文读懂分布式架构知识体系 背景介绍 分布式系统是指由多个独立的计算机节点组成的系统，这些节点通过网络连接在一起，共同完成某个任务或提供某个服务。分布式系统具有高度的可扩展性、高度的可靠性和高度的性能。因此，分布式系统已经成为现代信息技术的核心技术之一，广泛应用于互联网、大数据、人工智能等领域。\n然而，分布式系统也面临着很多挑战，如数据一致性、故障容错、负载均衡等。为了解决这些问题，需要深入理解分布式系统的基本概念和原理，并学习和掌握一些高级的分布式算法和技术。\n分布式系统的发展历程 分布式系统的发展历程可以分为以下几个阶段：\n基于消息传递的分布式系统（1970年代） 基于文件系统的分布式系统（1980年代） 基于Web的分布式系统（1990年代） 基于服务的分布式系统（2000年代） 基于云计算的分布式系统（2010年代至今） 每个阶段都有其特点和代表性的系统，如：\n基于消息传递的分布式系统：例如，ACTORS模型的系统。 基于文件系统的分布式系统：例如，Andrew文件系统。 基于Web的分布式系统：例如，Amazon的电子商务系统。 基于服务的分布式系统：例如，微软的.NET框架。 基于云计算的分布式系统：例如，阿里云、腾讯云、华为云等公有云服务。 分布式系统的特点 分布式系统具有以下特点：\n分布式性：节点分布在不同的计算机上，通过网络连接在一起。 并发性：多个节点可以同时执行任务，实现并行处理。 异步性：节点之间的通信可能存在延迟，需要处理异步问题。 故障性：单个节点的故障不会导致整个系统的宕机。 扩展性：通过增加节点，可以实现系统的扩展。 数据一致性：在分布式环境下，多个节点共享和修改同一份数据，需要保证数据的一致性。 分布式系统的分类 分布式系统可以分为以下几类：\n同步分布式系统：所有节点需要同时执行任务，实现并行处理。 异步分布式系统：节点之间可以自由地发送和接收消息，不需要同步。 有状态分布式系统：节点之间可以共享和修改状态信息，实现状态同步。 无状态分布式系统：节点之间不共享状态信息，实现无状态处理。 集中式分布式系统：有一个中心节点负责协调和管理其他节点，实现集中式控制。 去中心化分布式系统：没有中心节点，所有节点相互交互，实现去中心化管理。 核心概念与联系 在分布式系统中，有一些核心概念需要理解，如：\n节点（Node）：分布式系统中的基本组成单元。 网络（Network）：节点之间的连接。 通信（Communication）：节点之间的数据交换。 一致性（Consistency）：多个节点共享和修改同一份数据时，数据的一致性。 故障容错（Fault Tolerance）：单个节点故障不会导致整个系统宕机。 负载均衡（Load Balancing）：多个节点共同处理任务，实现资源利用率的均衡。 这些概念之间存在一定的联系，如：\n节点通过网络进行通信，实现任务的分布和协同。 通信是实现一致性和故障容错的关键。 负载均衡是实现系统性能和扩展的关键。 核心算法原理和实现流程 在分布式系统中，有一些核心算法需要理解，如：\n一致性算法：例如，Paxos、Raft等。 故障容错算法：例如，Chubby、ZooKeeper等。 负载均衡算法：例如，Round-robin、Least-connections、Random等。 一致性算法 一致性算法是用于实现数据一致性的算法，主要解决了分布式系统中多个节点共享和修改同一份数据时的一致性问题。\nPaxos算法 Paxos算法是一种一致性算法，可以在不需要时间顺序一致性的前提下，实现强一致性。Paxos算法的核心思想是通过多轮投票和选举来实现节点之间的协同。\nPaxos算法的主要组成部分包括：\n提案者（Proposer）：提出一个值进行决定。 接受者（Acceptor）：接受提案者的提案，并进行投票。 决策者（Learner）：收到多数接受者的支持，进行决策。 Paxos算法的具体操作步骤如下：\n提案者随机选择一个数字值，并向所有接受者发送提案。 接受者收到提案后，如果当前没有多数接受者支持其他提案，则支持当前提案，并向提案者报告支持情况。 提案者收到多数接受者的支持后，向决策者发送决策请求。 决策者收到多数接受者的支持后，进行决策，并向所有节点广播决策结果。 Raft算法 Raft算法是一种一致性算法，可以在有限的时间内实现强一致性。Raft算法的核心思想是通过选举来实现领导者的选举和数据复制。\nRaft算法的主要组成部分包括：\n领导者（Leader）：负责接收客户端请求，并向其他节点复制数据。 追随者（Follower）：等待选举，如果成为领导者，则向其他节点复制数据。 候选者（Candidate）：尝试成为领导者，通过选举来实现。 Raft算法的具体操作步骤如下：\n每个节点随机选择一个领导者标识，并向其他节点发送请求加入集群。 其他节点收到请求后，如果当前领导者已经存在，则将请求丢弃；如果当前领导者不存在，则将当前节点设置为候选者状态，并向其 节点发送自己为候选者的请求。 候选者收到多数节点的支持后，成为领导者，并向其他节点发送心跳消息。 追随者收到领导者的心跳消息后，更新自己的领导者标识，并设置为追随者状态。 客户端向领导者发送请求，领导者将请求广播给其他节点，并将数据复制到其他节点。 数学模型公式 Paxos和Raft算法的数学模型公式如下：\nPaxos算法： $$ n=3f+1n = 3f + 1n=3f+1 $$ 其中，n是节点数量，f是故障节点数量。\nRaft算法： $$ n=3fn = 3fn=3f $$ 其中，n是节点数量，f是故障节点数量。\n故障容错算法 故障容错算法是用于实现故障容错的算法，主要解决了分布式系统中单个节点故障不会导致整个系统宕机的问题。\nChubby算法 Chubby算法是一种故障容错算法，可以实现分布式系统中的共享锁和文件系统。Chubby算法的核心思想是通过集中式控制来实现故障容错。\nChubby算法的主要组成部分包括：\n主服务器（Master Server）：负责管理所有节点的状态。 备份服务器（Backup Server）：负责备份主服务器的状态。 客户端（Client）：与主服务器和备份服务器进行通信。 Chubby算法的具体操作步骤如下：\n客户端向主服务器发送请求，主服务器处理请求并返回结果。 主服务器在处理请求时，可以将请求委托给备份服务器处理。 主服务器和备份服务器之间通过心跳消息来实现故障检测和故障转移。 ZooKeeper算法 ZooKeeper算法是一种故障容错算法，可以实现分布式系统中的配置管理和集群管理。ZooKeeper算法的核心思想是通过多个服务器实现故障容错，并通过主备模式来实现高可用。\nZooKeeper算法的主要组成部分包括：\n主服务器（Leader）：负责处理客户端请求。 备份服务器（Follower）：负责备份主服务器的状态。 客户端（Client）：与主服务器和备份服务器进行通信。 ZooKeeper算法的具体操作步骤如下：\n客户端向主服务器发送请求，主服务器处理请求并返回结果。 主服务器在处理请求时，可以将请求委托给备份服务器处理。 主服务器和备份服务器之间通过心跳消息来实现故障检测和故障转移。 数学模型公式 Chubby和ZooKeeper算法的数学模型公式如下：\nChubby算法： $$ n=3fn = 3fn=3f $$ 其中，n是节点数量，f是故障节点数量。\nZooKeeper算法： $$ n=2f+1n = 2f + 1n=2f+1 $$ 其中，n是节点数量，f是故障节点数量。\n负载均衡算法 负载均衡算法是用于实现系统性能和扩展的算法，主要解决了分布式系统中多个节点共同处理任务的问题。\nRound-robin算法 Round-robin算法是一种负载均衡算法，可以实现基于轮询的请求分发。Round-robin算法的核心思想是将请求按顺序分发给节点。\nRound-robin算法的具体操作步骤如下：\n创建一个请求队列，将所有请求加入队列。 从队列中取出第一个请求，将其分发给第一个节点处理。 将请求队列中的下一个请求分发给第二个节点处理。 重复步骤2和3，直到队列中的所有请求都被处理。 Least-connections算法 Least-connections算法是一种负载均衡算法，可以实现基于最少连接数的请求分发。Least-connections算法的核心思想是将请求分发给连接数最少的节点。\nLeast-connections算法的具体操作步骤如下：\n创建一个节点状态表，记录每个节点的连接数。 从节点状态表中选择连接数最少的节点，将请求分发给该节点处理。 处理完请求后，更新节点状态表。 Random算法 Random算法是一种负载均衡算法，可以实现基于随机选择的请求分发。Random算法的核心思想是将请求随机分发给节点。\nRandom算法的具体操作步骤如下：\n创建一个请求队列，将所有请求加入队列。 从队列中随机选择一个请求，将其分发给一个节点处理。 重复步骤2，直到队列中的所有请求都被处理。 ","date":"2025-03-22T00:00:00Z","permalink":"https://loveleaves.github.io/p/distributed_system/","title":"【SE】 分布式系统架构设计"},{"content":"总结 个人总结，带有偏见，仅作参考\n事物的两面性：一件事从正反面甚至不同方面去思考，思考过程可以理性/感性，站在不同视角不受约束地为己方辩护，最后总结不要带有倾向性。 贴标签/去标签：给人或物贴标签，易于利用已有经验，但也会忽略关键细节。 利己性：根据自己（自发/他人诱发）的目的，调整自己的思想价值观念和行为，使其利于达成自己的目的。 行为复杂性：某一想法无法实现理论设想的行为，因为需要外物去执行，会因外物的利己性导致偏差，甚至替换原有想法。 思维超脱/物理现实 思维超脱：思维目的优先，结合现实手段进行实现，需要超理性 物理现实：物理需求优先，思维为超越生物欲望额外需求，借助理性获得物质，感性驱动 游戏 黑神话-悟空：反抗权威/命运，正义（胜利者）/邪恶（失败者） 因与果：整体目标/个体意义，潜意识 电影 夜行动物：遗传利弊（原生家庭/后天人格等）、价值观念差异、情感/理性 肖申克的救赎：改变的决心/毅力 盗梦空间：梦/心理暗示/潜意识 书籍 动漫 英雄联盟：双城之战：情感（什么是亲情/友情/爱情）、保守/革新 快乐时刻 人生不止眼前和远方的苟且，还有当下多巴胺的快乐。\n定期花点时间做点自己真正喜欢的事，不管其是否有意义 多接触新的人或事，了解年轻人的想法，保持年轻的心态 超脱时刻 人生不因止于生物欲望的满足，人类社会债务等的约束，也因思考超脱于人类社会以外的意义\n不要让物质欲望的追求成为囚禁自己牢笼，成为其他尝试的枷锁 思维的锻炼不能停止，追求超理性，利用感性=》理性思考=》移除感性 ","date":"2025-03-15T00:00:00Z","permalink":"https://loveleaves.github.io/p/life/","title":"记录一些可能对个人思考有用的东西"},{"content":"References https://segmentfault.com/a/1190000045332157 《实现领域驱动设计》 DDD分层架构：有效降低层与层之间的依赖 MVC和DDD的对比 实战一（上）：业务开发常用的基于贫血模型的MVC架构违背OOP吗？ https://zhuanlan.zhihu.com/p/343388831 https://zhuanlan.zhihu.com/p/342826364 DDD分层架构 分层架构的基本原则 每层只与位于其下方的层发生耦合。\n分层架构的分类 严格分层架构(Strict Layers Architecture) 某层只能与其直接下层耦合，即我的奴隶的奴隶，不是我的奴隶。 松散分层架构(Relaxed Layers Architecture) 允许任意上层与任意下层耦合。由于用户接口层和应用服务通常需要与基础设施打交道，许多系统都是该架构。 较低层有时也可与较高层耦合，但只限于采用观察者 (Observer)模式或者调停者(Mediator)模式场景。 较低层绝不能直接访问较高层。例如，在使用调停者模式时，较高层可能实现了较低层的接口，然后将实现对象作为参数传递到较低层。当较低层调用该实现时， 它并不知道实现出自何处。\n分层架构演进 传统四层架构 将领域模型和业务逻辑分离出来，并减少对基础设施、用户界面甚至应用层逻辑的依赖，因为它们不属业务逻辑。将一个夏杂的系统分为不同的层，每层都应该具有良好的内聚性，并且只依赖于比其自身更低的层。\n传统分层架构的基础设施层位于底层，持久化和消息机制便位于该层。 这里的消息包含\nMQ消息 SMTP 文本消息(SMS) 可将基础设施层中所有组件看作应用程序的低层服务，较高层与该层发生耦合以复用技术基础设施。即便如此，依然应避免核心的领域模型对象与基础设施层直接耦合。\n改良版四层架构 传统架构的缺陷\nDDD初创开发团队发现，将基础设施层放在最底层存在缺点，比如此时领域层中的一些技术实现就很困难：\n违背分层架构的基本原则 难以编写测试用例 何解？ 使用依赖反转设计原则：低层服务（如基础设施层）应依赖高层组件（比如用户界面层、应用层和领域层）所提供的接口。\n应用依赖反转原则\n依赖反转原则后的分层方式：基础设施层在最上方，可实现所有其他层中定义的接口 依赖反转原则真的可以支持所有层吗？ 有人认为依赖反转原则中只存在两层：最上方和最下方，上层实现下层定义的抽象接口。因此上图的基础设施层将位于最上方，而用户接口层、应用层和领域层应作同层且都位于下方。对此大家可保留自己意见。\n各层职责 用户接口层 一般包括用户接口、Web 服务等。\n只处理用户显示和用户请求，不应包含领域或业务逻辑。 有人认为，既然用户接口需验证用户输入，就无可避免应该包含业务逻辑。事实上，用户接口所进行的验证和对领域模型的验证不同：对那些粗制滥造且只面向领域模型的验证行为，应该予以限制。\n如果用户接口使用了领域模型中的对象，那么此时领域对象仅限于数据渲染展现。在采用这种方式时，可使用展现模型对用户接口与领域对象进行解耦。\n由于用户可能是人，也可能是其他系统，有时用户接口层将采用开放主机服务的方式向外提供API。用户接口层是应用层的直接用户。\n用户接口层在于前后端调用的适配。若你的微服务要提供服务给很多外部应用，而对每个外部应用的入参出参都不同，你不可能开发一堆一对一的应用服务，这时Facade接口就起到了很好的作用，包括DO和DTO对象的组装和转换。\n应用层 主要包含应用服务，理论上不应有业务规则或逻辑，而主要是面向用例和流程相关的操作。\n应用层位于领域层之上，因为领域层包含多个聚合，所以它可协调多个聚合服务和领域对象完成服务编排和组合，协作完成业务。 应用层也是微服务间的交互通道，它可调用其它微服务，完成微服务间的服务组合和编排。 开发设计时，不要将本该放在领域层的业务逻辑放到应用层。因为庞大的应用层会使领域模型失焦，时间一长，微服务就会退化为MVC架构，导致业务逻辑混乱。\n应用服务是在应用层，负责\n服务的组合、编排、转发、转换和传递，处理业务用例的执行顺序以及结果的拼装，以粗粒度服务通过API网关发布到前端 安全认证 权限校验 事务控制 发送或订阅领域事件 领域层 主要包含聚合根、实体、值对象、领域服务等领域模型中的领域对象。\n实现核心业务逻辑，通过各种校验保证业务正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念、业务状态和业务规则。\n领域模型的业务逻辑主要由实体和领域服务实现：\n实体采用充血模型 实现所有与之相关的业务功能。 实体和领域服务在实现业务逻辑上不是同级，当领域中的某些功能，单一实体或值对象无法实现，就会用到领域服务，它可组合聚合内的多个实体或值对象，实现复杂业务逻辑。\n基础层 为其它各层提供通用技术基础服务：\n三方工具 驱动 MQ API网关 文件 缓存 DB 最常用的 基础层包含基础服务，它采用依赖反转，封装基础资源服务，实现应用层、领域层与基础层解耦。\nMVC架构由于上层应用对DB强耦合，很多公司在架构演进最怕换DB，一旦更换，可能需重写一堆代码。 但采用依赖反转，应用层即可通过解耦保持独立核心业务逻辑。当DB变更，只需更换DB基础服务。\n微服务架构演进 领域模型中对象的层次从内到外依次是：值对象、实体、聚合和限界上下文。\n实体或值对象的简单变更，一般不会让领域模型和微服务发生大变。但聚合的重组或拆分却可以。因为聚合内业务功能内聚，能独立完成特定业务。那聚合的重组或拆分，势必引起业务模块和系统功能变化。\n可以聚合为基础单元，完成领域模型和微服务架构的演进。 聚合可作为整体，在不同领域模型间重组或拆分，或直接将一个聚合独立为微服务。\n微服务架构的演进案例 现有\n微服务 1：包含聚合 a、b、c 微服务2： 微服务3：包含聚合 d、e、f 当发现微服务1中聚合a的功能经常被高频访问，以致拖累了整个微服务1的性能，可把聚合a，从微服务1中剥离，独立为微服务2以应对高性能场景\n随业务发展，发现微服务3的领域模型变化，聚合d会更适合放到微服务1的领域模型。即可将聚合d整体迁移到微服务1。注意定义好聚合间的代码边界\n架构演进后，微服务1从最初包含聚合a、b、c，演进为包含聚合b、c、d的新领域模型和微服务\n可见，好的聚合和代码模型的边界设计，可让你快速应对业务变化，轻松实现领域模型和微服务架构演进。\n微服务内服务的演进 在微服务内部，实体的方法被领域服务组合和封装，领域服务又被应用服务组合和封装。在服务逐层组合和封装的过程中，你会发现这样一个有趣的现象。 服务设计时，你并不一定能完整预测有哪些下层服务会被多少个上层服务组装，因此领域层通常只提供一些原子服务，比如领域服务a、b、c。但随系统功能增强和外部接入越来越多，应用服务不断丰富。终有一日，你会发现领域服务b和c同时多次被多个应用服务调用了，执行顺序也基本一致。这时你可以考虑将b和c合并，再将应用服务中b、c的功能下沉到领域层，演进为新的领域服务（b+c）。这样既减少了服务的数量，也减轻了上层服务组合和编排的复杂度。\n这就是服务演进，领域模型会越来越能适应需求快速变化。\n从MVC跨越到DDD 由于层间松耦合，可专注本层设计，而不必关心其它层，也不必担心自己的设计会影响其它层。即DDD成功降低层与层之间的依赖。\n分层架构使得程序结构更清晰，升级和维护更容易。修改某层代码时，只要本层接口参数不变，其它层不必修改。即使本层接口发生变化，也只影响相邻的上层，修改工作量小且可控。\n传统企业应用大多是单体架构，而单体架构则大多是三层架构。三层架构解决了程序内代码间调用复杂、代码职责不清的问题，但这种分层是逻辑概念，在物理上它是中心化的集中式架构，并不适合分布式微服务架构。\nDDD分层要类似三层架构，只是在DDD中，这些要素被重新划分了层，确定了层与层之间的交互规则和职责边界。 DDD分层架构相比MVC（只有API）在用户接口层新增了DTO，给前端提供了更多的可使用数据和更高的展示灵活性。\nDDD分层架构对三层架构的业务逻辑层进行了更清晰的划分，改善了三层架构核心业务逻辑混乱，代码改动相互影响大的情况。\nMVC架构向DDD分层架构演进，主要发生在业务逻辑层和数据访问层。 DDD分层架构将业务逻辑层的服务拆分到了应用层和领域层：\n应用层快速响应前端的变化 领域层实现领域模型的能力 数据访问层和基础层之间：\n三层架构数据访问采用DAO方式 DDD分层架构的数据库等基础资源访问，采用了仓储（Repository）设计模式，通过依赖倒置实现各层对基础资源的解耦。 仓储本身属基础层，但考虑到一个聚合对应一个仓储，为了以后聚合代码整体迁移方便，在微服务代码目录设计时，在聚合目录下增加一个Repository的仓储目录，跟仓储相关的代码都在这个目录下。 这个目录下的代码与聚合的其它业务代码是分开的。如果未来换数据库，只需将Repository目录下的代码替换。而如果聚合需要整体迁移到其它微服务中去，仓储的代码也会一并迁移。\n仓储又分为两部分：仓储接口和仓储实现。仓储接口放在领域层中，仓储实现放在基础层。原来三层架构通用的第三方工具包、驱动、Common、Utility、Config等通用的公共的资源类统一放到了基础层。\nMVC 到 DDD 具体操作如下：\n抽象数据存储层 一般将Data Access层做抽象，降低系统对DB的直接依赖。 举个例子：\n新建Account实体对象：一个实体（Entity）是拥有ID的域对象，除了拥有数据之外，同时拥有行为。Entity和数据库储存格式无关。 对象储存接口类AccountRepository：Repository只负责Entity对象的存储和读取，而Repository的实现类完成数据库存储的细节。通过加入Repository接口，底层数据库连接可以通过不同的实现类而替换。\n","date":"2025-03-10T00:00:00Z","permalink":"https://loveleaves.github.io/p/se_ddd/","title":"【SE】 DDD领域驱动设计实战-分层架构"},{"content":"References https://segmentfault.com/a/1190000045395117 消息中间件优缺点对比及选型 概念 什么是中间件？ 非底层操作系统软件，非业务应用软件，不是直接给最终用户使用的，不能直接给客户带来价值的软件统称为中间件。\n什么是消息中间件？ 关注于数据的发送和接受，利用高效可靠的异步消息传递机制集成分布式系统。\n消息中间件的作用（解耦，并发，削峰，异步） 可以在模块、服务、接口等不同粒度上实现解耦 订阅/消费模式可以在数据粒度上解耦 可提高系统的并发能力，集中力量办大事（同步部分），碎片时间做小时（异步部分） 可提高系统可用性，因为缓冲了系统负载 消息中间件的弊端 系统可用性降低：MQ宕机之后整套系统均不能正常使用，如果要保障队列可用，需要额外机制保障（双活或容灾） 系统复杂性提高：存在消息重复消费、消息丢失、消息传递顺序不能保证的问题 降低数据一致性：多个系统消费存在部分成功部分失败的问题，数据不一致了，如要保持强一致性，需要高代价的补偿（分布式事务，对账） 重复消费：系统发了两条，两条都插入了数据库 消息丢失：系统根本没法请求到目标系统 一致性问题：系统要再ABC三个系统都执行成功之后才返回成功，结果AB成功了，C失败了\n什么是消息队列?（Message queue，简称MQ） 从字面理解就是一个保存消息的一个容器。那么我们为何需要这样一个容器呢？\n其实就是为了解耦各个系统，我们来举个例子： 有这么一个简单的场景，系统A负责生成userID，并调用系统B、C。如果系统BC频繁变化是否需要userID参数，则系统A的代码就得不断变化，如果哪天又来了系统DEF……也需要这个参数，则系统A又要加入很多业务逻辑，这样子各他系统之间就容易产生相互影响，另外大量的系统与A发生交互也容易产生问题。 加了消息队列后，A只负责产生userID，至于谁要用这个参数，怎么用？系统A不管。对这个数据感兴趣的系统自己去取用即可，各个系统之间就实现了解耦。而且解耦后，整个服务业变成了一个异步的方式，系统A产生数据后，不用依次调用BCD来累计耗时，各系统可以同时来取用消息队列的数据进行处理，加大吞吐。\n消息队列的特点 先进先出：消息队列的顺序在入队的时候就基本已经确定了，一般是不需人工干预的。 发布订阅：发布订阅是一种很高效的处理方式，如果不发生阻塞，基本可以当成是同步操作。 持久化：持久化确保消息队列的使用不只是一个部分场景的辅助工具，而是让消息队列能像数据库一样存储核心的数据。 分布式：在现在大流量、大数据的使用场景下，支持分布式的部署，才能被广泛使用。消息队列的定位就是一个高性能的中间件。 消息队列的使用场景 消息队列的使用场景有很多，最核心的有三个：解耦、异步、削峰\n解耦：一个系统或者一个模块，调用了多个系统或者模块，相互之间的调用很复杂，维护起来很麻烦。此时可以考虑使用消息队列来实现多个系统之间的解耦 异步：系统A接受一个请求，需要在自己本地写库，还需要在系统BCD三个系统写库，同步操作比较费时。 削峰：高峰时段系统接收到的请求缓存到消息队列，供系统根据负载慢慢消化 如秒杀、发邮件、发短信、高并发订单等。 不适合的场景如银行转账、电信开户、第三方支付等。 关键还是要意识到队列的优劣点，然后分析场景是否使用。\n其他使用场景还有：\n最终一致性：先写消息再操作，例如预写日志（Write Ahead Log，WAL） 日志处理：比如 Kafka 的应用，解决海量日志传输和缓冲的问题。 消息通信：消息队列一般都内置了高效的通信机制 MQ的6种工作模式: 简单模式：一个生产者，一个消费者 work模式：一个生产者，多个消费者，每个消费者获取到的消息唯一。 发布/订阅模式（Pub/Sub）：一个生产者发送的消息会被多个消费者获取。 路由模式：发送消息到交换机并且要指定路由key ，消费者将队列绑定到交换机时需要指定路由key topic模式：将路由键和某模式进行匹配，此时队列需要绑定在一个模式上，“#”匹配一个词或多个词，“*”只匹配一个词。 消息队列常见问题 如何保证消息队列的高可用（High Available, HA）？ RabbitMQ基于主从的高可用，分为单机模式、普通集群模式、镜像集群模式三种\n普通集群模式：多台服务器部署RabbitMQ，一个queue只会保存在一个节点上，其他节点只会同步该queue的元数据，当请求从其他节点获取该queue的数据时，该节点会再次去存储该queue的节点上拉取所需数据。这样就导致使用时要么固定使用其中一个节点，要么随机节点再需要的时候拉取数据。如果存放数据的节点宕机了，其他节点就无法拉取数据，如果开启了消息持久化让RabbitMQ落地存储消息就不一定会丢失消息，得等这个实例恢复后才能继续从这个queue拉取数据。 镜像集群模式（高可用模式）：创建的queue会同步到所有实例上来实现高可用。这样会带来同步数据的开销和扩展性降低（扩展机器会导致新增的机器同步queue增加更多同步数据的开销）；配置方式可通过控制台配置。 Kafka的高可用：分布式消息队列 Kafka由多个broker组成，每个broker是一个节点，创建的一个topic划分为多个partition，每个partition可放在不同的broker上，每个partition只存放一部分数据。\n","date":"2025-03-10T00:00:00Z","permalink":"https://loveleaves.github.io/p/se_mq/","title":"【SE】 消息中间件"},{"content":"References https://www.imooc.com/article/361234 https://blog.csdn.net/qq_40610003/article/details/143609078 前言 本文档全面介绍了系统架构师教程，涵盖了角色与职责、所需技能、职业发展路径以及架构设计原则和模式等内容，旨在帮助读者从入门到实践系统架构设计。文章还深入探讨了架构评估与优化策略，并提供了实际案例分析和常用工具介绍，帮助读者全面提升系统架构设计能力。\n介绍 系统架构师（System Architect, SA, SAr）是软件开发团队中的关键角色，负责指导团队进行架构设计和实施。本文档从系统架构师的角色与职责开始，逐步深入到架构设计原则、评估与优化，以及实际案例分析，最后探讨如何通过实践和工具来提升架构设计能力。\nSE和SA区别 系统工程师SE：负责本版本系统分析与设计的所有活动，关注当前版本的所有需求，关注当前版本所有的技术方案，管理SE团队。 架构师SA：负责本产品的架构设计和架构维护，关注影响架构的当前需求和未来需求，关注影响架构的技术方案，负责领域架构在当前版本的落地和产品架构的生命周期管理。 角色与职责 系统架构师的主要职责包括但不限于：\n架构设计：设计系统的整体框架，包括模块划分、组件间关系、数据流等。 技术选型：根据业务需求和技术趋势选择合适的技术栈。 性能优化：确保系统在高并发、大数据量等场景下仍能保持高效运行。 安全性保障：确保系统的安全性，防止数据泄露等安全事件。 团队领导：指导开发团队按照架构设计进行开发，并解决开发过程中遇到的技术难题。 监控与维护：监控系统运行状态，及时发现并解决性能瓶颈等问题。 用户反馈：与用户沟通，收集反馈，并根据用户反馈不断优化架构设计。 需要掌握的技能 系统架构师需要掌握以下技能：\n编程语言：具备至少一种主流编程语言的深厚技术功底，如Java、Python、C#等。 数据结构与算法：深入理解常用的数据结构（如数组、链表、树、图等）和算法（如排序、查找等）。 计算机网络：掌握计算机网络基础知识，如TCP/IP协议、HTTP协议等。 数据库技术：精通至少一种关系型数据库（如MySQL、Oracle）或非关系型数据库（如MongoDB）。 操作系统：熟悉主流的操作系统（如Linux、Windows）和虚拟化技术。 架构设计：理解常用的设计模式（如单例模式、工厂模式等）和架构模式（如微服务、SOA等）。 性能优化：掌握常见的性能优化方法和技术。 安全性：了解常见的安全漏洞和防护方法。 DFX特性：可维可测可靠等。 团队协作：具备良好的团队协作能力和沟通能力。 职业发展路径 系统架构师的职业发展路径通常如下：\n软件工程师：从一个普通的软件工程师开始，逐步积累编程经验。 高级工程师：通过不断学习和实践，成为公司内部的技术专家。 系统架构师：在高级工程师的基础上，进一步提升自己的系统设计能力。 技术总监：成为公司内部的技术决策者，负责整体技术方向和架构设计。 CTO：成为公司的首席技术官，负责公司的技术战略和产品开发。 基础架构知识 架构设计原则与模式 设计模式及其应用 设计模式是面向对象编程中的概念，用于解决特定问题的通用解决方案。常见的设计模式包括单例模式、工厂模式、观察者模式等。\n架构设计基本原则 KISS原则：保持简单，使系统易于理解和维护。 YAGNI原则：避免过度设计，只实现当前需要的功能。 DRY原则：不要重复自己，通过抽象和模块化减少代码冗余。 单一职责原则：每个模块或类只负责一个功能，避免职责混杂。 高内聚、低耦合：模块内部高度紧密，模块间弱耦合。 面向接口编程：通过定义接口来解耦实现细节。 常见架构模式解析 微服务架构：将一个大型系统拆分成多个小型、相互独立的服务，每个服务负责一个特定的功能。 SOA（面向服务的架构）：将系统组件抽象为服务，通过服务间的通信实现业务流程。 事件驱动架构：通过事件触发系统组件的响应，适用于异步处理场景。 架构设计中的常见问题及解决方案 问题1：单点故障\n解决方案：通过冗余设计和故障转移机制来解决单点故障问题。 问题2：性能瓶颈\n解决方案：通过性能测试找出性能瓶颈，并通过缓存、负载均衡等方式进行优化。 问题3：安全性问题\n解决方案：通过输入验证、权限管理和加密传输等方式来提高系统安全性。 架构评估与优化 架构性能评估方法 性能测试：使用工具（如JMeter、LoadRunner）模拟不同负载下的系统性能。 代码审查：检查代码中是否存在潜在的性能瓶颈。 监控与日志：通过监控系统运行状态和分析日志来发现性能问题。 架构安全性与可靠性考虑 安全性考虑：\n输入验证：确保所有输入都经过验证，防止SQL注入、跨站脚本攻击等。 权限管理：确保用户只能访问其权限范围内的资源。 加密传输：使用SSL/TLS协议加密传输数据，防止数据被窃听。 可靠性考虑：\n冗余设计：通过冗余设计提高系统的可用性，如使用多副本存储数据。 故障转移：在主服务不可用时自动切换到备用服务。 容错处理：设计系统时考虑可能出现的异常情况，并提供相应的容错机制。 实际案例分析 典型系统架构案例解析 案例1：电商平台\n架构设计：包括用户中心、订单中心、支付中心等模块。 技术选型：使用Spring Boot进行后端开发，React进行前端开发，MySQL和Redis作为数据库和缓存。 案例解析：通过微服务架构将大型系统拆分为多个小型服务，每个服务专注于一个特定功能。 案例2：视频流媒体平台\n架构设计：包括内容分发、视频编码、用户界面等模块。 技术选型：使用Node.js进行后端开发，React Native进行前端开发，MongoDB和Elasticsearch作为数据库。 案例解析：通过事件驱动架构实现异步处理，提高系统响应速度。 架构设计中的常见问题及解决方案 问题1：单点故障\n解决方案：通过冗余设计和故障转移机制来解决单点故障问题。 问题2：性能瓶颈\n解决方案：通过性能测试找出性能瓶颈，并通过缓存、负载均衡等方式进行优化。 问题3：安全性问题\n解决方案：通过输入验证、权限管理和加密传输等方式来提高系统安全性。 架构优化路径 电商平台\n通过引入缓存机制来减少数据库查询压力。 使用负载均衡来提高系统响应速度。 通过事件驱动架构实现异步处理，减少阻塞等待时间。 视频流媒体平台\n通过使用CDN来提高内容分发速度。 通过使用容器化部署来提高系统的灵活性和可扩展性。 通过引入机器学习算法来优化视频编码效率。 实践与工具 常用架构设计工具介绍 架构设计工具：\nVisio：Microsoft提供的架构设计工具，支持多种图形设计。 Archimate：支持架构建模语言，能够进行企业架构设计。 Lucidchart：在线协作绘图工具，支持架构设计和流程图绘制。 架构设计的实践步骤 实践步骤：\n需求分析：与业务团队沟通，明确业务需求。 技术选型：根据业务需求和技术趋势选择合适的技术栈。 架构设计：设计系统的整体框架，包括模块划分、组件间关系等。 系统实现：根据架构设计进行系统实现。 测试与部署：进行性能测试、安全测试等，确保系统满足要求。 运维监控：监控系统运行状态，不断优化架构设计。 如何构建个人架构设计案例集 构建案例集：\n记录设计过程：记录每次架构设计的过程，包括需求分析、技术选型、架构设计等。 总结经验教训：总结每次设计中的经验教训，不断改进自己的设计能力。 分享交流：通过博客、GitHub等渠道分享自己的设计经验，与他人交流学习。 记录设计过程示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 架构设计案例集 ## 案例1：电商平台架构设计 ### 需求分析 - 用户中心：提供用户信息管理功能。 - 订单中心：处理订单创建、支付、发货等业务逻辑。 ### 技术选型 - 后端：Spring Boot - 前端：React - 数据库：MySQL、Redis ### 架构设计 - 微服务架构：将系统拆分为多个小型服务，每个服务专注于一个特定功能。 - 负载均衡：使用Nginx进行负载均衡，提高系统可用性。 ### 测试与部署 - 性能测试：使用JMeter进行性能测试，确保系统满足性能要求。 - 安全测试：进行输入验证、权限管理等，确保系统安全性。 ### 运维监控 - 监控系统运行状态，及时发现并解决性能瓶颈等问题。 - 使用ELK（Elasticsearch、Logstash、Kibana）进行日志监控。 通过以上步骤，你可以构建出一个完整的个人架构设计案例集，记录自己的设计经验和心得，不断提升自己的架构设计能力。\n","date":"2025-03-08T00:00:00Z","permalink":"https://loveleaves.github.io/p/se_intro/","title":"【SE/SA】 系统架构师/系统工程师介绍"},{"content":"References tensorrt docs tensorrt api install tensorrt TensorRT samples Implementation of popular deep learning networks with TensorRT TensorRT推理部署方案 learning-cuda-trt code tensorRT quantization C++硬代码方案 代表：tensorrtx 流程：C++硬代码=》TRT API =》 TRT Builder =》 TRT Engine ONNX方案 流程：ONNX(libnvonnxparser.so) =》TRT API =》 TRT Builder =》 TRT Engine 一般思路： 导出模型onnx，查看输入和输出。 查看代码，找到onnx的预处理，分析预处理逻辑 利用上述信息实现onnx py推理实现 验证正常可实现转TRT模型用C++实现推理 TensorRT库文件 libnvinfer.so：TensorRT核心库 libnvinfer_plugin.so：nvidia官方提供的插件，github libprotobuf.so：protobuf库 libnvonnxparser.so：ONNX解析 TensorRT部署推理模型流程 模型构建 tensorrt的工作流程如下图： 首先定义网络 优化builder参数 通过builder生成engine,用于模型保存、推理等 engine可以通过序列化和逆序列化转化模型数据类型（转化为二进制byte文件，加快传输速率），再进一步推动模型由输入张量到输出张量的推理。 code structure 定义 builder, config 和network，其中builder表示所创建的构建器，config表示创建的构建配置（指定TensorRT应该如何优化模型），network为创建的网络定义。 输入，模型结构和输出的基本信息（如下图所示） 生成engine模型文件 序列化模型文件并存储 模型推理 执行推理的步骤：\n准备模型并加载\n创建runtime：createInferRuntime(logger)\n使用运行时时，以下步骤：\n反序列化创建engine, 得为engine提供数据：runtime-\u0026gt;deserializeCudaEngine(modelData, modelSize),其中modelData包含的是input和output的名字，形状，大小和数据类型\n1 2 3 4 5 6 class ModelData(object): INPUT_NAME = \u0026#34;data\u0026#34; INPUT_SHAPE = (1, 1, 28, 28) // [B, C, H, W] OUTPUT_NAME = \u0026#34;prob\u0026#34; OUTPUT_SIZE = 10 DTYPE = trt.float32 从engine创建执行上下文:engine-\u0026gt;createExecutionContext()\n创建CUDA流cudaStreamCreate(\u0026amp;stream)：\nCUDA编程流是组织异步工作的一种方式，创建流来确定batch推理的独立 为每个独立batch使用IExecutionContext(3.2中已经创建了)，并为每个独立批次使用cudaStreamCreate创建CUDA流。 数据准备：\n在host上声明input数据和output数组大小，搬运到gpu上 要执行inference，必须用一个指针数组指定input和output在gpu中的指针。 推理并将output搬运回CPU 启动所有工作后，与所有流同步以等待结果:cudaStreamSynchronize\n按照与创建相反的顺序释放内存\n重要接口使用说明：\nTR10中的节点索引变更为字符串，之前是数值 必须使用createNetworkV2,并指定为1（表示显性batch）。createNetwork已经废弃，非显性batch官方不推荐。这个方式直接影响推理时enqueue还是enqueueV2（TR10为V3） builder、config等指针，记得释放，否则会有内存泄漏，使用ptr-\u0026gt;destroy()（TR10使用delete）释放 markOutput表示是该模型的输出节点，mark几次，就有几个输出，addlnput几次就有几个输入。这与推理时相呼应 workspaceSize是工作空间大小，某些layer需要使用额外存储时，不会自己分配空间，而是为了内存复用，直接找tensorRT要workspace空间。 bindings是tensorRT对输入输出张量的描述，bindings = input-tensor + output-tensor。比如input有a, output有b,c, d,那么bindings = [a, b, c, d],bindings[0] = a, bindings[2] = c。此时看到engine- \u0026gt;getBindingDimensions(0)你得知道获取的是什么（TRT10改成了IOTensors） enqueueV2是异步推理，加入到stream队列等待执行。输入的bindings则是tensors的指针（注意是device pointer）。其shape对应于编译时指定的输入输出的shape(这里只演示全部shape静态)（TRT10使用enqueueV3） 动态shape 构建网络时：\n1.1. 必须在模型定义时，输入维度给定为-1，否则该维度不会动态。注意一下两点： 1.1.1. 若onnx文件，则onnx文件打开后应该看到为动态或者-1 1.1.2. 如果你的模型中存在reshape类操作，那么reshape的参数必须随动态进行计算。而大部分时候这都是问题。除非你是全卷积模型，否则大部分时候只需要为batch_size维度设置为动态，其他维度尽量避免设置动态 1.2. 配置profile: 1.2.1. create: builder-\u0026gt;createOptimizationProfile() 1.2.2. set: setDimensions()设置kMIN, kOPT, kMAX的一系列输入尺寸范围 1.2.3. add:config-\u0026gt;addOptimizationProfile(profile);添加profile到网络配置中 推理阶段时：\n2.1. 您需要在选择profile的索引后设置input维度：execution_context-\u0026gt;setBindingDimensions(0, nvinfer1::Dims4(1, 1, 3, 3)); （TR10为setInputShape） 2.1.1. 关于profile索引: 2.1.2. 在运行时，向engine请求绑定维度会返回用于构建网络的相同维度。这意味着，得到的还是动态的维度[-1, in_channel, -1, -1]： 1 2 engine.getBindingDimensions(0) // return [-1, 1, -1, -1] // execution_context-\u0026gt;getTensorShape // TR10接口 获取当前的实际维度，需要查询执行上下文： 1 context.getBindingDimensions(0) // return [3, 1, 3, 3] 检查正确性\n我们通常可以利用pytorch来校验是否发生了错误 ONNX模型操作 代码实战：\npytorch-gen-onnx.py：是之前讲过的从pytorch转换onnx格式的代码。 通过onnx-ml.proto和make-onnx-pb.sh了解onnx的结构 2.1. onnx是基于protobuf来做数据存储和传输,*.proto后缀文件, 其定义是protobuf语法，类似json。 2.2. 对于变量结构、类型等，我们可以参照onnx-ml.proto里面的定义。这个文件有800多行，放心我们只要搞清楚里面的核心部分就行： ModelProto:当加载了一个onnx后，会获得一个ModelProto。它包含一个GraphProto和一些版本，生产者的信息。 GraphProto: 包含了四个repeated数组(可以用来存放N个相同类型的内容，key值为数字序列类型.)。这四个数组分别是node(NodeProto类型)，input(ValueInfoProto类型)，output(ValueInfoProto类型)和initializer(TensorProto类型)； NodeProto: 存node，放了模型中所有的计算节点,语法结构如下： ValueInfoProto: 存input，放了模型的输入节点。存output，放了模型中所有的输出节点； TensorProto: 存initializer，放了模型的所有权重参数 AttributeProto:每个计算节点中还包含了一个AttributeProto数组，用来描述该节点的属性，比如Conv节点或者说卷积层的属性包含group，pad，strides等等； 2.3. 通过protoc编译onnx-ml.proto，产生onnx-ml.pb.cc文件 1 bash make-onnx-pb.sh create-onnx.py 3.1. create-onnx.py直接从构建onnx，不经过任何框架的转换。通过import onnx和onnx.helper提供的make_node，make_graph，make_tensor等等接口我们可以轻易的完成一个ONNX模型的构建。 3.2. 需要完成对node，initializer，input，output，graph，model的填充 3.3. 读懂creat-onnx.py以make_node为例： edit-onnx.py 4.1. 由于protobuf任何支持的语言，我们可以使用[c/c++/python/java/c#等等]实现对onnx文件的读写操作 4.2. 掌握onnx和helper实现对onnx文件的各种编辑和修改 增：一般伴随增加node和tensor 1 2 graph.initializer.append(xxx_tensor) graph.node.insert(0, xxx_node) 删： 1 graph.node.remove(xxx_node) 改： 1 input_node.name = \u0026#39;data\u0026#39; read-onnx.py 5.1 通过graph可以访问参数，数据是以protobuf的格式存储的，因此当中的数值会以bytes的类型保存。需要用np.frombuffer方法还原成类型为float32的ndarray。注意还原出来的ndarray是只读的。 ONNX Parser onnx解析器有两个选项，\nlibnvonnxparser.so或者 onnx-tensorrt parser(源代码)。 使用源代码的目的，是为了更好的进行自定义封装，简化插件开发或者模型编译的过程，更加具有定制化，遇到问题可以调试 onnx-tensorrt parser代码使用：\n什么是onnx: 先看名字：Open Neural Network Exchange(ONNX) 是一个开放的生态系统，使代码不被局限在框架和平台中。 具体一点：onnx可以把你的神经网络模型(PyTroch, TF, Caffe)统统转为标准的ONNX格式(一种protobuf格式)，然后就可在各种平台(云平台, windows, linux)和设备(cpu, gpu, npu)上运行 先看文件gen-onnx.py以pytorch构建的模型为例讲：pytorch模型转onnx格式 构建一个pytorch网络，并声明一个model对象 如果进行推理，将模型设为推理状态：这一点很重要，因为像dropout, batchnorm这样的算子在推理和训练模式下的行为是不同的。 导出为onnx模型：torch.onnx.export() 运行python脚本，生成onnx，在main.cpp中会对其进行解析 1 python gen-onnx.py 运行后的图示： Protobuf则通过onnx-ml.proto编译得到onnx-ml.pb.h和onnx-ml.pb.cc或onnx_ml_pb2.py 然后用onnx-ml.pb.cc和代码来操作onnx模型文件，实现增删改 onnx-ml.proto则是描述onnx文件如何组成的，具有什么结构，他是操作onnx经常参照的东西 再看文件main.cpp讲解如何解析onnx格式 使用onnx解析器：createParser的api在文件NvOnnxParser.h中 在这里使用onnx的结果填充到network中，而手动构建网络则是将输入和算子填入network中，区别如图所示： 导出后，可以使用netron软件进行打开查看:https://github.com/lutzroeder/Netron 除了构建过程的区别，makefile中，库文件也需要加上nvonnxparser： 注意：\nseverity_string 和 log仅是工具函数，无需过分关注 导出TRT模型 为了使用onnx导出网络有三种方式：\n我们使用自带的解析器，libnvonnxparser.so 从源代码编译：onnx-tensorrt，主要protobuf文件： onnx-ml.proto 来源 onnx-operators-ml.proto 来源 利用官方工具trtexec，YOLOv8部署推理案例 Usage: 1 2 3 4 5 /usr/src/tensorrt/bin/trtexec \\ --onnx=yolov8s.onnx \\ --saveEngine=yolov8s.engine \\ --fp16 # or --int8 Plugin 1.如何在pytorch里面导出一个插件 2.插件解析时如何对应，在onnx parser中如何处理 3.插件的creator实现 4.插件的具体实现，继承自IPluginV2DynamicExt 5.插件的序列化与反序列化\n量化 int8量化 对于int8，需要配置setFlag nvinfer1::BuilderFlag::kINT8，并且配置setInt8Calibrator 对于Int8EntropyCalibrator，则需要继承自IInt8EntropyCalibrator2 Int8EntropyCalibrator的作用，是读取并预处理图像数据作为输入 标定的原理，是通过输入标定图像I，使用参数WInt8推理得到输出结果PInt8，然后不断调整WInt8，使得输出PInt8与PFloat32越接近越好 因此标定时通常需要使用一些图像，正常发布时，一般使用100张图左右即可 常用的Calibrator Int8EntropyCalibrator2 熵校准选择张量的比例因子来优化量化张量的信息论内容，通常会抑制分布中的异常值。这是当前推荐的熵校准器。默认情况下，校准发生在图层融合之前。推荐用于基于 CNN 的网络。 Iint8MinMaxCalibrator 该校准器使用激活分布的整个范围来确定比例因子。它似乎更适合NLP任务。默认情况下，校准发生在图层融合之前。推荐用于NVIDIA BERT等网络。 计算机中的float计算量是非常大的，而改成int8后，计算量相比可以提升数倍 对于实际操作时，input[float32], w[int8], bias[float32], output[float32] 步骤如下： input[int8] = to_int8(input[float32]) y[int16] = input[int8] * w[int8] # 此处乘法会由计算机转换为int16，保证精度 output[float32] = to_float32(y[int16]) + bias[float32] 所以整个过程的只是为了减少float32的乘法数量以实现提速 对于to_int8的过程，并不是直接的线性缩放，而是经过KL散度计算最合适的截断点（最大、最小值），进而进行缩放，使得权重的分布尽可能小的被改变 可以参照这个地址：https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf ","date":"2025-03-02T00:00:00Z","permalink":"https://loveleaves.github.io/p/tensorrt_deploy/","title":"【TensorRT】 TensorRT模型部署介绍"},{"content":"References onnx量化推理例子 onnxruntime docs onnxruntime quantization ONNX Runtime Quantization Example, Pre-processing step Overview Quantization in ONNX Runtime refers to 8 bit linear quantization of an ONNX model.\nDuring quantization, the floating point values are mapped to an 8 bit quantization space of the form: val_fp32 = scale * (val_quantized - zero_point)\nscale is a positive real number used to map the floating point numbers to a quantization space. It is calculated as follows:\nFor asymmetric quantization:\n1 scale = (data_range_max - data_range_min) / (quantization_range_max - quantization_range_min) For symmetric quantization:\n1 scale = max(abs(data_range_max), abs(data_range_min)) * 2 / (quantization_range_max - quantization_range_min) zero_point represents zero in the quantization space. It is important that the floating point zero value be exactly representable in quantization space. This is because zero padding is used in many CNNs. If it is not possible to represent 0 uniquely after quantization, it will result in accuracy errors.\nONNX Quantization introduction ONNX Runtime provides python APIs for converting 32-bit floating point model to an 8-bit integer model, a.k.a. quantization. These APIs include pre-processing, dynamic/static quantization, and debugging.\nPre-processing: Pre-processing is to transform a float32 model to prepare it for quantization. The goal of these steps is to improve quantization quality. Dynamic Quantization: Dynamic quantization calculates the quantization parameters (scale and zero point) for activations dynamically. Static Quantization: quantization parameters are calculated in advance (offline) using a calibration data set. Quantization Debugging: Quantization may negatively affect a model’s accuracy. A solution to this problem is to compare the weights and activations tensors of the original computation graph vs those of the quantized one, identify where they differ most, and avoid quantizing these tensors, or choose another quantization/calibration method. Create Float16 and Mixed Precision Models offical web Converting a model to use float16 instead of float32 can decrease the model size (up to half) and improve performance on some GPUs. There may be some accuracy loss, but in many models the new accuracy is acceptable. Tuning data is not needed for float16 conversion, which can make it preferable to quantization.\nORT model format The ORT format is the format supported by reduced size ONNX Runtime builds. Reduced size builds may be more appropriate for use in size-constrained environments such as mobile and web applications.\nBoth ORT format models and ONNX models are supported by a full ONNX Runtime build.\nONNX onnx tutorial ONNX文件介绍 1、.ONNX的本质，是一种Protobuf格式文件 2、Protobuf则通过onnx-ml.proto编译得到onnx-ml.pb.h和onnx-ml.pb.cc或onnx_ml_pb2.py 3、然后用onnx—ml.pb.cc和代码来操作onnx模型文件，实现增删改 4、onnx—ml.proto则是描述onnx文件如何组成的，具有什么结构，他是操作onnx经常参照的东西 details、concepts ONNX结构 model：表示整个onnx的模型，包含图结构和解析器格式、opset版本、导出程序类型model.graph：表示图结构，通常是我们netron看到的主要结构 model.graph.node:表示图中的所有节点，数组，例如conv、bn等节点就是在这里的，通过input、output 表示节点之间的连接关系 model.graph.initializer:权重类的数据大都储存在这里 model.graph.input：整个模型的输入储存在这里，表明哪个节点是输入节点，shape是多少model.graph.output：整个模型的输出储存在这里，表明哪个节点是输出节点，shape是多少 对于anchorgrid类的常量数据，通常会储存在model.graph.node中，并指定类型为Constant,该类型节点在 netron中可视化时不会显示出来 onnx文件及其结构、正确导出onnx、onnx读取、onnx创建、onnx修改、onnx解析器 ONNX文件操作 code 1.ONNX的主要结构：graph、graph.node、graph.initializer、graph.input、graph.output 2.ONNX的节点构建方式：onnx.helper,各种make函数 3.ONNX的proto文件：onnx-proto2 4.理解模型结构的储存、权重的储存、常量的储存、netron的解读对应到代码中的部分 ONNX模型文件正确导出 自pytorch2.5以后，onnx的导出有两个版本exporter实现：export_simple_model_to_onnx_tutorial\ntorch.onnx.export 对于任何用到shape、size返回值的参数时，例如：tensor.view(tensor.size(0),-1)这类操作，避免直接使用tensor.size的返回值，而是加上int转换，tensor.view(int(tensor.size(0),-1),断开跟踪 对于nn.Upsample或nn.functional.interpolate函数，使用scale_factor指定倍率，而不是使用size参数指定大小 对于reshape、view操作时，—1的指定请放到batch维度。其他维度可以计算出来即可。batch维度禁止指定为大于-1的明确数字 torch.onnx.export指定dynamic_axes参数，并且只指定batch维度，禁止其他动态 使用opset_version=11,不要低于11 避免使用inplace操作，例如y[·,0:2]=y[·,0:2]*2-0.5 尽量少的出现5个维度，例如ShuffleNet Module，可以考虑合并wh避免出现5维 尽量把让后处理部分在onnx模型中实现，降低后处理复杂度 掌握了这些，就可以保证后面各种情况的顺利了 这些做法的必要性体现在，简化过程的复杂度，去掉gather、shape类的节点，很多时候，部分不这么改看似也是可以但是需求复杂后，依旧存在各类问题。按照说的这么修改，基本总能成。做了这些，就不需要使用onnx—simplifer了\n以上导出方法在导出自定义算子后，如果要在onnxruntime导入使用，首先需要再定义onnxruntime算子\ntorch.onnx.export(\u0026hellip;, dynamo=True) using torch.export and Torch FX to capture the graph. It was released with PyTorch 2.5 1 2 3 4 5 6 7 8 9 10 # Export the ONNX model onnx_program = torch.onnx.export(torch_model, example_inputs, dynamo=True) # Optimize the ONNX model # The ONNX model can be optimized with constant folding, and elimination of redundant nodes. onnx_program.optimize() # Save the ONNX model onnx_program.save(\u0026#34;demo.onnx\u0026#34;) # Check the ONNX model onnx_model = onnx.load(\u0026#34;deom.onnx\u0026#34;) onnx.checker.check_model(onnx_model) Example Simple Example The example has three parts:\nPre-processing Quantization Debugging YOLOv8 code Static Quantization ","date":"2025-02-20T00:00:00Z","permalink":"https://loveleaves.github.io/p/onnx_quantization/","title":"【ONNX量化】 ONNX量化推理介绍"},{"content":"计算机体系结构 存储器层次结构设计 分层思想/模型：分层解构，更好地理解，分工明确，可维护性高。 缓存（Cache） 特点\n硬件上：成本高但性能好 使用上：部分内容会被重复利用 应用场景：CPU 性能和Cache Line 算法的六种思想 https://www.cnblogs.com/zhaojinhui/p/18264853\n递归算法(Recursive Algorithm) 递归算法是一种自我调用的算法。\n在解决问题时，它将问题拆分成更小的子问题，并通过调用自己来解决这些子问题。每个子问题又可以进一步拆分，直到达到基本情况，然后逐层返回结果，最终得到整个问题的解决方案。 贪心算法(Greedy Algorithm) 贪心算法是一种通过在每一步选择当前最优解来解决问题的策略。\n它不考虑全局最优解，而是希望通过每次选择局部最优解来达到整体最优解。 分治算法 (Divide and ConquerAlgorithm) 分治算法是一种将复杂问题划分为更小的独立子问题，并对这些子问题进行解决的策略。\n它将问题分解为多个部分，然后对每个部分进行处理，最后将它们合并成最终的解决方案。 回溯算法(Backtracking Algorithm) 回溯算法是一种通过不断尝试所有可能的解决方案，直到找到满足条件的解决方案的方法。\n如果尝试的当前解决方案不满足条件，它会回溯到上一步，并继续尝试其他可能的选择，直到找到解决方案或者确定无解。 枚举算法(Brute Force Algorithm) 枚举算法是一种通过穷举所有可能的解决方案来解决问题的方法。\n它不利用任何特定的策略，而是尝试所有可能的选择，直到找到满足条件的解决方案。 动态规划(Dynamic Programming) 动态规划是一种通过将问题拆分为更小的子问题，并将其解决方案存储起来，避免重复计算来优化求解过程的方法。\n它使用一个表格或数组来保存子问题的解决方案，以便在需要时快速查找和使用。\n通过解决子问题，动态规划能够逐步得到整个问题的解决方案。 ","date":"2025-02-18T00:00:00Z","permalink":"https://loveleaves.github.io/p/cs/","title":"【CS】计算机科学重要思想、成果记录"},{"content":"References Int8量化-介绍 量化方法汇总 从TensorRT与ncnn看CNN卷积神经网络int8量化算法 谷歌量化白皮书：Quantizing deep convolutional networks for efficient inference: A whitepaper、Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference ppq 神经网络 - 量化与部署 模型压缩：模型量化打怪升级之路 - 1 工具篇 神经网络加速基础知识 计算机体系结构/组成原理 主要了解以下部分：\n指令系统 计算机组成原理和结构 流水线技术 指令耗时/热点指令 现代处理器 经典CPU体系结构 x86架构（CISC） 胶水typo，多核心 部分组件公共化，提高集成度 GPU架构 共享指令译码和控制，ALU运行的指令相同（分支发散问题） GPU架构介绍 ASIC专用芯片架构 继续移除非必要指令（浮点、图形支持等） 特定领域设计 异构计算与主从设备交互 找到性能瓶颈（performance bottleneck） 高算力场景=》用ASIC等芯片，提高算力，高延迟 低延迟场景=》用FPGA等芯片，降低延迟，低算力 性能热点分析工具 torch Profiler Nsight Compute Nsight Compute 量化硬件实现 量化算子 基本公式：\n1 2 3 4 float value = 1.0; // 输入值 float scale = 0.1; // 用于缩放输入值（尺度因子） int32 qt_32 = round_fn(value/scale); // 取整 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 取整函数round_fn比较特别，在不同硬件上有不同的取整模式（主要对中间值，如1.5，-2.5等），常见取整模式：\nRound half to even，torch 、 C使用，向偶数方向取整 Round half away from zero，向正负无穷方向取整 Round half toward zero，向0方向取整 Round half down，向下取整 Round half up，向上取整 量化子图与全精度子图（quantized subgraph） 权重是可以直接计算出来的，推理的时候只要计算一下量化算子即可\n通常情况，量化算子全部支持场景： 存在不支持量化算子，可用子图分割分离不支持运算子图分开计算，但会导致访存开销为热点 反量化算子 基本公式：\n1 2 3 Char value = 1; // 量化算子/运算输出值 float scale = 0.1; // 用于缩放输入值（尺度因子） Float deq = (value * scale); 量化模式（量化与反量化） 对称量化：基本量化模式，分布对称 1 2 3 int32 qt_32 = round_fn(value/scale); // 取整 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 // 反量化对应量化反向操作，类似encode《=》decode 非对称量化：充分利用int8数值范围（如relu负数范围） 1 2 int32 qt_32 = round_fn(value/scale) + offset; // 取整 uint8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 整数量化（power of two）：部分硬件不支持浮点运算，用整数运算替换 1 2 int32 qt_32 = round_fn(value * (2 \u0026lt;\u0026lt; shift)); // 取整，shift-定点位 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 指数量化\u0026hellip; tensor量化与通道量化 以上对称/非对称量化、整数量化中的offset、shift可以整个数据为粒度进行量化（可能数值偏差大，量化差），也可以采用其他粒度进行量化：\ntensor量化（per-tensor）：以单个tensor为粒度 通道量化（per-channel）：以单个channel为粒度 量化计算怎么写 整数运算：在许多硬件上，整数运算的微指令条数和指令吞吐量等可能和浮点差不多甚至比浮点差 访存：量化后数据传输耗时少 向量化技术：SIMD/SIMT，代码向量化网站 量化计算一般是：量化+反量化，目的是为了保证量化计算的逻辑与原来一致 量化乘法（quantized mul） 正常int8计算会溢出，所以先反量化成float计算乘法再量化，即量化计算一般要加上rescale操作\n1 2 3 4 5 6 7 // 原本量化运算 ouput[i][j]=inputa[i][j]*inputb[i][j]; //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn(inputa[i][j]*scale_a * inputb[i][j] * scale_b / scale_c)); // scale 为float 即 ouput[i][j]=quantizied(inputa[i][j] * inputb[i][j] / scale_abc); // scale_abc 可提前算 // 同理，如果采用整数量化 即 ouput[i][j]=quantizied(inputa[i][j] * inputb[i][j] \u0026lt;\u0026lt; round(log2 scale_abc)); // scale_abc 可提前算 量化加法 加法要求两个操作数的scale必须一致 1 2 3 4 5 6 // 原本量化运算 ouput[i][j]=inputa[i][j]+inputb[i][j]; //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn((inputa[i][j]*scale_a + inputb[i][j] * scale_b) / scale_c)); // scale 为float // 这里加法要求scale_a和scale_b必须一致（两个操作数的scale） 即 ouput[i][j]=quantizied((inputa[i][j] + inputb[i][j]) / scale_ab); // scale_ab 可提前算 量化激活函数 要求输入输出的scale必须一致 1 2 3 4 5 6 7 // 原本clip量化运算 ouput[i][j]=max(inputa[i][j], min); //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn((inputa[i][j]*scale_in + min) / scale_out)); // scale 为float // 这里加法要求scale_in和scale_out必须一致 即 ouput[i][j]=inputa[i][j] + min / scale_in; // 注意这里没有round_fn、clip操作，min被动量化 // 这时这类算子被称为被动量化算子，如clip、relu、concat等 量化矩阵乘（quantized Gemm） int8输入=》int16/32计算乘法=》int32/64保存求和结果=》量化为int8输出 量化非线性运算 算子包含非线性运算。如：exp、tanh、sigmoid、softmax等 非线性运算：用int无法替代float计算求得结果 CPU、GPU上，不做量化，以全精度模式运行 FPGA、ASIC、DSP上，不支持浮点运算，需要更改算子计算逻辑，以线性运算拟合或直接查表 计算图 算子 常见算子：https://github.com/onnx/onnx/blob/main/docs/Operators.md 最小调度单位 算子融合加速：减少访存调用栈开销，优化计算逻辑 常见计算图优化（算子融合） 计算图优化实践：https://www.bilibili.com/video/BV1Kr4y1n7cy/\n激活函数融合：Computing Op -\u0026gt; Activation =\u0026gt; ConputAct 常见OP：Conv、ConvTranpose、Gemm 常见Act：Relu、Clip（relu6）、Prelu、Tanh、Sigmoid、Switsh 移除batchnorm和dropout 常量折叠：把常量融合进行计算 矩阵乘融合 conv-add融合：Conv + any =\u0026gt; Y = Wx + (Y2 + B) Conv：Y1=WX+B any：Y2 联合定点 用于支持多后端使用，保留原始计算图信息和量化后的计算图信息\n图调度（Graph Dispatching） 误差分析后发现部分算子的误差较大，可将其单独调度到非量化平台计算 图模式匹配 一个计算图可以表示为一个由节点、边集、输入边、输出边组成的四元组 C = {N, E, I, O}。\n我们往往需要在计算图中寻找指定结构。\n如何用一个严谨的方式定义结构？ 如何设计计算模式匹配法，使得其尽可能高效？ 图模式匹配是量化算法、算子融合、算子调度的基础。 图模式匹配可用方法：子图匹配、遍历模式匹配 例子 想象一个场景，onnx不支持swish算子，其可能用以下算子组合实现： 这样有一个问题，量化时会将这三个算子都量化一遍，但其实只需要量化最后一个mul算子即可。这里就可以利用图模式匹配匹配到这个替代的swish结构，并针对性进行处理。\n1 2 3 4 5 6 7 8 9 // 匹配swish，子图模式匹配 search_engine = SearchableGraph(graph) results = search_engine.pattern_matching( patterns = lambda x: x.is_computing_op(\u0026#39;Sigmoid\u0026#39;, \u0026#39;Mul\u0026#39;), edges = [[0, 1], [1, 2], [0, 2]], exclusive = True ) for computing_op, sigmoid, mul in results: ... 遍历模式匹配 匹配模式：起点表达式=》中继点..=》终点..，自动机 步骤：图拆成树，树拆成链，在每个链上进行模式匹配，期间可用动态规划优化 子图模式匹配 子图同构问题为NP-Hard问题，使用近似算法 避免模式pattern多义性，保持互斥 算子调度 SOI正向传播：从开始算子往后找，可能有多个匹配 正向传播的反方向，从终点算子开始往前找 调度争议区：既可以量化，又不可以量化 调度约束： 激活函数与计算节点保持同一平台 NMS、shape、TOPK、MAX与计算节点保持同一平台 参与图融合的算子保持同一平台 孤立计算节点不量化 多输入算子所有输入同平台 手动调度：权衡精度和速度，考虑硬件支持情况 神经网络部署 运行时（runtime） 实际硬件执行库，针对不同硬件有不同实现\n神经网络部署 各厂商的训练框架、推理框架、硬件厂商 部署流程：训练框架训练模型=》导出统一中间表达模型（可选）=》指定推理框架=》指定硬件执行 部署建议：\n确保你的网络可以被Onnx表示，避免其中出现复杂条件逻辑及循环逻辑。 学会自定义算子，以备不时之需，（包括自定义算子的推理实现）。 避免使用各种小Trick，额外加入的算子很可能会破坏图优化。 神经网络能跑多快是Runtime决定的，神经网络加速应当根据runtime进行。 用一下 Onnx Simplifier。 写一个固定的 batchsize大小（latency和吞吐）。 ONNX部署推理 onnxruntime TensorRT Develop Guide, docs、quantization 连贯量化区：不要在网络中过度使用不可量化算子 网络结构设计、量化点插入不能破坏图融合 Tensor对齐 Profiler工具分析：Nsight System 自定义算子，必要时自己写plugin：https://github.com/NVIDIA/TensorRT/tree/release/10.8/plugin 量化理论分析 量化参数选择 假设 Ln/s用比值来评估量化偏差，忽略实际值的大小 int8实际应为-128，这里为了对称写成-127 注意这里的截断边界条件为.5，如127.5，-127.5，为了尽可能保留原精度 最大值截断 也就是说最大值截断在元素值趋于无限时，会出现误差发散的情况。 分位数截断 实际运用时，结合3-sigma原则取近似sigma值 最优截断 Bernard Widrow公式 最优估计问题：\n最优截断要求pdf的三阶积分，并求导令上式为0，对于大部分分布而言，无法顺利求得解析解。 同时在很多情况下，局部的MSE最优并不是全局MSE最优的。 数据量小时，估计的方差很大。 枚举最优截断 梯度优化截断 量化误差分析 https://www.bilibili.com/video/BV1V94y117Ej/\n量化框架 PPQ PPQ框架介绍 大模型LLM推理加速 TensorRT pytorch-quantization ONNX onnxruntime quantization onnx介绍 NCNN NCNN Conv量化详解 ","date":"2025-02-10T00:00:00Z","permalink":"https://loveleaves.github.io/p/quantization/","title":"【量化】 神经网络量化介绍"},{"content":"设计模式简介 以下引用自菜鸟教程、design pattern\n设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。\n设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。\n什么是 GOF（四人帮，全拼 Gang of Four）？ 在 1994 年，由 Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 四人合著出版了一本名为 Design Patterns - Elements of Reusable Object-Oriented Software（中文译名：设计模式 - 可复用的面向对象软件元素） 的书，该书首次提到了软件开发中设计模式的概念。\n四位作者合称 GOF（四人帮，全拼 Gang of Four）。他们所提出的设计模式主要是基于以下的面向对象设计原则。\n对接口编程而不是对实现编程。 优先使用对象组合而不是继承。 设计模式之美-王争 知识概览图 课程目录 文章导览 简介 开篇词 | 一对一的设计与编码集训，让你告别没有成长的烂代码！ 01 | 为什么说每个程序员都要尽早地学习并掌握设计模式相关知识？ 02 | 从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？ 03 | 面向对象、设计原则、设计模式、编程规范、重构，这五者有何关系？ 04 | 理论一：当谈论面向对象的时候，我们到底在谈论什么？ 05 | 理论二：封装、抽象、继承、多态分别可以解决哪些编程问题？ 06 | 理论三：面向对象相比面向过程有哪些优势？面向过程真的过时了吗？ 07 | 理论四：哪些代码设计看似是面向对象，实际是面向过程的？ 08 | 理论五：接口vs抽象类的区别？如何用普通的类模拟抽象类和接口？ 09 | 理论六：为什么基于接口而非实现编程？有必要为每个类都定义接口吗？ 10 | 理论七：为何说要多用组合少用继承？如何决定该用组合还是继承？ 11 | 实战一（上）：业务开发常用的基于贫血模型的MVC架构违背OOP吗？ 12 | 实战一（下）：如何利用基于充血模型的DDD开发一个虚拟钱包系统？ 13 | 实战二（上）：如何对接口鉴权这样一个功能开发做面向对象分析？ 14 | 实战二（下）：如何利用面向对象设计和编程开发接口鉴权功能？ 15 | 理论一：对于单一职责原则，如何判定某个类的职责是否够“单一”？ 16 | 理论二：如何做到“对扩展开放、修改关闭”？扩展和修改各指什么？ 17 | 理论三：里式替换（LSP）跟多态有何区别？哪些代码违背了LSP？ 18 | 理论四：接口隔离原则有哪三种应用？原则中的“接口”该如何理解？ 19 | 理论五：控制反转、依赖反转、依赖注入，这三者有何区别和联系？ 20 | 理论六：我为何说KISS、YAGNI原则看似简单，却经常被用错？ 21 | 理论七：重复的代码就一定违背DRY吗？如何提高代码的复用性？ 22 | 理论八：如何用迪米特法则（LOD）实现“高内聚、松耦合”？ 23 | 实战一（上）：针对业务系统的开发，如何做需求分析和设计？ 24 | 实战一（下）：如何实现一个遵从设计原则的积分兑换系统？ 25 | 实战二（上）：针对非业务的通用框架开发，如何做需求分析和设计？ 26 | 实战二（下）：如何实现一个支持各种统计规则的性能计数器？ 27 | 理论一：什么情况下要重构？到底重构什么？又该如何重构？ 28 | 理论二：为了保证重构不出错，有哪些非常能落地的技术手段？ 29 | 理论三：什么是代码的可测试性？如何写出可测试性好的代码？ 30 | 理论四：如何通过封装、抽象、模块化、中间层等解耦代码？ 31 | 理论五：让你最快速地改善代码质量的20条编程规范（上） 32 | 理论五：让你最快速地改善代码质量的20条编程规范（中） 33 | 理论五：让你最快速地改善代码质量的20条编程规范（下） 34 | 实战一（上）：通过一段ID生成器代码，学习如何发现代码质量问题 35 | 实战一（下）：手把手带你将ID生成器代码从“能用”重构为“好用” 36 | 实战二（上）：程序出错该返回啥？NULL、异常、错误码、空对象？ 37 | 实战二（下）：重构ID生成器项目中各函数的异常处理代码 38 | 总结回顾面向对象、设计原则、编程规范、重构技巧等知识点 39 | 运用学过的设计原则和思想完善之前讲的性能计数器项目（上） 40 | 运用学过的设计原则和思想完善之前讲的性能计数器项目（下） 41 | 单例模式（上）：为什么说支持懒加载的双重检测不比饿汉式更优？ 42 | 单例模式（中）：我为什么不推荐使用单例模式？又有何替代方案？ 43 | 单例模式（下）：如何设计实现一个集群环境下的分布式单例模式？ 44 | 工厂模式（上）：我为什么说没事不要随便用工厂模式创建对象？ 45 | 工厂模式（下）：如何设计实现一个Dependency Injection框架？ 46 | 建造者模式：详解构造函数、set方法、建造者模式三种对象创建方式 47 | 原型模式：如何最快速地clone一个HashMap散列表？ 48 | 代理模式：代理在RPC、缓存、监控等场景中的应用 49 | 桥接模式：如何实现支持不同类型和渠道的消息推送系统？ 50 | 装饰器模式：通过剖析Java IO类库源码学习装饰器模式 51 | 适配器模式：代理、适配器、桥接、装饰，这四个模式有何区别？ 52 | 门面模式：如何设计合理的接口粒度以兼顾接口的易用性和通用性？ 53 | 组合模式：如何设计实现支持递归遍历的文件系统目录树结构？ 54 | 享元模式（上）：如何利用享元模式优化文本编辑器的内存占用？ 55 | 享元模式（下）：剖析享元模式在Java Integer、String中的应用 56 | 观察者模式（上）：详解各种应用场景下观察者模式的不同实现方式 57 | 观察者模式（下）：如何实现一个异步非阻塞的EventBus框架？ 58 | 模板模式（上）：剖析模板模式在JDK、Servlet、JUnit等中的应用 59 | 模板模式（下）：模板模式与Callback回调函数有何区别和联系？ 60 | 策略模式（上）：如何避免冗长的if-else/switch分支判断代码？ 61 | 策略模式（下）：如何实现一个支持给不同大小文件排序的小程序？ 62 | 职责链模式（上）：如何实现可灵活扩展算法的敏感信息过滤框架？ 63 | 职责链模式（下）：框架中常用的过滤器、拦截器是如何实现的？ 64 | 状态模式：游戏、工作流引擎中常用的状态机是如何实现的？ 65 | 迭代器模式（上）：相比直接遍历集合数据，使用迭代器有哪些优势？ 66 | 迭代器模式（中）：遍历集合的同时，为什么不能增删集合元素？ 67 | 迭代器模式（下）：如何设计实现一个支持“快照”功能的iterator？ 68 | 访问者模式（上）：手把手带你还原访问者模式诞生的思维过程 69 | 访问者模式（下）：为什么支持双分派的语言不需要访问者模式？ 70 | 备忘录模式：对于大对象的备份和恢复，如何优化内存和时间的消耗？ 71 | 命令模式：如何利用命令模式实现一个手游后端架构？ 72 | 解释器模式：如何设计实现一个自定义接口告警规则功能？ 73 | 中介模式：什么时候用中介模式？什么时候用观察者模式？ 74 | 总结回顾23种经典设计模式的原理、背后的思想、应用场景等 75 | 在实际的项目开发中，如何避免过度设计？又如何避免设计不足？ 76 | 开源实战一（上）：通过剖析Java JDK源码学习灵活应用设计模式 77 | 开源实战一（下）：通过剖析Java JDK源码学习灵活应用设计模式 78 | 开源实战二（上）：从Unix开源开发学习应对大型复杂项目开发 79 | 开源实战二（中）：从Unix开源开发学习应对大型复杂项目开发 80 | 开源实战二（下）：从Unix开源开发学习应对大型复杂项目开发 81 | 开源实战三（上）：借Google Guava学习发现和开发通用功能模块 82 | 开源实战三（中）：剖析Google Guava中用到的几种设计模式 83 | 开源实战三（下）：借Google Guava学习三大编程范式中的函数式编程 84 | 开源实战四（上）：剖析Spring框架中蕴含的经典设计思想或原则 85 | 开源实战四（中）：剖析Spring框架中用来支持扩展的两种设计模式 86 | 开源实战四（下）：总结Spring框架用到的11种设计模式 87 | 开源实战五（上）：MyBatis如何权衡易用性、性能和灵活性？ 88 | 开源实战五（中）：如何利用职责链与代理模式实现MyBatis Plugin？ 89 | 开源实战五（下）：总结MyBatis框架中用到的10种设计模式 90 | 项目实战一：设计实现一个支持各种算法的限流框架（分析） 91 | 项目实战一：设计实现一个支持各种算法的限流框架（设计） 92 | 项目实战一：设计实现一个支持各种算法的限流框架（实现） 93 | 项目实战二：设计实现一个通用的接口幂等框架（分析） 94 | 项目实战二：设计实现一个通用的接口幂等框架（设计） 95 | 项目实战二：设计实现一个通用的接口幂等框架（实现） 96 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（分析） 97 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（设计） 98 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（实现） 99 | 总结回顾：在实际软件开发中常用的设计思想、原则和模式 100 | 如何将设计思想、原则、模式等理论知识应用到项目中？ 加餐一 | 用一篇文章带你了解专栏中用到的所有Java语法 加餐二 | 设计模式、重构、编程规范等相关书籍推荐 春节特别加餐 | 王争：如何学习《设计模式之美》专栏？ 加餐三 | 聊一聊Google是如何做Code Review的 加餐四 | 聊一聊Google那些让我快速成长的地方 加餐五 | 听一听小争哥对Google工程师文化的解读 加餐六 | 什么才是所谓的编程能力？如何考察一个人的编程能力？ 加餐七 | 基础学科的知识如何转化成实际的技术生产力？ 加餐八 | 程序员怎么才能让自己走得更高、更远？ 加餐九 | 作为面试官或候选人，如何面试或回答设计模式问题？ 加餐十 | 如何接手一坨烂业务代码？如何在烂业务代码中成长？ 结束语 | 聊一聊机遇、方向、能力、努力！ MVC和DDD 两者对比：业务开发常用的基于贫血模型的MVC架构违背OOP吗\nMVC MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。这种模式用于应用程序的分层开发。 https://www.runoob.com/design-pattern/mvc-pattern.html 基于贫血模型的传统的开发模式，是一种彻彻底底的面向过程的编程风格 DDD 领域驱动设计（Domain Driven Design，简称DDD） 基于充血模型的开发模式，面向对象编程风格 软件建模 软件建模介绍 将想法通过模型可视化地表达出来，方便记忆和进一步分析，方便团队/同事交流，口语交流容易失真。 软件建模体现了软件设计的思想，在需求和实现之间架起了一座桥梁，通过模型指导软件系统的具体实现。 模型并不是软件系统的一个完备表示，而是所研究系统的一种抽象。 如何进行软件建模 软件建模原则\n1、选择正确的模型，模型要与现实相联系 2、从不同的视角，使用不同的模型去表示一个系统 3、模型是抽象的，是选取系统某个最显著的特征并进行简化表示，因此需要通过不同的视角采用不同模型表示： **外部视角：**对系统上下文或环境进行建模 **交互视角：**对系统及其环境或者系统的构件之间的交互进行建模，建立用例模型 **结构化视角：**对系统的组织或者系统所处理的数据的结构进行建模，建立静态模型 **行为视角：**对系统的动态行为以及系统如何响应事件进行建模，建立动态模型 软件建模方法 在不同的领域和场景下有不同的软件建模方法，其各自的建模思想和采用的建模工具也不尽相同，如：\n结构化方法（Structured Method） 面向对象方法（Object Oriented Method） 基于构件方法（Component Based Method） 面向服务方法（Service Oriented Method） \u0026hellip; 面向对象软件建模方法 UML介绍 UML：Unified Modeling Language（统一建模语言），是面向对象的软件建模工具，使用UML进行建模的作用：\n可以更好的理解问题 可以及早的发现错误或者被遗漏的点 可以更加方便的进行组员之间的沟通 支持面向对象软件开发建模，可以更好的描述显示编程的情景。 对于复杂的系统来说，如果概要模型做的好，那么整个系统的模型也就很清晰明了。 UML一共有10种图，可分为四大类： 用例图 静态图：类图、对象图、包图 行为图：状态图、活动图、交互图，交互图分为序列图和协作图。 实现图：部署图、构件图 主要包括4种关系: 关联关系(association) 依赖关系(dependency) 泛化关系(generalization) 实现关系(realization) 4种视角 References UML实战教程 UML教程 UML2.5笔记 ＵＭＬ基础与建模实践教程 Tools 在线免费：draw.io UML常用图介绍 假设用UML建模以下场景：\n“机票订购系统是一个允许用户在线查询航班、购票、管理行程及退票的平台。系统区分了访客（未登录用户）与注册用户的功能权限：访客仅能浏览航班信息，而注册用户在登录后，还能进行购票、查看已购票以及退订操作。此外，系统内置了与外部信用评分系统的接口，该接口用于监控用户退票行为，若用户一个月内退票超过两次，其在信用评分系统中的等级会下调，信用等级过低时，系统将限制其继续购票。”\n用例图（Use Case Diagram）\n用例图是用来描述客户的需求，从用户的角度描述系统的功能，并指出系统的执行者，强调谁在使用系统，系统执行者完成了哪些功能。用例图包括角色、用例和关系。 类图（Class Diagram）\n用来展示系统中的类、类之间的关系（如继承、关联、聚合等）。适用于系统设计阶段，帮助开发人员理解系统的数据结构和类之间的关系。 顺序图（时序图，sequence diagram）\n描述对象之间如何通过消息交互以完成特定任务。适用于详细设计阶段，用于展示操作的时间顺序。 状态图（State Diagram）\n描述对象或系统在不同状态之间的转移和条件。适用于描述对象生命周期，特别是在系统的状态变化较为复杂时。 活动图（Activity Diagram）\n描述工作流、业务流程或操作的顺序。适用于系统行为建模、业务流程建模等。 构件图（组件图, Component Diagram）\n用来展示系统的物理组件及它们之间的依赖关系。适用于高层设计阶段，帮助理解系统的模块化结构。 部署图（Deployment Diagram）\n描述系统的硬件架构及其部署情况，显示硬件节点、节点之间的通信和软件组件部署到硬件节点的情况。适用于系统部署和运维阶段。 ","date":"2025-02-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/design_pattern/","title":"【软件设计】 设计模式介绍"},{"content":"ARM SIMD ARM平台基于ARM v7-A架构的ARM Cortex-A系列处理器(Cortex-A5, Cortex-A7,Cortex-A8, Cortex-A9, Cortex-A15)上的NEON加速：\n针对C/C++语言：循环展开等编译优化，-O2启用 针对NEON intrinsics：NEOM SIMD C/C++语言接口，针对架构启用V向量扩展，选择浮点处理器和ABI（application Binary Interface）接口类型 针对汇编语言：内联汇编，直接操作neon指令和寄存器 路线：了解相应编译优化=》使用intrinsic接口，学习对应汇编代码=》内联汇编，在编译器汇编代码基础上（否则可能反优化）学习并优化 references NEON Programmer\u0026rsquo;s Guide Cortex-A Series Programmer\u0026rsquo;s Guide 算子源码 AI算子：腾讯ncnn 数据处理算子：numpy simd 图像处理算子：Nvidia carotene，OpenCV third party 理论学习 指令流水线 经典的五级流水线模型 1、取指（IF）\n以程序计数器（PC）中的内容作为地址，从存储器中取出指令并放入指令寄存器（IR）； PC值加4（假设每条指令占4字节），指向顺序的下一条指令。 2、指令译码/读寄存器周期（ID）\n对指令进行译码，并用IR中的寄存器地址去访问通用寄存器组，读出所需的操作数； 对IR中的立即数进行扩展 3、执行/有效地址计算周期（EX）\nALU对上一个周期中准备好的操作数进行运算或处理。在这个阶段，不同类型的指令进行的操作不同。\n（1）load和store指令：ALB把指令中所指定的寄存器的内容与偏移量相加，形成访存有效地址； （2）寄存器-寄存器 ALU 指令：ALU按照操作码指定的操作对从通用寄存器组中读出的数据进行运算； （3）寄存器-立即数 ALU 指令：ALU按照操作码指定的操作对从通用寄存器组中读出的操作数和指令中给出的立即数进行运算； （4）分支指令：ALU把指令中给出的偏移量与PC值相加，形成转移目标的地址。同时，对在前一个周期读出的操作数进行判断，确定分支是否成功。 4、存储器访问/分支完成周期（MEM）\n（1）load和store指令：load指令根据上一个周期计算出的有效地址从存储器中读出的相应的数据；store把指定的数据写入这个有效地址对应的存储单元。 （2）分支指令：如果分支“成功”，就把前一个周期中计算好的转移目标地址送入PC。分支指令执行完成；否则，就不进行任何操作。 5、写回周期（WB）\n把结果写入通用寄存器组。对于ALU运算来说，这个结果来自ALU，而对于load指令来说，这个结果来自存储器。 SIMD加速原理 《计算机体系结构：量化研究方法》。Neon是ARM平台的SIMD（Single Instruction Multiple Data，单指令多数据流）指令集实现，书中4.1~4.3讨论了SIMD，推荐阅读。 之所以能加速的原因总结：\n（1）通过加长的寄存器减少数据的读取/写入次数，从而减少将数据读入寄存器的时间开销。例如Neon可以一次性将16个int8（16*8=128bit）数据读入专用寄存器，这一次读取时间开销，明显少于16个int8数据一个一个地读入的时间之和。写入同理。（注意不要和cache的减少访存时间的原理混淆。从cache读取余下的第2~第16个int8数据到寄存器仍然是要花费时钟周期的）。 （2）执行SISD（single instruction, Single data，单指令流单数据流，这里可理解为标量计算）指令时，需要完成（时间开销大的）冒险（hazard）检查。既然使用SIMD指令计算，就暗示这些数据之间无依赖性，也就从指令集层面回避了不必要的时间开销。 了解硬件决定的速度极限：Software Optimization Guide 我们可能还要关心，我们所编写的Neon Intrinsics，可以将手头上硬件的性能发挥到多少水平？是否还有提升空间？这些是好问题。\n在讨论一个问题前，先插入一个使笔者拍案叫绝的相关案例：在另一本计算经典《深入理解计算机系统》 （一般简称 CS:APP）的第5章 优化程序性能 中，该书作者考虑若干计算机硬件特性，将矩阵乘法连续优化了6个版本，直至优化到了该x86 CPU的吞吐量上限（注：对于某种指令，延迟latency 主要关注单条该指令的最小执行时间，吞吐量throughout主要关注单位时间内系统（一个CPU核）最多执行多少条该指令。因为AI计算的数据量比较大，我们更关注吞吐量） 回到问题，我们需要知道我们的吞吐量上界是多少。ARM官方为每个CPU架构（手机CPU一般大核是A7X架构，小核是A5X架构）提供对应的Software Optimization Guide，里面有进行各种运算的latency和throughout。以A76架构（采用该架构作为大核架构的CPU例如骁龙855，麒麟980）为例子，从ARM官网下载对应的pdf（https://developer.arm.com/documentation/swog307215/a/?lang=en） 翻到ASIMD（Advance SIMD）那里，就能查阅各条Neon指令相应的latency和throughout。不同架构的吞吐量上界会有所不同，其他架构请自行在ARM官网文档中心下载。 理论数据有了，至于如何通过实验测试峰值，可参考BBuf的文章 如何判断算法是否有可优化空间？ （https://zhuanlan.zhihu.com/p/268925243）\n反汇编分析生成代码质量 可通过反汇编的方式查看Intrinsics 生成的汇编是否满足预期，如果不满足预期则进行手写汇编优化。具体操作可参考梁德澎的文章 移动端arm cpu优化学习笔记第4弹\u0026ndash;内联汇编入门（https://zhuanlan.zhihu.com/p/143328317）\nmaterials （1）研讨会视频 \u0026ldquo;Performance Analysis for Optimizing Embedded Deep Learning Inference Software,\u0026rdquo; a Presentation from Arm - Edge AI and Vision Alliance，建立优化分析思维 （2）研讨会视频 LCU14-504: Taming ARMv8 NEON: from theory to benchmark results （3）研讨会视频 HKG15-408: ARM v8-A NEON optimization （4）Ne10（ARM官方的计算库）：https://github.com/projectNe10/Ne10 （5）Arm Optimized Routines（ARM官方的计算、网络、字符串库）：https://github.com/ARM-software/optimized-routines （6）Neon优化Chromium的案例：https://developer.arm.com/documentation/101964/developer.arm.com NEON 介绍 ARM NEON 是 ARM 架构的一种 SIMD（Single Instruction, Multiple Data）扩展，旨在加速多媒体、数字信号处理（DSP）、图像处理、音视频编解码、加密算法等高并发计算任务。NEON 是 ARMv7 （ARMv7-A只支持单精度，32x64-bit寄存器；Armv8-A AArch64支持双精度，32x128-bit寄存器，针对浮点操作的Vector Floating Point，VFP）及之后版本的处理器的标准扩展，广泛用于智能手机、嵌入式设备、平板电脑以及其他移动设备中，尤其是处理需要并行化的计算密集型应用时，它能显著提高性能。\n重要概念 lane：如一个float32x4_t类型的变量float32x4_t v = {1.0f, 2.0f, 3.0f, 4.0f}，它占用 128 位，存储 4 个 32 位的浮点数，在这个向量寄存器 v 中，每个值依次存储在不同的lane序号为0、1、2、3中。 NEON 寄存器 定义：NEON 使用专门的寄存器来存储向量数据，这些寄存器通常用于处理多个数据元素，ARMv7-A只支持单精度，32x64-bit寄存器；Armv8-A AArch64支持双精度，32x128-bit寄存器。 作用：NEON 寄存器组包含了 128 （Q字母）或 64（D字母） 位宽的寄存器，可以存储多个 8 位、16 位、32 位、64 位整数或浮点数据。 例子： Q0-Q15：128 位宽的 NEON 寄存器，用于存储 8 位、16 位、32 位、64 位的数据（整数或浮点数）。 D0-D15：64 位宽的 NEON 寄存器，也用于存储 64 位数据。 向量和标量操作 定义：NEON 支持对向量（多个元素）和标量（单个元素）进行操作。 作用：标量操作是普通的逐元素操作，而向量操作则允许一次性处理多个数据元素。 例子： vadd.f32：向量浮点加法操作。 vadd.i32：向量整数加法操作。 NEON 数据类型 定义：NEON 支持多种数据类型，包括整数、浮点数、双精度浮点数和混合类型数据。 作用：不同的数据类型适应不同的应用需求，如 8 位整数、32 位浮点数等。 例子： i8, i16, i32, i64：不同宽度的整数类型。 f32, f64：浮点数类型，支持单精度和双精度浮点数。 NEON 指令集 定义：NEON 提供了一组专门的指令来处理数据并执行并行计算。NEON 指令包括加法、乘法、减法、移位、汇聚（归约）、比较、选择、数据类型转换等。 作用：这些指令能够加速处理向量数据，尤其是应用于图像处理、音频处理、视频编解码、加密算法等领域。 例子： vadd：向量加法指令。 vmul：向量乘法指令。 vsub：向量减法指令。 vmax：向量最大值选择指令。 扩展数据类型 定义：NEON 提供了扩展数据类型的支持，如高/低16位扩展、饱和算术、向量数据类型转换等。 作用：这种扩展数据类型用于在计算过程中执行高效的数据操作和转换，避免数据溢出或精度丢失。 例子： vshl：向左移位操作。 vqadd：饱和加法指令，防止数据溢出。 数据载入和存储指令 定义：NEON 提供了一些专门的加载（load）和存储（store）指令，用于从内存中加载数据到寄存器，或将寄存器中的数据存储回内存。 作用：这些指令能够优化内存访问，支持从多个内存地址加载和存储数据。 例子： vld1：加载向量数据指令。 vst1：存储向量数据指令。 数据汇聚和归约操作 定义：NEON 提供了对向量数据的汇聚（归约）操作，例如求和、最大值、最小值等。 作用：这些操作通常用于计算总和、平均值、最大值等统计量，广泛应用于信号处理和数据分析中。 例子： vaddv：对向量元素进行加法归约，返回所有元素的和。 vmaxv：对向量元素进行最大值归约，返回最大值。 条件执行 定义：NEON 支持条件执行，通过设置条件码（flags），可以对某些指令的执行进行条件限制。 作用：可以根据特定的条件执行指令，避免不必要的计算，提高性能。 例子： vsel：根据掩码（mask）选择性地执行指令。 SIMD 聚合指令（广播操作） 定义：NEON 支持广播操作，允许单一标量值扩展到整个向量中。广播操作使得标量与向量的数据处理更加简便。 作用：通过广播操作，标量可以与向量中的每个元素进行计算，提高了指令的灵活性。 例子： vdup：将一个标量值复制到整个向量中。 NEON 浮点数运算 定义：NEON 支持单精度浮点数和双精度浮点数的运算，符合 IEEE 754 标准。 作用：这些浮点数运算指令可用于科学计算、图像处理等应用。 例子： vadd.f32：单精度浮点数向量加法。 vmul.f32：单精度浮点数向量乘法。 数据类型转换 定义：NEON 支持多种类型之间的转换操作，如浮点与整数类型之间的转换。 作用：这种转换对于不同数据类型之间的运算非常重要，可以确保类型匹配并避免数据丢失。 例子： vcvt.f32.s32：将 32 位整数转换为 32 位单精度浮点数。 vcvt.s32.f32：将 32 位单精度浮点数转换为 32 位整数。 向量掩码 定义：NEON 支持通过掩码控制哪些向量元素应该被操作。掩码机制允许在处理多个数据时根据特定条件选择性地操作某些元素。 作用：掩码可以控制并行操作的粒度，提高计算的灵活性。 例子： vmla：向量乘加指令，根据掩码控制哪些元素参与计算。 NEON Intrinsic 兼容armv7和v8（部分指令可能不兼容），所以不同架构之间迁移方便，不需要改代码\nReferences NEON-Intrinsics Neon Programmer Guide for Armv8-A Coding for Neon intrinsics检索，用来查看接口和支持架构 ARM Neon Intrinsics 学习指北：从入门、进阶到学个通透 numpy simd 数据和计算指令类型的格式 1、向量数据类型格式：\u0026lt;type\u0026gt;\u0026lt;size\u0026gt;x\u0026lt;number of lanes\u0026gt;_t\n比如float32x4_t，=float,=32,=4 向量数据类型： 2、向量数组类型：\u0026lt;type\u0026gt;\u0026lt;size\u0026gt;x\u0026lt;number of lanes\u0026gt;x\u0026lt;length of array\u0026gt;_t\n比如 1 2 3 4 struct int16x4x2_t { int16x4_t val[2]; }; 向量指令格式：\u0026lt;opname\u0026gt;\u0026lt;flags\u0026gt;_\u0026lt;type\u0026gt;\n比如vmulq_f32，=vmul，=q,=f32 Note 普通计算逻辑考虑优化编译器优化、类型量化等 循环一般用do-while的形式 对于非整数倍元素个数的解决方法： leftovers 使用 NEON 的广播操作，避免显示复制数据 使用 NEON 的饱和操作，避免数据溢出 利用数据类型转换操作，并合理进行量化 利用shift、insert、mask等 计算机组成结构运行相关（通用） 并行\n充分利用计算机流水线：去除数据依赖 逻辑操作代替分支选择（分支预测） 数据预加载（预取/并行） 资源利用\n充分利用寄存器资源，分块处理数据，但避免寄存器溢出(Register Spilling）（测试时开启O2优化使编译器允许寄存器存储临时变量） 内存合理对齐分配，按对应寄存器长度读取 多线程处理，如OpenMP（并行/数据共享） 利用数据连续特性、利用cache NEON 汇编 可用__aarch64__宏区分是armv8，否则armv7，针对性编写代码\nReferences 移动端arm cpu优化学习笔记第4弹\u0026ndash;内联汇编入门 arm 内联汇编使用 arm内联汇编的一般格式，detail、docs\n1 2 3 4 5 6 7 8 __asm__ qualifiers ( // 汇编代码部分 : OutputOperands //在内联汇编代码中被修改的变量列表 : InputOperands //在内联汇编代码中用到的变量列表 : Clobbers //在内联汇编代码中用到的寄存器列表 ); Note 先写intrinsic代码反汇编，学习编译器优化后的汇编代码，再优化 重点关注指令流水线排布，避免CPU的Hazard ","date":"2025-02-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/arm-neon/","title":"【SIMD】 ARM SIMD指令集NEON等介绍"},{"content":"References The RISC-V Instruction Set Manual Volume II: Privileged Architecture RVV spec Xuantie+900+Series+RVV-0.7.1+Intrinsic+Manual 算子源码 ARM-software/CMSIS, CMSIS-DSP Nuclei-software/NMSIS Note illegal instruction：修改CSR的mstatus标志位 important concepts VLEN (Vector Length) 定义：向量寄存器的长度，表示每个寄存器可以存储的最大元素数量，通常是硬件设定的，例如 128 位、256 位或 512 位。 作用：决定向量寄存器的容量和能处理的数据量。 例子： 如果 VLEN 为 256 位且每个元素为 32 位整数，则每个寄存器最多存储 8 个元素（256 / 32 = 8）。 SLEN (Stride Length) 定义：元素在内存中的步长，即两个连续元素之间的内存偏移量。 作用：影响内存访问模式，特别是在访问非连续内存时，SLEN 决定了元素之间的间隔。 例子： 假设一个向量寄存器存储 4 个元素，每个元素大小为 32 位，而 SLEN 设置为 2，这意味着每个向量元素在内存中的位置间隔为 2 个 32 位单元。 ELEN (Element Length) 定义：每个向量元素的大小（单位：比特），决定了每个元素占用多少内存。 作用：影响向量中每个元素的数据类型大小，在指令中用e表示，如e32。 例子： 如果 ELEN 设置为 32 位，则每个向量元素为 32 位宽，可以是一个 32 位整数或 32 位浮点数。 如果 ELEN 为 64 位，则每个元素占 64 位，适用于较大数据类型（如 64 位整数或浮点数）。 LMUL (Vector Register Grouping Factor) 定义：向量寄存器的分组因子，控制每个向量寄存器内元素的数量，决定寄存器的并行度。 作用：LMUL 会影响每个向量寄存器中包含的元素数量，从而影响并行性，在指令中用m表示，如m1。 例子： LMUL = 1：每个寄存器存储最大数量的元素（假设 VLEN = 256 位，ELEN = 32 位，则每个寄存器存储 8 个元素）。 LMUL = 2：每个寄存器只存储 4 个元素，寄存器总数增加，适合提高并行度。 LMUL = 4：每个寄存器只存储 2 个元素。 VL (Vector Length Register) 定义：VL 是一个寄存器，用来控制当前向量指令的长度，即当前指令能处理的元素数量。 作用：在 RVV 指令中，VL 决定了向量运算的迭代次数，向量操作将执行 VL 次。 例子： 如果 VL = 4，那么该指令将对前 4 个向量元素执行操作，用setvl(max)指令可以得到指令类型的最大元素数量，其中每个指令指定vl可处理不同数量的元素。 VTYPE (Vector Type Register) 定义：VTYPE 控制向量操作的类型，如元素长度 (ELEN) 和 LMUL 的配置。 作用：配置向量操作的具体参数，帮助硬件理解如何处理向量指令。 例子： VTYPE 设置为 ELEN = 32 位，LMUL = 1，表示每个向量寄存器存储 32 位元素，且每个寄存器的并行度为 1。 Vector Mask (vmsk) 定义：向量掩码用于控制哪些向量元素应该被操作，哪些应该被忽略。 作用：掩码机制使得程序能够选择性地执行向量操作。 例子： 若 vmsk = 11110000（二进制），则只有前 4 个向量元素会被操作，后 4 个元素将被忽略。 Vector Registers (v0 - vn) 定义：向量寄存器用于存储向量数据，RISC-V 定义了 v0 到 v31 的向量寄存器。 作用：这些寄存器用于存储和处理向量数据，数量和大小可由硬件决定。 例子： v0 和 v1 可以分别存储 256 位的向量数据，适用于不同长度的数据类型。 Vector Load/Store Instructions 定义：向量加载和存储指令，用于将数据从内存加载到向量寄存器，或将向量寄存器中的数据存储回内存。 作用：支持各种内存访问模式，如连续或非连续访问。 例子： vlb：加载字节数据到向量寄存器。 vsb：将字节数据存储回内存。 Vector Arithmetic Instructions 定义：向量算术指令用于执行向量加法、减法、乘法、除法等算术运算。 作用：向量算术指令在多核处理器中并行执行运算。 例子： vadd：向量加法，执行两个向量的逐元素加法。 vmul：向量乘法，执行两个向量的逐元素乘法。 Vector Compare Instructions 定义：向量比较指令用于比较向量中的元素，返回布尔掩码结果。 作用：常用于条件判断和控制流。 例子： vseq：判断两个向量的元素是否相等，结果返回掩码。 vsgt：判断向量元素是否大于另一个向量，返回布尔掩码。 Vector Reduction Instructions 定义：向量归约指令用于将向量中的多个元素归约为一个单一结果，如求和、求最大值等。 作用：常用于矩阵运算、图像处理等应用。 例子： vredsum：求和，将向量中所有元素相加。 vredmax：求最大值，返回向量中的最大元素。 Vector Scatter/Gather Instructions 定义：用于从非连续的内存地址中加载数据或将数据存储到非连续的内存地址。 作用：提高对非连续内存的访问效率。 例子： vscatter：将向量元素存储到不连续的内存位置。 vgather：从不连续的内存位置加载数据到向量寄存器。 Vector-Scalar Operations 定义：向量与标量之间的操作，允许标量与每个向量元素进行逐一运算。 作用：通过标量与向量元素的结合，处理常数数据。 例子： vaddvi：将一个标量与向量中的每个元素相加。 vmulvi：将一个标量与向量中的每个元素相乘。 Vector Predication 定义：根据掩码或布尔条件选择性执行向量操作。 作用：通过掩码决定哪些元素进行计算，哪些跳过。 例子： vmand：与掩码进行与运算，满足条件的元素进行计算。 Vector Tail \u0026amp; Masking 定义：当 VL 不能完全填充向量寄存器时，通过尾部掩码控制哪些元素需要操作。 作用：避免浪费计算资源，确保运算的有效性。 例子： 如果 VL = 5，而寄存器有 8 个元素，掩码将控制只操作前 5 个元素。 Vector Unit (VU) 定义：向量单元是硬件中的计算单元，负责执行向量指令。 作用：处理向量计算，提高处理器的并行度。 例子： 在支持 RVV 的处理器中，向量单元可以同时处理多个向量运算。 Note 常见使用方式 以float32类型dot计算为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 void riscv_dot_prod_f32( const float32_t * pSrcA, const float32_t * pSrcB, uint32_t blockSize, float32_t * result) { float32_t sum = 0.0f; size_t blkCnt = blockSize; size_t l; vfloat32m8_t v_A, v_B; vfloat32m8_t vsum; l = __riscv_vsetvlmax_e32m8(); vsum = __riscv_vfmv_v_f_f32m8(0.0f, l); for (; (l = __riscv_vsetvl_e32m8(blkCnt)) \u0026gt; 0; blkCnt -= l) { v_A = __riscv_vle32_v_f32m8(pSrcA, l); pSrcA += l; v_B = __riscv_vle32_v_f32m8(pSrcB, l); pSrcB += l; vsum = __riscv_vfmacc_vv_f32m8(vsum, v_A, v_B, l); } l = __riscv_vsetvl_e32m8(1); vfloat32m1_t temp00 = __riscv_vfmv_v_f_f32m1(0.0f, l); l = __riscv_vsetvlmax_e32m8(); temp00 = __riscv_vfredusum_vs_f32m8_f32m1(vsum, temp00, l); sum = __riscv_vfmv_f_s_f32m1_f32(temp00); *result = sum; } ","date":"2025-02-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/rvv/","title":"【SIMD】 Risc-v SIMD指令集RVV介绍"},{"content":"环境准备 1.1 Git下载 前往【Git官网】，下载安装程序 一直点下一步，默认安装即可\nHugo下载 前往【Hugo Github Tags】，选择对应版本下载，下载后解压即可 Windows下载版本：hugo_extended_xxxxx_windows_amd64.zip\n搭建博客 创建博客 （1）在hugo.exe所在文件夹的地址栏敲打cmd，然后Enter唤起命令行\n（2）敲打命令hugo new site xxxx创建hugo文件\n（3）敲打命名cd xxxx切换目录，并把hugo.exe复制到刚生成的文件夹中\n（4）敲打命令hugo server -D启动服务，访问http://localhost:1313，Ctrl+C停止服务 （hugo默认是没有主题的，需要进行主题配置）\n配置主题 （1）前往【Hugo Themes】，查找自己喜欢的主题，进行下载\n（2）这边以【Stack主题】为例，将下载好的主题解压，放到/themes文件夹中\n（3）将exampleSite样例数据中的 Content 和 hugo.yaml 复制到主文件夹中，并删掉hugo.toml和content/post/rich-content\n（4）修改 hugo.yaml 中的 theme，将他修改为跟主题文件夹同名\n（5）再次启动hugo服务，查看主题，具体主题配置修改 hugo.yaml，这里不细说，感兴趣可自行查找相关文章\n启用 Giscus 评论 Giscus 是利用 GitHub Discussions 实现的评论系统，开源、无跟踪、无广告、永久免费。\nHugo 对 Giscus 有很好的支持，在 hugo-theme-jane 主题中配置启用Giscus 很简单。\n要启用 Giscus 请先确保：\n仓库是公开的，否则访客将无法查看 discussions。 giscus app 已安装，否则访客将无法评论和回应。 Discussions 功能已在你的仓库中启用。 前面搭建的博客仓库就是公开的，满足了第一点，接下来要做的就是安装 Giscus app 和启用 Discussions。\nReferences https://www.codeaer.com/post/enable-giscus-comments-in-hugo/ 配置 Giscus 根据版本有所不同，0.143.1版本可使用以下模板\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # repoId、categoryId参考网址修改：https://giscus.app/zh-CN giscus: repo: \u0026#34;xxx/xxx.github.io\u0026#34; repoId: \u0026#34;xxx\u0026#34; category: \u0026#34;General\u0026#34; categoryId: \u0026#34;xxx\u0026#34; mapping: \u0026#34;pathname\u0026#34; # comment value is the default value strict: 0 reactionsEnabled: 1 # emitMetadata: 0 inputPosition: \u0026#34;top\u0026#34; theme: \u0026#34;dark\u0026#34; lang: \u0026#34;zh-CN\u0026#34; lazyLoading: true crossorigin: \u0026#34;anonymous\u0026#34; Github部署 常规部署 （1）前往【Github官网】，创建仓库 {github用户名}.github.io\n（2）前往Setting -\u0026gt; Pages -\u0026gt; Branch选择main分支，然后保存，会自动开启 https://{github用户名}.github.io 的地址，这地址也是以后访问博客的地址\n（3）回到hugo文件中，执行命令hugo -D，会生成 public 静态资源文件夹\n（4）在 public 执行以下命令上传到github仓库上，第一次上传可能需要输入账号密码\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main （5）上传成功后访问 https://{github用户名}.github.io，成功搭建属于自己的Hugo博客\nGithub Action自动部署 （1）Github创建一个新的仓库，用于存放Hugo的主文件\n（2）前往Setttings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens，创建一个token(classic)\n（3）token选择永不过期，并勾选 repo 和 workflow 选项\n（4）为保证安全，将生成的token，保存的仓库的变量中，前往Settings -\u0026gt; Secrets and variables -\u0026gt; Actions中设置\n（5）在hugo主文件创建一个.github/workflows/xxxx.yaml文件，将以下内容复制进去，想具体了解更多，可查看【Github Action文档】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: deploy # 代码提交到main分支时触发github action on: push: branches: - main jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;latest\u0026#34; extended: true - name: Build Web run: hugo -D - name: Deploy Web uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.你的token变量名 }} EXTERNAL_REPOSITORY: 你的github名/你的仓库名 PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy （6）在hugo主文件创建.gitignore文件，来避免提交不必要的文件\n1 2 3 4 5 6 7 # 自动生成的文件 public resources .hugo_build.lock # hugo命令 hugo.exe （7）将hugo的主文件上传到仓库，上传成功后会触发Github Action，来自动部署你的静态页面\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main Reference https://letere-gzj.github.io/hugo-stack/p/hugo/custom-blog/ ","date":"2025-02-05T00:00:00Z","permalink":"https://loveleaves.github.io/p/hugo-blog/","title":"Hugo + Github 免费部署自己的博客"},{"content":"References C进阶：https://www.bookstack.cn/read/whyilearnc/README.md 中科大超算中心资料手册：https://scc.ustc.edu.cn/zlsc/ https://www.zhihu.com/question/33576416 https://heptagonhust.github.io/HPC-roadmap/ HPC指南：https://github.com/l0ngc/hpc-learning 高等数值分析（高性能计算，并行计算）：https://math.ecnu.edu.cn/~jypan/Teaching/ParaComp/ https://developer.nvidia.com/hpc-sdk-downloads 概念 并行计算三要素\n硬件：并行计算机/体系结构 算法：并行算法设计/应用问题的并行度 软件：并行编程环境/Linux/Fortran/C/C++/MPI/OpenMP 代码优化 分支预测：https://blog.csdn.net/yaojingqingcheng/article/details/120913601 simd优化： 简单例子：https://blog.csdn.net/csdn546229768/article/details/128728780 https://blog.csdn.net/yaojingqingcheng/article/details/121616954 数据结构布局优化：https://blog.csdn.net/yaojingqingcheng/article/details/122418208 循环优化技术：输入值嵌入、分支消除、减少子过程调用次数、循环合并、子过程合并、改变循环变量的迭代顺序、改变数组维数、循环展开、循环分块（提高cache命中率，利用cache line） video 利用局部性原理 CPU寄存器、内存、外存：优化缓存，如用restrict关键字说明指针间地址不存在关联。 并行编程 概念 指令并行：CPU流水线 分布式并行：MPI 共享存储式并行：OpenMP、OpenCL、OpenACC SIMD（Single Instruction Multi-Data） SIMD是CPU实现DLP（Data Level Parallelism）的关键 x86架构 SSE指令集（Streaming SIMD Extensions系列），使用XMM寄存器 AVX指令集（Advanced Vector Extensions系列），使用YMM寄存器，相比SSE扩充浮点 arm架构 neon v7/v8 riscv架构 riscv-v 优点：更高速的计算方法 缺点：更高的开发复杂度，专用的CPU组件 SIMT（Single Instruction Multi-Threads） CUDA/ROCM CUDA：NIDIA ROCM：AMD OpenMP（Open Multi-Processing） openMP介绍 高性能计算入门：OpenMP并行编程技术（一）:https://www.bilibili.com/video/BV1ss4y1K7q1?p=1 OpenMP编程三要素： 编译指导（Compiler Directive）：包含并行域指令、工作共享指令、同步指令、数据环境 运行库函数（Runtime Library Routines） 环境变量（Environment Variables） OpenMP模式：fork-join，是针对CPU的并行编程模型，基于线程 硬件内存模型： CPU在主存上有L1、L2、L3多级缓存 L3为多核共有，但L1和L2为每个核心私有，所以存在缓存一致性问题（False Sharing） OpenCL（Open Computing Language） 跨平台 基于C/C++语言 OpenACC 针对GPU，OpenMP模型在GPU上的扩展，支持AMD GPU openACC介绍 MPI MPI，Message Passing Interface，消息传递接口，主要用于进程间的消息传递（或数据传递） MPI介绍 性能分析 程序流程分析 静态分析：即对代码进行数据对象、函数接口封装和调用分析，工具understand 动态分析：即程序实际调用过程中分析执行的函数及流程，工具gprof ","date":"2025-01-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/hpc/","title":"【HPC】高性能计算总结"},{"content":"References C++ Core Guidelines 核心 C++ 语言构造的参考手册 现代 C++ 大典 cs106b C++知识总结 C++ 语言参考 优秀开源 github cpp trending Abseil Abseil 是一个由 Google 开源的 C++/python 库，提供了一组常用的工具和基础设施，用于补充 C++ 标准库中缺失的功能或提高效率。 C++17的string_view前身就是来自absl::string_view abseil-cpp Dlib Dlib 是一个流行的 C++ 库，主要用于机器学习、计算机视觉和图像处理。它提供了丰富的机器学习功能，支持多种算法和优化方法。 dlib XGBoost XGBoost 是一个高效的机器学习库，特别适用于梯度提升决策树（GBDT）算法，广泛用于回归、分类和排序任务。 xgboost Google\u0026rsquo;s glog (Google Logging Library) 功能：glog 是一个 C++ 日志库，提供了强大的日志记录功能，包括日志级别（DEBUG、INFO、WARNING、ERROR 和 FATAL）、日志输出到文件、以及日志格式化。 特点：简单易用，支持日志级别设置、日志输出的细粒度控制，还可以在生产环境中非常高效地记录日志。 链接：glog GitHub spdlog 功能：spdlog 是一个非常快速的 C++ 日志库，旨在提供低延迟、高性能的日志记录功能。 特点：spdlog 提供线程安全的日志记录支持，能够输出到控制台或文件，支持日志级别、日志格式等功能。 链接：spdlog GitHub folly (Facebook Open-source Library) 功能：folly 是 Facebook 开发的一个 C++ 库，包含了许多高性能的组件和工具，适用于大规模系统的开发。它包括内存管理、并发、容器、算法、IO等多个方面的扩展。 特点：folly 提供了大量与系统底层交互的工具，具有很高的性能，适用于对性能要求极高的应用。 链接：folly GitHub Boost 功能：Boost 是一个广泛使用的 C++ 库集合，提供了许多扩展标准库的功能，包括智能指针、正则表达式、线程、文件系统、算法等。 特点：Boost 提供了丰富的功能，经过多年的开发和优化，成为了 C++ 生态中非常重要的工具库之一。很多 C++ 标准库中的特性都源自 Boost（如 std::shared_ptr 和 std::filesystem）。 c++17中的std::filesystem、std::any、std::varient等直接来自于boost中。boost::program_options用于处理控制台的输入参数也是很方便 链接：Boost官网 fmt 功能：fmt 是一个现代化的、快速的格式化库，提供了类似 Python 中的 f-string 或 C# 中的 string interpolation 的功能。 特点：它允许开发者使用更加简洁和类型安全的方式进行字符串格式化。fmt 库的速度非常快，而且 API 设计符合现代 C++ 风格。 链接：fmt GitHub gflags 功能：gflags 是一个 Google 提供的命令行参数解析库，广泛用于解析应用程序启动时的命令行选项。 特点：gflags 提供了易于使用的命令行选项定义和管理功能，支持复杂的命令行解析需求，例如布尔值选项、枚举类型选项等。 链接：gflags GitHub tbb (Threading Building Blocks) 功能：tbb 是 Intel 提供的一个 C++ 并行编程库，旨在帮助开发者利用多核处理器，简化并行编程。 特点：提供了线程池、并行算法和数据结构，能够方便地进行并行化计算，且通过自动负载平衡使多核资源得到高效利用。 链接：TBB GitHub cppcoro 功能：cppcoro 是一个支持 C++20 协程的 C++ 库，提供了多种并发控制结构，如 task 和 awaiter，用于协程的高效实现。 特点：使 C++ 开发者能够高效地编写异步代码，同时保持代码简洁和易于理解。适合需要异步操作的场景。 链接：cppcoro GitHub Eigen 功能：Eigen 是一个高效的 C++ 数学库，专门用于矩阵运算、线性代数和数值计算。 特点：Eigen 提供了一个高性能的模板库，支持多维数组、矩阵操作以及高级的线性代数功能，广泛用于科学计算、机器学习等领域。 链接：Eigen GitHub C++语言参考 类和结构（class and struct） 类成员 override：重写父类虚函数 final：表示一个虚函数不能被进一步重写，或者表示一个类不能被继承 delete：禁用某个函数，如默认构造 default：明确地请求编译器为类生成默认实现 explicit：防止隐式转换调用其他函数 纯虚函数：virtual void doStep() = 0; // 要求派生类必须实现，否则派生类也将变成抽象类，无法实例化。 常成员函数const：只能调用其他常成员函数，不能修改成员变量（除mutable） static静态成员函数：不用实例化，可被直接调用 inline：内联请求，将代码插入调用函数处，较少调用栈开销 noexcept：表示该函数不会抛出异常 mutable：修饰变量可在常成员函数中修改 constexpr：表示该函数在编译时计算结果 friend：友元函数/类，允许外部函数或类在需要时访问类的私有实现 operator ：用于定义或重载类的运算符 自定义迭代器类：通常需重载==、!=、++、*解引用，实现begin、end 三/五/零之法则(rule of three) 因为C++类的特殊成员特性在实际应用可能产生用户非预期的效果，所以总结为法则用以规避可能出现的潜在风险 cpp references 资源获取即初始化(Resource Acquisition Is Initialization, RAAI) 与托管语言不同，C++ 没有自动回收垃圾机制，易导致内存泄露 C++ 将资源的生命周期与对象的生命周期所绑定（构造获取资源/析构释放资源，利用了栈上的变量在离开作用域的时候会析构的特性） c++11后的四大smart_point(shared_ptr、unique_ptr、weak_ptr、auto_ptr(在17中废除))采用了这种思想 善于利用析构特性进行自动内存回收管理，如std::lock_guard、Std::make_unique、Std::make_share等 运行时类型识别(Run Time Type Identification，RTTI) c++中RTTI的一些体现typeid、dynamic_cast、type traits 具体可以看runtime的库的函数__RTtypeid，rtti把所需的type_info(不同编译器会有所不同)信息放在vtable前，大概也是dynamic_cast要求父类必须有虚函数的原因吧 注意，取虚函数表地址时 （此处请注意环境在32位和64位下的区别，在32/64位下取对象a(带有虚函数的基类的实例)的首地址(虚函数表地址)有区分，即(int )\u0026amp;a 和 (long )\u0026amp;a的不同，为避免也可直接，（int）(int)(\u0026amp;classname)替换成（intptr_t）(intptr_t)(\u0026amp;classname)）** 用于编译时封装的 Pimpl Pimpl（Pointer to Implementation）是一种设计模式，常用于C++编程中以隐藏类的实现细节。Pimpl模式通过将实现细节移到一个私有的实现类中，从而提高代码的可维护性、降低编译时间以及实现二进制兼容性。\n编译依赖项的最小化。 接口和实现的分离。 可移植性。 一般实现： 1 2 3 4 5 6 7 // 头文件定义private类指针，源文件进行实现类impl // my_class.h class my_class { // ... all public and protected stuff goes here ... private: class impl; unique_ptr\u0026lt;impl\u0026gt; pimpl; // opaque type here }; 匿名函数 lambda表达式 引用 reference 指针 异常 模板 template 变长参数模板： 1 2 3 4 5 template \u0026lt;typename... Modules\u0026gt; explicit Sequential(Modules \u0026amp;\u0026amp;...modules) { modules_.reserve(sizeof...(Modules)); pushBack(std::forward\u0026lt;Modules\u0026gt;(modules)...); } // 递归展开，调用基础pushBack方法 完美转发：std::forward，保留原来值类型（左值/右值） std::optional：处理可能为null等值情况 std::enable_shared_from_this：在对象的成员函数中获取指向自身的智能指针，增加对象的引用计数，确保对象在异步操作或回调过程中不会被销毁 STL（Standard Template Library，标准模板库） 容器（Containers） vector.reserve 和 resize Vecotr.emplace_back和push_back std::reference_wrapper存储引用 std::initializer_list 轻量级初始化列表，不可修改; 算法（Algorithms） 迭代器（Iterators） 函数对象（Function Objects） C++ 14新特性 cppreference C++ 17新特性 cppreference C++17完全指南 并行算法库 不同编译器对并行算法库的支持: https://en.cppreference.com/w/cpp/compiler_support/17#C.2B.2B17_library_features 支持的算法 依赖tbb 使用示例 1 2 3 4 5 6 7 8 #include \u0026lt;algorithm\u0026gt; #include \u0026lt;execution\u0026gt; // std::sort(begin, end, comp); // origin std::sort(exe_policy, begin, end, comp); // 执行策略(execution policy)可选： // 1、std::execution::seq（顺序执行） // 2、std::execution::par（并行执行） // 3、std::execution::par_unseq（并行和向量化执行） C++ 20新特性 cppreference 其他 宏定义 #、#@、##、VA_ARGS 应用 1 2 3 4 5 6 7 8 9 10 #define Conn(x,y) x##y // 表示x连接y #define ToChar(x) #@x // 给x加上单引号 #define ToString(x) #x // 给x加上双引号 char* str = ToString(123132); // str=\u0026#34;123132\u0026#34;; int n = Conn(123,456); //n=123456; char* str = Conn(\u0026#34;asdf\u0026#34;, \u0026#34;add\u0026#34;) //str = \u0026#34;asdfadf\u0026#34;; char a = ToChar(1); // a=\u0026#39;1\u0026#39;; // char a = ToChar(123); // 编译器报错 #define debug(...) printf(__VA_ARGS__) // 用于宏定义中代表可变参数 运行时类型反射(Run Time Type Reflection, RTTR) 反射是一个进程检查、反省和修改其自身结构和行为的能力 众所周知，java、c#、Go等语言在语言层面支持了反射特性。而c++不支持反射，因为C++没有在语言层面提供返回类的metadata的能力，所以很多属性要靠手动注册，于是乎有人自造轮子搞了个反射机制（UE中的U++通过UHT和UBT来支持反射） ","date":"2025-01-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/c_plus_plus/","title":"【编程语言】 C++高级特性及实战"},{"content":"References mpi tutorial, github OMP、MPI培训文档 并行程序设计导论 介绍 MPI，Message Passing Interface，消息传递接口，主要用于进程间的消息传递（或数据传递） 是一种库描述，不是语言 是一种标准或规范，不是具体的实现（如Intel MPI，OpenMPI等） 是一种消息传递编程模型，并成为这种编程模型的代表和事实上的标准。 并行效率不降反增（加速比下降）：负载不均衡、并行粒度的选择 MPI四类通讯模式 逻辑进程排列：MPI虚拟进程拓扑 ","date":"2025-01-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/mpi/","title":"【HPC】 MPI介绍"},{"content":"References openACC resources OpenACC 笔记 OpenACC Programming and Best Practices Guide openacc-training-materials 介绍 Open Accelerators，OpenACC 编译器：PGI，nvc或nvc++，linux下PGI编译器安装 针对GPU，OpenMP模型在GPU上的扩展，支持AMD GPU 入门例程 示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // 代码 1：test.cpp，使用命令编译：nvc++ -o test -gpu=mem:managed test.cpp #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;openacc.h\u0026gt; // Function to initialize the vectors with values void initialize(std::vector\u0026lt;double\u0026gt;\u0026amp; a, std::vector\u0026lt;double\u0026gt;\u0026amp; b, int n) { for(int i = 0; i \u0026lt; n; ++i) { a[i] = static_cast\u0026lt;double\u0026gt;(i); b[i] = static_cast\u0026lt;double\u0026gt;(2 * i); } } // detect if GPU is actually running void detect_gpu() { double a[100], b[100]; #pragma acc parallel loop for (int i = 0; i \u0026lt; 100; ++i) { if (i == 10) { if (acc_on_device(acc_device_not_host)) printf(\u0026#34;Executing on GPU.\\n\u0026#34;); else printf(\u0026#34;Not executing on GPU.\\n\u0026#34;); } a[i] += b[i]; } } int main() { const int n = 1000000; // Size of the vectors std::vector\u0026lt;double\u0026gt; a(n), b(n), c(n); double *pa = a.data(), *pb = b.data(), *pc = c.data(); // Initialize vectors a and b initialize(a, b, n); detect_gpu(); // Using OpenACC to offload the following computation to an accelerator // and explicitly handle data movement #pragma acc data copyin(pa[0:n], pb[0:n]) copyout(pc[0:n]) { #pragma acc parallel loop for(int i = 0; i \u0026lt; n; ++i) pc[i] = pa[i] + pb[i]; } // Display the first 10 results for(int i = 0; i \u0026lt; 10; ++i) { std::cout \u0026lt;\u0026lt; \u0026#34;c[\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;] = \u0026#34; \u0026lt;\u0026lt; c[i] \u0026lt;\u0026lt; std::endl; } } 编译器选项 -ta=tesla: Compiler option to target NVIDIA Tesla GPUs. -Minfo=accel: Provides feedback about the code generated by the compiler. 常用命令 循环\n#pragma acc parallel: GPU 并行运算 #pragma acc kernels: Identifies a code block for parallelization, allowing the compiler to automatically manage parallelism. #pragma acc loop: Used within parallel or kernels regions to indicate loops that should be parallelized. 函数和变量 #pragma acc routine: 让一个函数可以在 GPU 代码中被调用（也可以在 CPU 代码调用）。 #pragma acc declare: Used for declaring variables or creating a data region. 数据传输 #pragma acc data: Manages data movement to and from the GPU. #pragma acc enter data: Specifies data that should be moved to the GPU. #pragma acc exit data: Specifies data to be moved back from the GPU. #pragma acc update: Synchronizes data between the host and the GPU. copy, copyin, copyout, create, present: Clauses for data construct to define how data is handled (e.g., whether it\u0026rsquo;s copied to/from the GPU or just created there). 线程精细控制 gang, worker, vector: Used with loop directive to control how loop iterations are distributed over parallel execution units. collapse(n): Collapses nested loops to enhance parallelism. reduction(operator:list): Performs a reduction operation (like sum, max) across parallel elements. ","date":"2025-01-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/openacc/","title":"【HPC】 OpenACC介绍"},{"content":"References OMP、MPI培训文档 并行程序设计导论 OpenMP tutorial github OpenMP详细介绍专栏 OpenMP official website openMP paper 介绍 OpenMP属于片上通信、跨核并行、共享存储式并行，支持跨平台共享内存方式的多线程编程接口（规范）。\nOpenMP编程三要素 编译指导（Compiler Directive，19）：包含并行域指令、工作共享指令、同步指令、数据环境 运行库函数（Runtime Library Routines，32） 环境变量（Environment Variables，9） Note OpenMP编程模型：内存共享模型，OpenMP是专为多处理器/核，共享内存机器所设计的。底层架构可以是UMA和NUMA。即(Uniform Memory Access和Non-Uniform Memory Access) 基于线程的并行性 显示的控制并行，极高的控制度 共享变量（默认），私有变量（通过private指定），数据竞争（Race Condition）（通过critical和atomic等同步机制） CPU在主存上有L1、L2、L3多级缓存，L3为多核共有，但L1和L2为每个核心私有，所以存在缓存一致性问题（False Sharing） Fork-Join模型：以一个主线程开始，通过fork创建并行线程组，通过join同步合并只留下主线程。 使用 编译 1 2 3 4 #include \u0026lt;omp.h\u0026gt; \u0026gt; gcc -fopenmp test.c \u0026gt; export OMP_NUM_THREADS=n # 指定线程数量，omp_get_num_threads()获取 \u0026gt; ./a.out 编译器指令 OpenMP编译器指令用于各种目的： 产生平行区域 在线程之间划分代码块 在线程之间分配循环迭代 序列化代码段 线程之间的工作同步 格式如下 #pragma omp \u0026lt;directive\u0026gt; [clause[[,] clause] ...] 通用规则：\n区分大小写 指令遵循编译指令的C/C++规则 每个指令只能指定一个指令名 每个指令最多使用一个后续语句，该语句必须是结构化块 通过在指令行末尾用反斜杠（“\\”）转义换行符，可以在后续行上“继续”长指令行 OpenMP基本指令 1、定义并行区域 #pragma omp parallel 用途: 定义一个并行区域，启动多个线程并行执行该区域中的代码。 示例： 1 2 3 4 #pragma omp parallel { // 并行执行的部分 } #pragma omp for 用途: 将循环的迭代分配给多个线程并行执行。 示例： 1 2 3 4 #pragma omp parallel for for (int i = 0; i \u0026lt; n; i++) { // 并行执行的循环体 } #pragma omp single 用途：指定代码块只由第一个到达线程执行，其他线程跳过该代码块。 2、同步机制(Synchronization) #pragma omp critical 用途: 定义一个临界区，保证代码块在同一时刻只被一个线程执行，以防止竞争条件。 1 2 3 4 5 6 7 8 9 10 11 12 13 float res; #pragma omp parallel { float B; int i, id, nthrds; id = omp_get_thread_num0; nthrds=omp_get_num_threads0; for(i=id;i\u0026lt;niters;i+=nthrds){ B= big _job(i); #pragma omp critical //Threads wait their turn. Only one at a time calls consume() res += consume (B); } } #pragma omp barrier 用途: 强制所有线程在此处同步，确保所有线程都执行到这一步后，才继续执行后续代码。 1 2 3 4 5 6 7 #pragma omp parallel { int id=omp_get_thread_num0; A[id] = big_calc1 (id); #pragma omp barrier // 只有当所有线程都到达barrier的时候才会继续运行 B[id] = big_calc2(id, A); } #pragma omp atomic 1 2 3 4 5 6 7 8 #pragma omp parallel { double tmp, B; B= DOITO; tmp = big ugly(B); #pragma omp atomic X+= tmp; } #pragma omp for 1 2 3 4 5 6 7 #pragma omp parallel { #pragma omp for for(i=0;i\u0026lt;n;i++){ // i is private by default do...; } } 3、变量的作用域 shared：默认情况下，并行区域外申明的变量在并行区域中是共享的，可以使用shared子句显式指定变量为共享的。 示例： 1 2 3 4 5 int a; #pragma omp parallel for shared(a) for (int i = 0; i \u0026lt; n; i++) { // a为公有变量 } private：每个线程在并行区域中有自己独立的变量副本，线程之间相互独立，互不干扰。并行区域内申明的变量默认为私有的，并行区域外申明的变量需要显式申明private 示例： 1 2 3 4 5 6 int a; #pragma omp parallel for private(a) for (int i = 0; i \u0026lt; n; i++) { int b; //a,b均为私有变量 } reduction： 用于将每个线程的私有变量在并行区域结束时进行归约（如求和、求最大值等），最终将结果存储到共享变量中。 示例： 1 2 3 4 5 int sum = 0; #pragma omp parallel for reduction(+:sum) for (int i = 0; i \u0026lt; 10; i++) { sum += i; } 4、调度方法 static：静态调度将循环的迭代均匀分配给所有线程，并且相邻的迭代会被分配在同一个线程，分配方式在程序开始执行时就已经确定。 示例: 1 2 3 4 #pragma omp parallel for schedule(static, 3) for (int i = 0; i \u0026lt; n; i++) { // 每个线程执行3个连续的迭代 } dynamic：动态调度在执行时分配迭代，每当一个线程完成当前分配的迭代时，它会动态获取下一个块的迭代。 guided：引导调度是一种动态调度的变体，但块大小（chunk size）随着任务的完成而逐渐减小。 auto：自动调度将调度策略的选择权交给编译器或运行时库，由它们决定最佳的调度方式。 runtime：运行时调度允许在程序运行时通过环境变量设置调度策略。 环境变量 OMP_SCHEDULE：负责规定调度方式。 OMP_NUM_THREADS：设置执行期间要使用的最大线程数。 OMP_PROC_BIND：启用或禁用线程绑定到处理器。有效值为TRUE或FALSE。 OMP_STACKSIZE：控制创建（非主）线程的堆栈大小。 ","date":"2025-01-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/openmp/","title":"【HPC】 OpenMP介绍"},{"content":"References HPC/ML/OS/SW性能工具总结 汇编/嵌入式编程工具 在 Linux 环境下进行汇编或嵌入式编程时，涉及的工具和程序非常广泛，包括编译器、调试工具、构建系统、性能分析工具等。下面是一些常见的汇编或嵌入式编程工具的详细介绍：\n汇编工具 (Assembly Tools) GAS (GNU Assembler) GAS 是 GNU 编译器集合（GCC）的一部分，专门用于将汇编语言转换成机器代码（即目标文件）。它支持多种体系结构，适用于嵌入式系统开发，通常与 GCC 配合使用。\n常用选项：\n-o \u0026lt;file\u0026gt;: 指定输出文件。 -g: 生成调试信息。 -D \u0026lt;macro\u0026gt;: 定义宏。 示例：\n1 as -o main.o main.s 交叉编译工具链 (Cross Compiler Toolchain) GCC (GNU Compiler Collection) GCC 是用于 C、C++、Fortran 等语言的编译器，常用于嵌入式编程中。它可以生成目标平台的代码，并支持交叉编译（cross-compilation），即在一种平台上为另一种平台编译代码。\n常用选项：\n-o \u0026lt;file\u0026gt;: 输出文件。 -mcpu=\u0026lt;target\u0026gt;: 指定目标架构（如 ARM、MIPS）。 -m32 或 -m64: 设置生成的代码是 32 位或 64 位。 示例：\n1 arm-none-eabi-gcc -o my_program.elf main.c Clang Clang 是 LLVM 项目的一部分，作为 GCC 的替代品，Clang 提供了高效的编译功能，并且具有更加友好的错误报告。它同样支持交叉编译，特别适合现代嵌入式编程和集成开发环境（IDE）中使用。\n常用选项：\n-target \u0026lt;target\u0026gt;: 指定目标平台。 -o \u0026lt;file\u0026gt;: 输出文件。 示例：\n1 clang -target arm-none-eabi -o my_program.elf main.c Binutils Binutils 是一组二进制工具，包括汇编器、链接器、调试器等，广泛用于嵌入式系统开发。ld 和 as 工具是其中最常用的，负责汇编、链接以及生成目标文件。\n常用工具：\nas：汇编源文件。 ld：链接目标文件生成最终的可执行文件。 objcopy：将目标文件转换为不同格式。 示例：\n1 2 as -o main.o main.s ld -o my_program.elf main.o 调试工具 (Debugging Tools) GDB (GNU Debugger) GDB 是一个功能强大的调试工具，适用于 C/C++ 等程序的调试。在嵌入式开发中，GDB 通常配合交叉编译工具链和硬件调试器（如 JTAG、SWD）一起使用。\n常用命令：\nrun：启动程序。 break \u0026lt;line\u0026gt;：在指定行设置断点。 step：单步执行，进入函数。 next：单步执行，不进入函数。 示例：\n1 gdb my_program.elf OpenOCD OpenOCD 是一个用于与目标硬件（如 ARM 处理器）进行通信的调试工具。它支持通过 JTAG 或 SWD 接口进行调试，可以与 GDB 配合使用。\n常用命令：\ntargets：列出连接的目标。 reset halt：复位并停止目标。 flash write_image erase \u0026lt;file\u0026gt; 0x0：将固件烧录到设备。 示例：\n1 openocd -f interface/stlink-v2.cfg -f target/stm32f4x.cfg JLink (SEGGER J-Link) JLink 是 SEGGER 提供的一个商业级调试器，支持 JTAG 和 SWD 接口，用于调试各种嵌入式设备。它提供高性能的调试功能，广泛用于工业和开发中。\n主要功能：\n支持高速调试，能够快速读写内存和寄存器。 与多种 IDE（如 Keil、IAR、Eclipse）兼容。 提供强大的脚本支持和自动化功能。 常用命令：\nconnect: 连接目标硬件。 r: 重置目标设备。 loadfile : 加载二进制文件到目标设备。 示例：\n1 JLinkExe -device STM32F407VG -if SWD LLDB LLDB 是 LLVM 提供的调试工具，类似于 GDB，但更加现代化。它具有更高效的性能，特别适用于基于 Clang 的编译工具链。\n常用命令：\nrun：启动程序。 breakpoint set：设置断点。 step：单步执行。 示例：\n1 lldb my_program.elf 构建工具 (Build Tools) Make Make 是一个非常常用的构建工具，使用 Makefile 管理项目的编译过程。它会根据 Makefile 中的规则自动执行编译、链接等操作，尤其适合嵌入式项目。\n常用命令：\nmake：构建项目。 make clean：清理编译结果。 示例：\n1 make -f Makefile CMake CMake 是一个跨平台的自动化构建工具，可以生成适用于不同平台的构建文件（如 Makefile、Ninja 文件等）。它在现代嵌入式开发中非常流行，支持复杂的项目构建配置。\n常用命令：\ncmake .：生成构建文件。 make：执行构建。 示例：\n1 2 cmake . make 其他工具 nm nm 是一个用于列出二进制文件（例如可执行文件、共享库、目标文件等）符号表的工具。它显示文件中定义和引用的符号，包括函数、变量等。通过 nm，用户可以查看符号的类型和地址信息。\n常用选项：\nnm : 列出指定文件的符号。 -g: 只显示全局符号。 -n 或 \u0026ndash;numeric-sort: 按地址排序符号。 示例：\n1 nm my_program|grep func Objdump objdump 用于反汇编和查看目标文件的详细信息。它可以显示汇编代码、符号表、段信息等，帮助开发人员理解程序的低级结构。\n常用命令：\nobjdump -d \u0026lt;file\u0026gt;：反汇编文件。 objdump -t \u0026lt;file\u0026gt;：显示符号表。 示例：\n1 objdump -d my_program Readelf readelf 用于显示 ELF 文件的详细信息，提供比 objdump 更加专注于 ELF 文件结构的查看。它支持查看 ELF 头、段、节区、符号表等信息。\n常用命令：\nreadelf -h \u0026lt;file\u0026gt;：显示 ELF 文件头信息。 readelf -S \u0026lt;file\u0026gt;：显示节区信息。 示例：\n1 readelf -h my_program 热点分析 热点分析通常通过使用 性能分析工具 来实现，工具会提供每个函数、方法、代码块的执行时间、调用次数、CPU 占用率等信息，帮助开发人员识别耗时最多的部分。\n常见的热点分析方法 调用图（Call Graph）：通过调用图分析函数之间的调用关系，找到调用最频繁的部分。 性能剖析（Profiling）：通过工具生成程序运行时的性能数据，分析哪些函数或代码块占用了最多的时间或资源。 热代码路径（Hot Code Path）分析：关注那些频繁执行的路径或分支，优化这些路径的性能。 内存热点分析：分析程序中哪些数据结构或对象频繁创建、销毁，导致内存管理不善或频繁的垃圾回收。 实际操作 函数级分析：分析程序中的每个函数，找出耗时最多的函数并进行优化。 多线程/并发分析：对于并发程序，热点分析还要考虑线程的执行时间、锁竞争和同步问题，识别线程间的性能瓶颈。 内存分析：分析内存的分配和释放，找出内存泄漏或频繁的内存分配导致的性能瓶颈。 性能分析工具 gprof：GNU profile工具 适用语言：C、C++、Pascal、Fortran 介绍：用于程序的性能优化以及程序瓶颈问题的查找和解决。通过分析应用程序运行时产生的“flat profile”，可以得到每个函数的调用次数，每个函数消耗的处理器时间，也可以得到函数的“调用关系图”，包括函数调用的层次关系，每个函数调用花费了多少时间。 缺点：对并行程序支持较差，不能提供细粒度的分析，主要适用于函数级别的性能分析。 使用步骤：\n1、用gcc、g++、xlC编译程序时，使用-pg参数，如：g++ -pg -o test test.cpp。编译器会自动在目标代码中插入用于性能测试的代码片断，这些代码在程序运行时采集并记录函数的调用关系和调用次数，并记录函数自身执行时间和被调用函数的执行时间。 2、执行编译后的可执行程序，如：./test。该步骤运行程序的时间会稍慢于正常编译的可执行程序的运行时间。程序运行结束后，会在程序所在路径下生成一个缺省文件名为gmon.out的文件，这个文件就是记录程序运行的性能、调用关系、调用次数等信息的数据文件。 3、使用gprof命令来分析记录程序运行信息的gmon.out文件，如：gprof test gmon.out。则可以在显示器上看到函数调用相关的统计、分析信息。 Perf 适用语言： C, C++ 平台： Linux 特点： Perf 是 Linux内置的性能分析工具，可用于分析 CPU 使用率、内存访问、系统调用等。它是一个命令行工具。适用于深度的 Linux 系统级性能分析。 缺点：需要一定的学习成本，报告可能较为复杂。 Perf是一个很大的工具，此处仅展示分析某个应用的的用法。 使用步骤（使用gprof的那个可执行文件）：\n1、perf record ./test，部分性能参数需要root权限 2、perf report References\nhttps://www.brendangregg.com/perf.html perf tutorial WSL2安装perf perf原理及火焰图 perf分析c热点函数 perf简单例子-程序调用栈火焰图\n1 2 3 4 5 6 7 8 9 10 11 perf record -F 99 -p 2347 -g -- sleep 30 # perf record表示采集系统事件, 没有使用 -e 指定采集事件, 则默认采集 cycles(即 CPU clock 周期), -F 99 表示每秒 99 次, -p 2347 是进程号, 即对哪个进程进行分析, -g 表示记录调用栈, sleep 30 则是持续 30 秒. # 统计每个调用栈出现的百分比, 然后从高到低排列 perf report -n –stdio # 解析perf收集的信息 perf script -i perf.data \u0026amp;\u0026gt; perf.unfold # 生成折叠后的调用栈 # 使用开源软件：https://github.com/brendangregg/FlameGraph.git ./stackcollapse-perf.pl perf.unfold \u0026amp;\u0026gt; perf.folded # 生成火焰图 ./flamegraph.pl perf.folded \u0026gt; perf.svg perf简单例子-分析热点函数、指令\n1 2 3 4 5 6 7 8 # 通过-g选项保留源代码信息 gcc -g test.c -o test # 通过perf record命令对test程序采样，-g表示采样调用栈 perf record -F 999 ./test # 查看热点分布 perf report # 查看热点函数testA中的热点指令及语句 perf annotate --stdio --symbol=testA Intel VTune Profiler 适用语言： 多语言支持 平台： Windows、Linux 特点： Intel VTune Profiler 是一个功能强大的性能分析工具，可用于分析 CPU 使用率、内存访问、多线程性能等。适用于 Intel 处理器。 可以看到 perf 看不到L3cache 等硬件特性 references\nhttps://www.cnblogs.com/bandaoyu/p/16751995.html https://zhuanlan.zhihu.com/p/12642264312 https://blog.csdn.net/yaojingqingcheng/article/details/120335335 TAU 适用语言： C、C++、python 官网：https://www.cs.uoregon.edu/research/tau/home.php 特点： 是一个面向MPI与OpenMP并行程序的profiler，在目前看到的OpenMPI的Profiler中算是比较健全的一个。相比于Intel的vtune面向OpenMPI的时候会有些限制，TAU可以根据不同的MPI发行版重新编译。 references\nTAU Profiler安装 python 使用性能测试工具TAU测试MPI程序记录 深入解析TAU工具 GPU 分析工具 官方全部工具\ncuda-gdb cuda-gdb -g -G编译选项 Nsight Compute nvprof，计算能力8.0以下使用 注意系统要求（如win11 ws2才支持）：system-requirements、unknown-error-on-device-0-when-running-ncu-on-wsl 用于深入分析单个 CUDA 内核的性能瓶颈，帮助你优化内核代码。 通常，你可以使用 Nsight Systems 先找到瓶颈的 CUDA 内核，然后使用 Nsight Compute 对这些内核进行详细的性能分析。 使用方案：\n1、用户界面：使用ncu-ui命令 2、CLI方式 Nsight System 用于高层次的系统级性能分析，帮助你识别整个应用的瓶颈，例如 GPU 内核启动延迟、数据传输等问题。 UserGuide 使用方案：\n类似Nsight Compute，但支持jupyter等 可以支持应用执行中的很多系统调用情况 ComputeSanitizer https://docs.nvidia.com/compute-sanitizer/ComputeSanitizer/index.html#id1\n功能正确性检查工具，包含：memcheck、racecheck、initcheck、synccheck等 cuda12.0以下内存检查使用CUDA-MEMCHECK，以上使用ComputeSanitizer HPCtoolkit 适用语言： C、C++、CUDA 官网：HPCToolkit 特点：支持CUDA 内存分析工具 gdb：-g源码调试 tsan TSan（ThreadSanitizer）是一个用于检测多线程程序中的 数据竞争 和 线程安全问题 的工具。它是由 Google 开发的，用于帮助开发者发现并修复多线程程序中的并发问题，这些问题可能导致难以复现的错误和难以调试的行为。\n1. 什么是数据竞争？ 数据竞争是指多个线程并发地访问同一块内存区域，并且至少有一个线程在写入该内存区域，而其他线程可能在读或写该内存。数据竞争通常会导致不可预测的程序行为，比如程序崩溃、结果错误等。数据竞争的问题尤其难以发现，因为它们通常依赖于程序执行的特定时序和上下文。\n2. TSan 的功能 ThreadSanitizer 是一种 动态检测工具，它能够监测并发程序中的线程交互，并在检测到数据竞争时，给出详细的报告。它通过 **插桩（Instrumentation） **方式，插入检查代码，追踪每个线程对共享内存的访问，以此来检测潜在的数据竞争。\n具体功能包括：\n检测数据竞争：在多线程程序中，TSan 能够发现不同线程对同一内存位置的并发访问（读-写或写-写），并且报告潜在的数据竞争。 报告细节：当 TSan 检测到数据竞争时，会提供详细的错误报告，包含竞争发生的栈信息、线程信息、访问的内存位置等，帮助开发者定位问题。 跨平台支持：TSan 支持 Linux、macOS、Android 和其他平台，通常与 Clang 和 GCC 编译器兼容。 3. 如何使用 TSan TSan 是通过编译器插件实现的，因此需要在编译程序时启用它。以下是启用 TSan 的基本步骤：\n1 2 3 4 5 6 7 8 9 10 # 1、编译时启用 TSan，使编译器将 TSan 插桩到代码中，在程序运行时启用线程安全检查。 g++ -fsanitize=thread -g test.cpp -o test # 2、运行时，程序将被 TSsan 监控，检测线程间的竞争。 ./test # 如果程序中有数据竞争，TSan 会输出类似以下的报告： ThreadSanitizer: data race in function \u0026#39;foo\u0026#39; at address 0x601000000020 #0 0x7f89b5cb5e6f in foo #1 0x7f89b5cb5e79 in bar #2 0x7f89b5cb5f89 in main TSan 会提供详细的栈跟踪，指出哪些线程、哪些内存地址、在哪些函数中发生了数据竞争。 4. TSan 的工作原理 TSan 通过对程序进行 插桩，在程序中每次内存访问（读/写）时插入检查代码，追踪每个线程对内存的访问。它会记录每个线程对共享内存的访问并进行比较，以判断是否存在数据竞争。\n主要机制：\n内存访问追踪：TSan 会追踪每个线程对内存地址的访问情况，记录访问的时间戳和线程标识。 同步原语检测：TSan 会检查线程之间的同步操作（如 mutex、lock、atomic）是否正确使用，确保线程安全。 数据竞争检测：如果两个线程访问同一内存位置，并且至少一个是写操作，TSan 会标记为潜在的数据竞争。 5. TSan 检测的线程安全问题 除了检测数据竞争，TSan 还可以帮助识别以下并发编程中的常见问题：\n死锁：如果两个线程因相互等待而导致死锁，TSan 也可以通过检测锁的顺序和依赖关系来帮助识别死锁。 非原子操作：在多线程环境中，如果某些操作不是原子的，可能会导致竞态条件。TSan 可以通过对同步操作的检查，帮助发现这些问题。 不当的内存同步：如果线程没有适当的同步机制（如 mutex 或 atomic）来协调对共享数据的访问，可能会出现竞态条件，TSan 会标记这些不安全的内存访问。 6. TSan 的优点和限制\n优点：能够捕获到很难复现的多线程问题，提供详细的报告，包括访问的内存位置、线程栈、数据竞争的上下文，帮助开发者快速定位并修复问题。 限制：会有一定的性能开销（开发阶段使用），可能不会检测所有类型的并发问题，特别是某些边缘情况或者深度依赖于硬件的并发问题。 AddressSanitizer (ASan) ASan（AddressSanitizer）是一个用于检测 内存错误 的强大工具，特别是针对 缓冲区溢出、堆栈溢出、使用后释放（use-after-free）等常见内存问题。ASan 是由 Google 开发的，作为一个 编译时检测工具，它可以在程序运行时检测出许多类型的内存错误，并提供详细的错误报告。ASan 可以用于 C 和 C++ 等语言，广泛应用于开发和测试阶段，帮助开发者发现和修复难以调试的内存错误。\nASan 的功能 ASan 的核心功能是通过 内存访问跟踪 来检测程序中的各种内存错误。它能有效检测以下几类常见的内存问题： 缓冲区溢出（Buffer Overflow）：当程序写入超出分配内存的区域时，会导致数据损坏或程序崩溃。 堆栈溢出（Stack Overflow）：当程序的栈内存超出预定范围时，可能会覆盖局部变量或函数返回地址。 使用后释放（Use-After-Free）：指在内存被释放后，程序仍然访问该内存。 内存泄漏（Memory Leak）：指程序分配了内存但没有释放，导致内存消耗不断增加。 双重释放（Double Free）：指在释放内存后再次释放该内存，可能导致程序崩溃。 未初始化内存读取（Use of Uninitialized Memory）：程序读取未初始化的内存内容，可能导致不可预测的行为。 ASan 的工作原理 ASan 通过 编译器插桩（Instrumenting Compiler）和 运行时库（Runtime Library）的配合工作来检测内存错误。 编译时插桩：在程序的源代码编译过程中，ASan 会插入额外的检查代码，这些代码会在程序运行时检查每个内存访问，确保它们在合法的内存范围内。 内存分配替换：ASan 会替换程序的 内存分配函数（如 malloc、free、new、delete）来监控内存的分配和释放操作。 内存红区（Redzones）：ASan 在每个内存块的前后插入一些特殊的 \u0026ldquo;红区\u0026rdquo;（Redzones），这些区域用于检测 越界访问。如果程序试图访问红区，ASan 会报告错误。 运行时检测：当程序访问非法内存时，ASan 会触发 运行时错误检测，并输出详细的错误信息（如错误的内存地址、堆栈信息等）。 如何使用 ASan 要启用 AddressSanitizer，您需要在编译时添加 -fsanitize=address 选项，并启用调试信息 -g（以便于调试）。 1 g++ -fsanitize=address -g -o test test.cpp ASan 错误报告 当 ASan 检测到内存错误时，它会生成详细的错误报告。该报告通常包含以下信息： 错误类型：如 use-after-free、buffer overflow、stack overflow 等。 错误位置：报告发生错误的内存地址，指出程序在哪里进行非法内存访问。 调用栈：ASan 会提供程序的调用栈信息，帮助开发者快速定位问题。 内存布局：显示内存分配情况，包括程序访问的内存区域和红区位置。 ASan 检测的内存问题 ASan 可以检测的内存问题包括： 堆栈溢出（Stack Overflow）：当局部变量超出栈边界时，ASan 会报告堆栈溢出。 缓冲区溢出（Buffer Overflow）：当访问超出数组或缓冲区的范围时，ASan 会检测到缓冲区溢出。 使用后释放（Use-After-Free）：在内存被释放后，如果程序继续使用该内存，ASan 会报告此错误。 内存泄漏（Memory Leak）：ASan 可以检测到程序中未释放的内存（通过启用 -fsanitize=address 和使用 ASAN_OPTIONS=detect_leaks=1）。 双重释放（Double Free）：当程序尝试两次释放同一块内存时，ASan 会报告此问题。 未初始化内存访问（Use of Uninitialized Memory）：当程序访问未初始化的内存时，ASan 会报告此错误。 ASan 的优点和缺点 优点：高效的内存错误检测、易于使用、详细的错误报告、广泛支持。 缺点：性能开销、仅支持动态检测、依赖编译器。 valgrind 平台：Linux / macOS / Windows（通过 Cygwin） 用途：Valgrind 是一款开源的动态分析工具，广泛用于 内存分析，如查找内存泄漏、内存越界等问题。 功能： Memcheck：用于检测内存泄漏、越界访问和未初始化的内存读取。 Cachegrind：用于缓存行为分析，评估 CPU 缓存的命中率。 Callgrind：支持函数级别的性能分析，提供详细的 CPU 性能数据。 Helgrind：用于检测并发程序中的数据竞争。 适用场景：适用于内存优化、程序调试和多线程程序的性能分析。 使用方式：通过命令行运行程序时加上 valgrind，比如 valgrind \u0026ndash;leak-check=full ./my_program。 优点：强大的内存分析功能，能够检测很多潜在的错误。 缺点：运行时开销较大，程序执行速度可能会减慢。 eBPF (Extended Berkeley Packet Filter) 类型：内核性能分析工具 功能：eBPF 可以用于监控系统的 CPU 使用情况、内存分配、I/O 性能、网络流量 等。 使用场景：eBPF 适用于 Linux 系统的全栈性能分析，特别是在容器化环境中（如 Kubernetes、Docker）。 优点：能够高效且低开销地进行性能分析，实时提供系统各个层次的性能数据。 缺点：需要一定的学习成本，并且工具的设置可能比较复杂。 在现代计算中，性能优化是提高程序效率、响应时间、资源利用率等重要方面的核心工作。不同类型的性能瓶颈可以通过不同的优化策略来解决，常见的优化策略包括并行度优化、数据传输优化、存储器访问优化、向量化优化、负载均衡优化和多线程扩展性优化。下面将详细介绍每个优化策略。\n性能优化策略 1. 并行度优化（Parallelism Optimization） 并行度优化是指将计算任务拆分成多个独立的子任务，利用多核处理器或多台机器的计算能力来加速计算过程。并行度优化主要关注如何高效地将任务分解并利用多个计算资源。\n核心策略： 任务划分：将计算任务划分为多个相对独立的子任务，确保每个子任务都能并行执行。划分可以基于数据分割或功能划分。 并行模型选择：选择合适的并行编程模型，如多线程、分布式计算、SIMD（单指令多数据）等，依赖于硬件架构和应用的需求。 粒度控制：控制任务的划分粒度，避免过多的细小任务带来的上下文切换开销。任务太小可能引发更多的线程启动和调度开销，反而会降低性能。 避免线程同步问题：在并行化时，尽量减少线程间的同步需求，如锁的竞争等，因为锁竞争会增加线程等待时间，影响性能。 实例： 多核处理器利用：将计算密集型任务分配给不同的 CPU 核心。 GPU 加速：使用图形处理单元（GPU）进行并行计算，例如深度学习中广泛使用的并行训练。 2. 数据传输优化（Data Transfer Optimization） 数据传输优化关注的是如何减少计算过程中数据的传输开销，尤其是在多核、多节点或大规模并行计算环境中，数据传输的延迟和带宽限制可能成为性能瓶颈。\n核心策略： 减少数据传输量：尽量减少进程之间、计算节点之间的通信量。可以通过局部计算、减少数据的复制或压缩数据传输来减少带宽消耗。 数据预取：根据访问模式预测数据的需求，提前加载数据到缓存中，从而减少等待时间。 内存映射与共享内存：使用共享内存或内存映射文件来避免频繁的进程间通信，特别是在多进程或多线程的应用程序中。 局部性优化：将数据分配到物理内存的本地区域，减少跨节点或跨芯片的数据传输。 实例： 在多节点集群中，避免每次计算都从主存储器加载大量数据，而是通过缓存和局部数据共享来减少传输。 在 GPU 和 CPU 之间，使用较小的批次数据传输，以减少 GPU 与主机之间的通信开销。 3. 存储器访问优化（Memory Access Optimization） 存储器访问优化主要目的是减少内存访问延迟，提高内存带宽的利用率。内存访问模式的不合理会造成严重的性能瓶颈，尤其是对于大规模数据的计算密集型任务。\n核心策略： 数据局部性优化：通过优化数据访问模式，提高数据在缓存中的命中率。可分为时间局部性（重复访问相同数据）和空间局部性（访问数据时的空间邻近性）。 缓存优化：优化程序数据结构，使数据在缓存中更容易命中，从而减少访问主内存的次数。使用预取技术和合理的缓存对齐可以显著提高缓存命中率。 避免不必要的内存访问：减少冗余的内存访问，如不必要的内存复制或多次访问相同的数据。 非一致性存储模型优化：在多处理器系统中，保持各个缓存一致性可能导致额外的开销，优化缓存一致性协议和访问策略可以提升性能。 实例： 优化矩阵运算时，按行或按列的顺序访问数据，以提高缓存命中率。 使用 NUMA（Non-Uniform Memory Access）架构时，避免频繁地访问远程内存，尽量保持计算和数据存储在同一个节点的本地内存中。 4. 向量化优化（Vectorization Optimization） 向量化是指将标量操作转换为向量操作，在单条指令中处理多个数据元素。现代处理器，尤其是具有SIMD（单指令多数据）指令集的处理器，能够通过向量化提升计算效率。\n核心策略： 利用SIMD指令：使用 SIMD 指令集（如 AVX、SSE、NEON 等）对数据进行向量化操作，在单个指令周期内处理多个数据元素。 编译器自动向量化：现代编译器（如 GCC、Clang、Intel Compiler）能够自动识别可以向量化的循环，并进行相应优化。 手动优化：在一些复杂的场景中，可以手动编写 SIMD 代码，通过内联汇编或编写特定的 SIMD 库来实现向量化优化。 数据对齐：确保数据存储在合适的内存地址对齐，以便在向量化时避免额外的开销。 实例： 在图像处理、科学计算等应用中，使用 SIMD 向量化技术对每个像素或数据点执行并行操作（如加法、乘法等）。 5. 负载均衡优化（Load Balancing Optimization） 负载均衡优化是指在多处理器、多核心或分布式系统中，合理分配计算任务，以避免某些处理器过载或闲置，从而提高计算资源的利用率。\n核心策略： 任务划分：合理划分任务，将计算负载均匀地分配给不同的计算单元。划分粒度要合适，避免过细的划分导致调度开销。 动态负载均衡：在运行时动态调整任务的分配，以应对负载变化和计算资源的不均衡。例如，在多核环境中，动态地将任务从负载较重的核心转移到空闲的核心上。 数据局部性和负载均衡的结合：在多核或多节点环境中，除了考虑负载均衡，还要考虑任务和数据的局部性，避免数据传输引发的性能瓶颈。 实例： 在分布式计算中使用负载均衡策略，避免某些计算节点过载，其他节点空闲。 在多核处理器上，使用调度算法动态调整任务负载。 6. 多线程扩展性优化（Multithreading Scalability Optimization） 多线程扩展性优化关注的是如何使程序在多核或多处理器系统上运行时能够保持良好的性能提升，尤其是在线程数增加时，如何避免性能的下降。\n核心策略： 避免线程竞争：合理设计程序，减少线程间的资源竞争。过多的锁、临界区和线程同步会导致线程间的阻塞，从而影响程序的扩展性。 线程数的调优：选择合适的线程数，避免过多线程带来的上下文切换开销。通常，线程数不应超过处理器核心数。 工作窃取（Work Stealing）：在多线程应用中，可以使用工作窃取算法，通过让空闲线程从负载较重的线程中窃取任务，平衡负载，提升扩展性。 任务划分粒度：避免过小或过大的任务粒度，过小的任务会增加线程调度开销，过大的任务则可能导致资源利用率不足。 实例： 在多核机器上，动态调整线程数，以适应任务的计算需求和机器的硬件能力。 在并行计算中，使用线程池和任务队列来有效管理线程的创建和销毁。 环境模拟 docker qemu docs\nqemu安装ARM QEMU启动ARM64 Linux内核 大致思路是： 安装qemu-system-aarch64（ARM-64bit）模拟器； 安装aarch64-linux-gnu（ARM-64bit）交叉编译器； 交叉编译linux源码，得到ARM64 Linux内核镜像； 交叉编译busybox源码，使用busybox制作initramfs； 最后使用qemu-system-aarch64启用ARM64 Linux内核； 环境管理/运维 微服务 k8s python conda 其他 内容比较compare Beyond Compare 代码调用关系 cflow：静态分析工具，用来生成 C/C++ 程序的调用图。 Callgrind：动态函数分析 ","date":"2025-01-05T00:00:00Z","permalink":"https://loveleaves.github.io/p/tool/","title":"【Tool】 记录各种用到的工具"},{"content":"介绍 CUDA（Compute Unified Device Architecture，统⼀计算架构）是由 NVIDIA 开发的并行计算平台和编程模型，旨在利用 NVIDIA GPU（图形处理单元）强大的并行计算能力来加速计算密集型任务。CUDA 提供了一种编程接口，让程序员能够直接访问 GPU 上的计算资源。通过并行化计算任务，可以显著提升执行效率。GPU 相较于 CPU，在处理大量并行任务时具有显著的优势，通常拥有成百上千的处理核心（CUDA 核心），能够同时执行大量的操作。\n核心指标：核心数、GPU显存容量、GPU计算峰值、显存带宽 GPU不能单独计算，CPU+GPU组成异构计算架构：CPU起到控制作用，一般称为主机（Host）；GPU可以看作CPU的协处理器，一般称为设备（Device）；主机和设备之间内存访问一般通过PCIe总线链接。 CUDA 提供两层API接口：CUDA驱动(driver)API和CUDA运行时(runtime)API CUDA驱动(driver)API cuda driver使用方式：libcuda.so和cuda.h，cuda-driver-api context管理机制：方便管理device 手动管理的context,cuCtxCreate(手动管理，以堆栈方式push/pop) 自动管理的context,cuDevicePrimaryCtxRetain(自动管理，runtime api以此为基础) 首先需要调用culnit初始化驱动API CUDA运行时(runtime)API cuda runtime使用方式：libcudart.so和cuda_runtime.h。runtime API随cuda toolkit发布 主要内容：核函数的使用、线程束布局、内存模型、流的使用 主要实现：归约求和、仿射变换、矩阵乘法、模型后处理 References 《CUDA 并行程序设计-GPU 编程指南》 第5、6、9章 https://github.com/loveleaves/ML_CPP/tree/main/ParallelFramework/CUDA cuda docs、programming-guide、best-practices-guide CIS 5650-GPU Programming and Architecture CUDA笔记 CUDALibrarySamples CUDA框架 基础编程框架 单文件example.cu编程框架\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 header inclusion const or macro definition declarations of C++ functions and CUDA kernels int main() { allocate host and device memory initialize data in host memory transfer data from host to device launch (call) kernel to do calculations in the device transfer data from device to host free host and device memory } definitions of C++ functions and CUDA kernels 编译指令\n1 nvcc -arch=sm_XY -code=compute_XY -o example example.cu nvcc编译工作原理 host code（standard C/C++ compiler）、device code（compiled into PTX/cubin） CUDA程序兼容性考虑：在将源代码编译为 PTX 代码时，需要用选项-arch=compute_XY指定一个虚拟架构的计算能力，用以确定代码中能够使用的CUDA功能。在将PTX代码编译为cubin代码时，需要用选项-code=sm_ZW指定一个真实架构的计算能力，用以确定可执行文件能够使用的GPU。 https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html Deep Dive into Triton Internals GPU设备设置 1、获取GPU设备数量 1 2 int iDeviceCount = 0; cudaGetDeviceCount(\u0026amp;iDeviceCount); 2、设置GPU执行时使用的设备 1 2 int iDev = 0; cudaSetDevice(iDev) 内存管理 主设内存管理 Note：GPU内存管理runtime接口传入的是双重指针。\n内存分配：malloc、cudaMalloc 数据传递：memcpy、cudaMemcpy 内存初始化：memset、cudaMemset 内存释放：free、cudaFree 主设内存传递\n1 cudaError_t cudaMemcpy(dst, src, count, kind); 枚举类型kind可取值：\ncudaMemcpyHostToHost，表示从主机复制到主机。 cudaMemcpyHostToDevice，表示从主机复制到设备。 cudaMemcpyDeviceToHost，表示从设备复制到主机。 cudaMemcpyDeviceToDevice，表示从设备复制到设备。 cudaMemcpyDefault，表示根据指针dst和src所指地址自动判断数据传输的方向。这要求系统具有统一虚拟寻址（unifiedvirtualaddressing）的功能（要求64位的主机）。 数据同步Synchronize 调用输出函数时，输出流是先存放在缓冲区的，而缓冲区不会自动刷新。只有程序遇到某种同步操作时缓冲区才会刷新。所以当要打印某个数据时，要先使用函数cudaDeviceSynchronize显式地同步主机与设备，促使缓冲区刷新。 核函数（Kernel function） 1、核函数在GPU上进行并行执行 2、注意： （1）限定词__global__ 修饰（可在void前后） （2）返回值必须是void （3）对于N是非blockSize整数倍时，必要时添加if，即使导致条件分支 注意事项：\n1、核函数只能访问GPU内存 2、核函数不能使用变长参数 3、核函数不能使用静态变量 4、核函数不能使用函数指针 5、核函数具有异步性 6、其他：核函数不支持C++的iostream 自定义设备函数 用__global__修饰的函数称为核函数，一般由主机调用，在设备中执行。如果使用动态并行，则也可以在核函数中调用自己或其他核函数。 用__device__修饰的函数叫称为设备函数，只能被核函数或其他设备函数调用，在设备中执行。 用__host__修饰的函数就是主机端的普通C++函数，在主机中被调用，在主机中执行。对于主机端的函数，该修饰符可省略。之所以提供这样一个修饰符，是因为有时可以用__host__和__device__同时修饰一个函数，使得该函数既是一个C++中的普通函数，又是一个设备函数。这样做可以减少冗余代码。编译器将针对主机和设备分别编译该函数。 不能同时用__device__和__global__修饰一个函数，即不能将一个函数同时定义为设备函数和核函数。 也不能同时用__host__和__global__修饰一个函数，即不能将一个函数同时定义为主机函数和核函数。 线程模型 线程的组织结构是由执行配置（executionconfiguration）\u0026laquo;\u0026lt;grid_size,block_size\u0026raquo;\u0026gt;决定的。这里的grid_size（网格大小）和block_size（线程块大小），对应核函数内部的内建变量 gridDim、blockDim、blockIdx、threadIdx 注意GPU系列对应框架最大允许的线程块大小，如1024 线程束：线程调度、管理 CUDA错误检查 运行时错误检测 所有CUDA运行时API函数都是以cuda为前缀的，而且都有一个类型为cudaError_t的返回值，代表了一种错误信息。只有返回值为cudaSuccess时才代表成功地调用了API函数。\n功能正确性检查 内存检查、越界访问、异常检查等 checktool 获得GPU加速的关键 CUDA事件计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start)); cudaEventQuery(start); // 此处不能用 CHECK 宏函数，对处于TCC 驱动模式的 GPU 来说可以省略，但对处于 WDDM 驱动模式的GPU来说必须保留。 需要计时的代码块 CHECK(cudaEventRecord(stop)); CHECK(cudaEventSynchronize(stop)); float elapsed_time; CHECK(cudaEventElapsedTime(\u0026amp;elapsed_time, start, stop)); printf(\u0026#34;Time = %g ms.\\n\u0026#34;, elapsed_time); CHECK(cudaEventDestroy(start)); CHECK(cudaEventDestroy(stop)); 程序性能分析 Nsight Compute，详见tools\n影响GPU加速的关键因素 数据传输的比例：主设数据传输 算术强度（arithmeticintensity）：计算相比于数据传输耗时的占比 并行规模：数据规模要尽量匹配SM等计算资源 因此, 在编写与优化CUDA程序时，一定要想方设法（主要是指仔细设计算法）做到以下几点\n减少主机与设备之间的数据传输。 提高核函数的算术强度。 增大核函数的并行规模。 CUDA中的数学函数库 https://docs.nvidia.com/cuda/cuda-math-api/\n单精度浮点数内建函数和数学函数（singleprecisionintrinsics and math functions）。使用该类函数时不需要包含任何额外的头文件。 双精度浮点数内建函数和数学函数（doubleprecisionintrinsicsandmathfunctions）。使用该类函数时不需要包含任何额外的头文件。 半精度浮点数内建函数和数学函数（halfprecisionintrinsicsandmathfunctions）。使用该类函数时需要包含头文件\u0026lt;cuda_fp16.h\u0026gt;。 整数类型的内建函数（integerintrinsics）。使用该类函数时不需要包含任何额外的头文件。 类型转换内建函数（typecasting intrinsics）。使用该类函数时不需要包含任何额外的头文件。 单指令-多数据内建函数（SIMDintrinsics）。使用该类函数时不需要包含任何额外的头文件。 内存组织 分层思想，平衡成本和效率（在编码中体现为高内聚、低耦合） https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-variable-specifier 不同硬件架构的内存编排不一定相同 全局内存（global memory） 核函数中的所有线程都能够访问其中的数据，容量是所有设备内存中最大的。基本上就是显存容量。 主要为核函数提供数据，并在主机与设备及设备与设备之间传递数据。 host端访问数据：使用runtime接口cudaGetSymbolAddress() / cudaGetSymbolSize() / cudaMemcpyToSymbol() / cudaMemcpyFromSymbol() 同步函数__syncthreads()：只是针对同一个线程块中的线程的，不同线程块中线程的执行次序依然是不确定的（不同线程块数据要保证不依赖）。 在CUDA中还有一种内部构造对用户不透明的（nottransparent）全局内存，称为CUDAArray。CUDAArray使用英伟达公司不对用户公开的数据排列方式，专为纹理拾取服务。 动态全局内存\n生命周期（lifetime）不是由核函数决定的，而是由主机端决定的（cudaMalloc、cudaFree） 静态全局内存\n静态全局内存变量由以下方式在任何函数外部定义： 1 2 __device__ T x; // 单个变量 __device__ T y[N]; // 固定长度的数组 在核函数中，可直接对静态全局内存变量进行访问，并不需要将它们以参数的形式传给核函数。 常量内存（constant memory） 有常量缓存的全局内存，一共仅有64KB，位于常量内存空间，核函数外部用__constant__定义。 它的可见范围和生命周期与全局内存一样，host端访问数据与全局内存一样。 由于有缓存，常量内存的访问速度比全局内存高，但得到高访问速度的前提是一个线程束中的线程（一个线程块中相邻的32个线程）要读取相同的常量内存数据。 纹理内存（texture memory）和表面内存（surface memory） 类似于常量内存，也是一种具有缓存的全局内存，有相同的可见范围和生命周期，而且一般仅可读（表面内存也可写）。不同的是，纹理内存和表面内存容量更大，而且使用方式和常量内存也不一样。 对于计算能力5.0以上的GPU来说，将某些只读全局内存数据用__ldg()函数通过只读数据缓存（read-onlydatacache）读取，既可达到使用纹理内存的加速效果，又可使代码简洁。对帕斯卡架构和更高的架构来说，全局内存的读取在默认情况下就利用了__ldg()函数，所以不需要明显地使用它。 寄存器（register）和 局部内存（local memory） 存储函数入参、内建变量和临时变量等，32位。 计算能力5.0~9.0的GPU，每个中都是64K的寄存器数量，Fermi架构只有32K； 考虑：每个线程块使用的最大数量、每个线程的最大寄存器数量 局部内存是全局内存的一部分，寄存器溢出是保存在局部内存中。 共享内存（shared memory） 和寄存器类似，存在于芯片上，具有仅次于寄存器的读写速度，extern __shared__ float shared[]定义，数组大小在运行时确定,或__shared__ float shared[100]。 共享内存对整个线程块可见，其生命周期也与整个线程块一致。 一个线程块中的所有线程都可以访问该线程块的共享内存变量副本，但是不能访问其他线程块的共享内存变量副本。 注意避免n路bank冲突（n很大场景，类似TLB组相联）：共享内存在物理上被分为32个（刚好等于一个线程束中的线程数目，即内建变量warpSize的值）同样宽度的、能被同时访问的内存bank。在所有其他架构中，每个bank的宽度为4字节。当同一线程束内的多个线程不同时访问同一个bank中不同层的数据，该线程束对共享内存的访问就只需要一次内存事务（memory transaction）,就会发生bank冲突。 L1 和 L2 缓存 从费米架构开始，有了SM层次的L1缓存和设备（一个设备有多个SM）层次的L2缓存 SM及其占有率 SM（Streaming MultiProcessor）构成\n一个GPU是由多个SM构成的。一个SM包含如下资源（不同架构不一定相同）：\n一定数量的寄存器。 一定数量的共享内存。 常量内存的缓存。 纹理和表面内存的缓存。 L1缓存。 两个（计算能力6.0）或4个（其他计算能力）线程束调度器（warpscheduler），用于在不同线程的上下文之间迅速地切换，以及为准备就绪的线程束发出执行指令。 执行核心，包括： 若干整型数运算的核心（INT32）。 若干单精度浮点数运算的核心（FP32）。 若干双精度浮点数运算的核心（FP64）。 若干单精度浮点数超越函数（transcendentalfunctions）的特殊函数单元（Special Function Units，SFUs）。 若干混合精度的张量核心（tensorcores，由伏特架构引入，适用于机器学习中的低精度矩阵计算）。 SM管理\nGPU中每个SM都可以支持数百个线程并发执行 以线程块block为单位，向SM分配线程块，多个线程块可被同时分配到一个可用的SM上 当一个线程块被分配好后，就不可以在分配到其他上了 线程束（warp）\nCUDA 采用单指令多线程架构管理执行线程，每32个为一组，构成一个线程束。同一个线程块中相邻的 32个线程构成一个线程束 每个线程束中只能包含同一线程块中的线程 线程束是GPU硬件上真正的做到了并行 ** SM 的占有率**\n一般来说，要尽量让SM的占有率不小于某个值，比如%，才有可能获得较高的性能。 SM的理论占有率（theoreticaloccupancy）的两个指标: 一个SM中最多能拥有的线程块个数 一个SM中最多能拥有的线程个数 根据寄存器、共享内存等具体架构具体分析 高效正确地并发并行 原子函数（atomic function） cuda提供原子函数来进行控制数据一致性读写。其中atomicCAS函数是比较特殊的，所有其他原子函数都可以用它实现（指定架构不支持时，但性能可能较差）。\nAtomic APIs with _system suffix (example: atomicAdd_system) are atomic at scope cuda::thread_scope_system if they meet particular conditions. compute capability must greater than 7.2. Atomic APIs without a suffix (example: atomicAdd) are atomic at scope cuda::thread_scope_device. Atomic APIs with _block suffix (example: atomicAdd_block) are atomic at scope cuda::thread_scope_block. 线程束（warp）基本函数 一个SM以32个线程为单位产生、管理、调度、执行线程。这样的32 个线程称为一个线程束。 SM执行属于单指令-多线程（single instruction, multiple thread，SIMT）的执行模式：在同一时刻，一个线程束中的线程只能执行一个共同的指令或者闲置。 在伏特架构之前，一个线程束中的线程拥有同一个程序计数器（programcounter），但各自有不同的寄存器状态（registerstate），从而可以根据程序的逻辑判断选择不同的分支。因此当同一个线程束（不同的不会）中的线程顺序地执行判断语句中的不同分支时，会发生分支发散（branch divergence）。 从伏特架构开始，引入了独立线程调度（independentthreadscheduling）机制。每个线程有自己的程序计数器。这使得伏特架构有了一些以前的架构所没有的新的线程束内同步与通信的模式，但导致： 增加了寄存器负担：单个线程的程序计数器一般需要使用两个寄存器。 独立线程调度机制使得假设了线程束同步（warpsynchronous）的代码变得不再安全：必须显式同步。 线程束内的线程同步函数：都在一个线程束内时，可以将线程块同步函数__syncthreads 换成一个更加廉价的线程束同步函数__syncwarp。 其他基本函数： 线程束表决函数（warpvotefunctions） 线程束匹配函数（warpmatchfunctions） 线程束洗牌函数（warp shuffle functions） 线程束矩阵函数（warp matrix functions） 协作组（cooperativegroups） 类似线程块和线程束同步机制的推广，它提供了更为灵活的线程协作方式，包括线程块内部的同步与协作、线程块之间的（网格级的）同步与协作及设备之间的同步与协作。 https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction-cg CUDA流（CUDA stream） CUDA流介绍 主要用cuda流解决核函数外部的并行：\n核函数计算与数据传输之间的并行。 主机计算与数据传输之间的并行。 不同的数据传输（回顾一下cudaMemcpy函数中的第4个参数）之间的并行。 核函数计算与主机计算之间的并行。 不同核函数之间的并行。 任何CUDA操作都存在于某个CUDA流中，要么是默认流（default stream），也称为空流（null stream），要么是明确指定的非空流。\n在主机端产生与销毁。一个CUDA流由类型为cudaStream_t 的变量表示，cudaStreamCreate和cudaStreamDestroy创建和销毁。 为了实现不同CUDA流之间的并发，主机在向某个CUDA流中发布一系列命令之后必须马上获得程序的控制权，不用等待该CUDA流中的命令在设备中执行完毕。这样，就可以通过主机产生多个相互独立的CUDA流。 检查一个CUDA流中的所有操作是否都在设备中执行完毕：cudaStreamSynchronize同步、cudaStreamQuery查询 默认流（default stream）/ 为空流（null stream） 1 2 3 两种调用方式： my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block\u0026gt;\u0026gt;\u0026gt;(函数参数); my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block, N_shared\u0026gt;\u0026gt;\u0026gt;(函数参数); 核函数的启动是异步的（asynchronous），或者说是非阻塞的（non-blocking），所以会host会立即执行下一条语句。该命令如果是CUDA操作不会被device立即执行，因为这是默认流中的CUDA操作，必须等待前一个CUDA操作（即核函数的调用）执行完毕才会开始执行。 可以在核函数启动后放置host操作，利用前面CUDA操作完成时间。 非默认流/非空流 1 2 3 4 调用方式： my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block, N_shared, stream_id\u0026gt;\u0026gt;\u0026gt;(函数参数); my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid,N_block, 0 ,stream_id\u0026gt;\u0026gt;\u0026gt;(函数参数); // 不使用动态共享内存 # stream_id是CUDA流的编号，N_shared是核函数中使用的动态共享内存的字节数。 用非默认CUDA流重叠核函数的执行与数据传递\n要实现核函数执行与数据传输的并发（重叠），必须让这两个操作处于不同的非默认流，而且数据传输必须使用cudaMemcpy函数的异步版本，即cudaMemcpyAsync函数。异步传输由GPU中的DMA（directmemoryaccess）直接实现，不需要主机参与。 在使用异步的数据传输函数时，需要将主机内存定义为不可分页内存（non-pageable memory）或者固定内存（pinned memory），在程序运行期间，其物理地址将保持不变，由cudaMallocHost和cudaFreeHost申请和释放。 统一内存（unifiedmemory）编程 介绍 统一内存是一种逻辑上的概念，一种系统中的任何处理器（CPU或GPU）都可以访问，并能保证一致性的虚拟存储器。这种虚拟存储器是通过CPU和GPU各自内部集成的内存管理单元（memorymanagementunit）实现的。 使用统一内存对硬件有较高的要求：不低于开普勒架构等。 好处：不用手动内存传输管理；相比手动内存操作可能会有更好的性能；超量分配，类似虚拟内存策略。 基本使用 统一内存在设备中是当作全局内存使用的，而且必须在主机端定义或分配内存，而不能在设备端（核函数和__device__函数）定义或分配内存。 动态申请：cudaMallocManaged 静态申请： __device____managed__int ret[1000]; 数据预取：cudaMemPrefetchAsync 多GPU编程 CUDA标准库 cuda所以接口及库详见官网：cuda docs、cuda developer\nThrust 类似于C++的标准模板库（standard template library）\nthrust、NCCL 数据结构：容器thrust::host_vector\u0026lt;typename\u0026gt;和thrust::device_vector\u0026lt;typename\u0026gt; 算法： 变换（transformation）。本书多次讨论的数组求和计算就是一种变换操作。 规约（reduction）。这是本书重点讨论过的算法。 前缀和（prefixsum）。下一节将详细讨论该算法。 排序（sorting）与搜索（searching）。 选择性复制、替换、移除、分区等重排（reordering）操作。 cuBLAS（basic linear algebra subprograms） 基本线性代数子程序，矩阵在内存中的存储是列主序（column-major order）的Fortran 风格，而不是像C语言中是行主序（row-majororder）的。\ncublas、blas cuBLAS 库包含3个API： cuBLAS API：相关数据必须在设备。 cuBLASXTAPI：相关数据必须在主机。 cuBLASLt API：一个专门处理矩阵乘法的API。 cuFFT 快速傅里叶变换（fast Fourier transforms）\ncufft cuSPARSE 稀疏（sparse）矩阵\ncusparse cusparse提供了一些稀疏矩阵、向量和稠密矩阵、向量的运算函数。 cuSolver 稠密（dense）矩阵和稀疏（sparse）矩阵计算库\ncuSolver 专注于一些比较高级的线性代数方面的计算，如矩阵求逆和矩阵对角化，类似LAPACK库。基于cuBLAS和cuSPARSE两个更基础的库实现。 cusolver、lapack cuSolver 库由以下3个相互独立的子库组成： cuSolverDN（DeNse, DN）：一个处理稠密矩阵线性代数计算的库。 cuSolverSP（SParse, SP）：一个处理稀疏矩阵的线性代数计算的库。 cuSolverRF（ReFactorization, RF）：一个特殊的处理稀疏矩阵分解的库。 cuSolver 库函数倾向于使用异步执行。为了保证一个cuSolver函数的工作已经完成，可以使用cudaDeviceSynchronize() 函数进行同步。 cuRAND 与随机数生成有关的库,包含伪随机数（pseudorandom numbers）和准随机数（quasirandom numbers）。\ncurand cuRand是后向兼容（backward compatible）的，注意cuRAND 和 the CUDA runtime的版本对应 提供了两种API：主机API和设备API。 cuDNN 深度神经网络（deep neural networks）\n是一个用于深度神经网络的 GPU 加速基元库。cuDNN 为标准例程（如前向和后向卷积、注意力、matmul、池化和规范化）提供高度优化的实现。 cudnn docs、cudnn developer ","date":"2025-01-03T00:00:00Z","permalink":"https://loveleaves.github.io/p/gpu/","title":"【GPU】 GPU架构及使用介绍"},{"content":"References openmlsys https://www.zhihu.com/question/26754848 ML Architecture 编程接口 pybind ctypes Computational Graph (计算图) 计算图由基本数据结构张量（Tensor）和基本运算单元算子（operator）构成。在计算图中通常使用节点来表示算子，节点间的有向边（Directed Edge）来表示张量状态，同时也描述了计算间的依赖关系，通常为有向无环图DAG。\n计算图是机器学习框架的核心理念之一，了解主流机器学习框架的设计思想，有助于深入掌握这一概念，建议阅读 TensorFlow 设计白皮书、 PyTorch计算框架设计论文。\n图外控制流直接使用前端语言控制流，熟悉编程语言即可掌握这一方法，而图内控制流则相对较为复杂，建议阅读TensorFlow控制流论文。\n动态图和静态图设计理念与实践，建议阅读TensorFlow Eager 论文、TensorFlow Eager Execution示例、TensorFlow Graph理念与实践、MindSpore动静态图概念。\nTorch JIT\nhttps://github.com/louis-she/torchscript-demos https://zhuanlan.zhihu.com/p/370455320 pytorch2.0新特性：https://www.bilibili.com/video/BV1p84y1675B pytorch计算图例子 How Computational Graphs are Constructed in PyTorch AI编译器和前端技术 编译器前端基础结构\n传统编译器：video AI编译器: summary、video AI System 机器学习编译 主流编译器LLVM Getting Started with LLVM Core Libraries 用LLVM开发新语言 LLVM写个简易编译器1、LLVM写个简易编译器2 编译器后端和运行时 编译器后端总体架构简图\n硬件加速器 算子编译器 当前业界的算子编译器/编译框架主要有\nTVM/Ansor [Zheng et al., 2020] MLIR [Lattner et al., 2020] 华为昇腾芯片上的TBE/AKG [Zhao et al., 2021] 加速器实践 数据处理框架 数据模块的核心组件\n模块设计重点\n易用性 高效性 保序性 AI 推理框架 移动端 腾讯ncnn 模型部署 分布式训练 进阶： 华盛顿大学 Deep Learning Systems，机器学习程序的编译过程,Apache TVM深度学习编译器 AI Systems 微软亚洲研究院 ","date":"2024-12-10T00:00:00Z","permalink":"https://loveleaves.github.io/p/mlsys/","title":"【MLsys】机器学习系统介绍"},{"content":"多线程并行/并发 同一进程各个线程之间共享内存，可用多个线程并行执行，每个线程处理数据或操作的一部分，类似OpenMP。\n线程 操作系统调度的最小单位 每个进程可以有多个线程，线程之间共享进程的内存空间，但有自己的栈、寄存器等 线程切换涉及保存和恢复上下文，内存分配，线程同步等，具有一定的系统开销（注意衡量数据规模对应的线程数量）。 在多核处理器上，线程可以实现真正的并行计算。 在 C 语言中，线程通常通过 POSIX 线程（pthread）库来实现 使用 用多线程优化下面算子：\n1 2 3 4 5 6 7 int sum_array(int *arr, int len) { int sum = 0; for(int i = 0; i \u0026lt; len; ++i) { sum += arr[i]; } return sum; } C例子 优化完成程序：(在链接时指定 -pthread，告诉 GCC 在编译和链接时启用 POSIX 线程支持)\n仅使用多线程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; typedef struct { int *arr; int start; int end; int partial_sum; } ThreadData; void *sum_partial(void *arg) { ThreadData *data = (ThreadData *)arg; data-\u0026gt;partial_sum = 0; for (int i = data-\u0026gt;start; i \u0026lt; data-\u0026gt;end; ++i) { data-\u0026gt;partial_sum += data-\u0026gt;arr[i]; } return NULL; } int sum_array(int *arr, int len, int num_threads) { pthread_t *threads = malloc(sizeof(pthread_t) * num_threads); ThreadData *thread_data = malloc(sizeof(ThreadData) * num_threads); int chunk_size = len / num_threads; int remainder = len % num_threads; // Create threads to compute partial sums for (int i = 0; i \u0026lt; num_threads; ++i) { thread_data[i].arr = arr; thread_data[i].start = i * chunk_size; thread_data[i].end = (i == num_threads - 1) ? len : (i + 1) * chunk_size; // Handle remainder elements (if any) if (i == num_threads - 1 \u0026amp;\u0026amp; remainder != 0) { thread_data[i].end += remainder; } pthread_create(\u0026amp;threads[i], NULL, sum_partial, \u0026amp;thread_data[i]); } // Wait for all threads to finish and calculate the total sum int total_sum = 0; for (int i = 0; i \u0026lt; num_threads; ++i) { pthread_join(threads[i], NULL); total_sum += thread_data[i].partial_sum; } free(threads); free(thread_data); return total_sum; } int main() { int arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; int len = sizeof(arr) int num_threads = 4; int result = sum_array(arr, len, num_threads); printf(\u0026#34;Total sum: %d\\n\u0026#34;, result); return 0; } 使用多线程+互斥锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define NUM_THREADS 4 // 使用4个线程 // 线程参数结构体 typedef struct { int *arr; int start; int end; int *sum; pthread_mutex_t *mutex; } ThreadData; void* thread_sum(void *arg) { ThreadData *data = (ThreadData *)arg; int partial_sum = 0; for (int i = data-\u0026gt;start; i \u0026lt; data-\u0026gt;end; ++i) { partial_sum += data-\u0026gt;arr[i]; } // 使用互斥锁保护共享资源sum pthread_mutex_lock(data-\u0026gt;mutex); *data-\u0026gt;sum += partial_sum; pthread_mutex_unlock(data-\u0026gt;mutex); return NULL; } int sum_array(int *arr, int len, int *sum, pthread_mutex_t *sum_mutex) { pthread_t threads[NUM_THREADS]; ThreadData thread_data[NUM_THREADS]; int chunk_size = len / NUM_THREADS; // 创建线程 for (int i = 0; i \u0026lt; NUM_THREADS; ++i) { thread_data[i].arr = arr; thread_data[i].start = i * chunk_size; thread_data[i].end = (i == NUM_THREADS - 1) ? len : (i + 1) * chunk_size; // 最后一个线程处理剩余部分 thread_data[i].sum = sum; thread_data[i].mutex = sum_mutex; pthread_create(\u0026amp;threads[i], NULL, thread_sum, (void*)\u0026amp;thread_data[i]); } // 等待所有线程完成 for (int i = 0; i \u0026lt; NUM_THREADS; ++i) { pthread_join(threads[i], NULL); } return *sum; } int main() { int arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; // 示例数组 int len = sizeof(arr) / sizeof(arr[0]); int sum = 0; // 用于存储总和 pthread_mutex_t sum_mutex; // 互斥锁 pthread_mutex_init(\u0026amp;sum_mutex, NULL); // 调用sum_array进行求和 int result = sum_array(arr, len, \u0026amp;sum, \u0026amp;sum_mutex); pthread_mutex_destroy(\u0026amp;sum_mutex); printf(\u0026#34;Sum of array: %d\\n\u0026#34;, result); return 0; } C++ 例子 优化完成程序：(在链接时指定 -pthread，告诉 GCC 在编译和链接时启用 POSIX 线程支持)\n仅使用多线程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;thread\u0026gt; int sum_array(int *arr, int len) { const int num_threads = 4; int chunk_size = len / num_threads; std::vector\u0026lt;std::thread\u0026gt; threads(num_threads); std::vector\u0026lt;int\u0026gt; partial_sums(num_threads, 0); // 定义一个线程函数，用于计算某个范围内的和 auto sum_part = [\u0026amp;](int thread_id) { int start = thread_id * chunk_size; int end = (thread_id == num_threads - 1) ? len : (thread_id + 1) * chunk_size; for (int i = start; i \u0026lt; end; ++i) { partial_sums[thread_id] += arr[i]; } }; for (int i = 0; i \u0026lt; num_threads; ++i) { threads[i] = std::thread(sum_part, i); } for (int i = 0; i \u0026lt; num_threads; ++i) { threads[i].join(); } int total_sum = 0; for (int i = 0; i \u0026lt; num_threads; ++i) { total_sum += partial_sums[i]; } return total_sum; } int main() { // 示例数组 int arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; int len = sizeof(arr) / sizeof(arr[0]); int result = sum_array(arr, len); std::cout \u0026lt;\u0026lt; \u0026#34;Sum of array: \u0026#34; \u0026lt;\u0026lt; result \u0026lt;\u0026lt; std::endl; return 0; } 使用多线程+原子操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;numeric\u0026gt; // std::accumulate void partial_sum(const std::vector\u0026lt;int\u0026gt;\u0026amp; data, size_t start, size_t end, std::atomic\u0026lt;long long\u0026gt;\u0026amp; result) { long long partial_result = 0; for (size_t i = start; i \u0026lt; end; ++i) { partial_result += data[i]; } result += partial_result; // result += std::accumulate(data.data()+start, data.data()+end, 0); } int main() { const size_t data_size = 10000000; std::vector\u0026lt;int\u0026gt; data(data_size, 1); const size_t num_threads = 4; // std::thread::hardware_concurrency(); 获取硬件支持的线程数 std::vector\u0026lt;std::thread\u0026gt; threads; std::atomic\u0026lt;long long\u0026gt; result(0); size_t chunk_size = data_size / num_threads; for (size_t i = 0; i \u0026lt; num_threads; ++i) { size_t start = i * chunk_size; size_t end = (i == num_threads - 1) ? data_size : (i + 1) * chunk_size; // 最后一个线程处理剩余部分 threads.emplace_back(partial_sum, std::cref(data), start, end, std::ref(result)); } for (auto\u0026amp; t : threads) { t.join(); } std::cout \u0026lt;\u0026lt; \u0026#34;Total sum: \u0026#34; \u0026lt;\u0026lt; result.load() \u0026lt;\u0026lt; std::endl; return 0; } 使用多线程+互斥锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;mutex\u0026gt; void partial_sum(const std::vector\u0026lt;int\u0026gt;\u0026amp; data, size_t start, size_t end, long long\u0026amp; result, std::mutex\u0026amp; mtx) { long long local_sum = 0; for (size_t i = start; i \u0026lt; end; ++i) { local_sum += data[i]; } mtx.lock(); // std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mtx); result += local_sum; mtx.unlock(); } int main() { const size_t data_size = 1\u0026#39;000\u0026#39;000; const size_t thread_count = 4; std::vector\u0026lt;int\u0026gt; data(data_size, 1); long long result = 0; std::mutex mtx; std::vector\u0026lt;std::thread\u0026gt; threads; size_t chunk_size = data_size / thread_count; for (size_t i = 0; i \u0026lt; thread_count; ++i) { size_t start = i * chunk_size; size_t end = (i == thread_count - 1) ? data_size : start + chunk_size; threads.emplace_back(partial_sum, std::cref(data), start, end, std::ref(result), std::ref(mtx)); } for (auto\u0026amp; t : threads) { t.join(); } std::cout \u0026lt;\u0026lt; \u0026#34;Total sum: \u0026#34; \u0026lt;\u0026lt; result \u0026lt;\u0026lt; std::endl; return 0; } ","date":"2024-10-22T00:00:00Z","permalink":"https://loveleaves.github.io/p/multi_threads/","title":"【HPC】 C/C++多线程并行/并发"},{"content":"References 深度神经网络剪枝综述，A Survey on Deep Neural Network Pruning: Taxonomy, Comparison, Analysis, and Recommendations 目前针对大模型剪枝的方法有哪些？ MIT 6.5940 TinyML and Efficient Deep Learning Computing 模型压缩的小白入门教程 介绍 **模型剪枝（Model Pruning）**是一种用于减少神经网络模型参数数量和计算量的技术。它通过识别和去除在训练过程中对模型性能影响较小的参数或连接，从而实现模型的精简和加速。\n通常，模型剪枝可以分为两种类型：结构化剪枝（Structured Pruning）和非结构化剪枝（Unstructured Pruning）。\n结构化剪枝和非结构化剪枝的主要区别在于剪枝目标和由此产生的网络结构。结构化剪枝根据特定规则删除连接或层结构，同时保留整体网络结构。而非结构化剪枝会剪枝各个参数，从而产生不规则的稀疏结构。\n模型剪枝的一般步骤包括：\n训练初始模型：首先，需要训练一个初始的大模型，通常是为了达到足够的性能水平。 评估参数重要性：使用某种评估方法（如：权重的绝对值、梯度信息等）来确定模型中各个参数的重要性。 剪枝：根据评估结果，剪枝掉不重要的参数或连接，可以是结构化的或非结构化的。 修正和微调：进行剪枝后，需要进行一定的修正和微调，以确保模型的性能不会显著下降。 模型剪枝可以带来多方面的好处，包括减少模型的存储需求、加速推理速度、减少模型在边缘设备上的资源消耗等。然而，剪枝可能会带来一定的性能损失，因此需要在剪枝前后进行适当的评估和调整。\n剪枝方法 Network Slimming 基本思想 论文核心点\n以 BN 中的 γ 为切入点，即 γ 越小，其对应的特征图越不重要 为了使得 γ 能有特征选择的作用，引入 L1 正则来控制 γ $$ L = \\sum_{(x,y)} l(f(x, W), y) + \\lambda \\sum_{\\gamma \\in \\Gamma} g(\\gamma) $$ BatchNorm 如何得到每个特征图的重要性呢？\u0026ndash;BN要解决的问题\nNetwork slimming，就是利用BN层中的缩放因子Y 先来回顾下BN是做什么的：$\\hat{x}^{(k)} = \\frac{x^{(k)} - E[x^{(k)}]}{\\sqrt{Var[x^{(k)}]}}$ 整体感觉就是一个归一化操作，但是BN中还额外引入了两个可训练的参数：γ和β。 BN本质作用\nBN要做的就是把越来越偏离的分布给他拉回来！ 再重新规范化到均值为0方差为1的标准正态分布 这样能够使得激活函数在数值层面更敏感，训练更快 有一种感觉：经过BN后，把数值分布强制在了非线性函数的线性区域中 BN额外参数\n如果都是线性的了，神经网络还有意义吗？ BN另一方面还需要保证一些非线性，对规范化后的结果再进行变换 这两个参数是训练得到的：$y^{(k)}=\\gamma^{(k)}\\hat{x}^{(k)}+\\beta^{(k)}$ 感觉就是从正太分布进行一些改变，拉动一下，变一下形状！ 稀疏化原理与效果\n论文中提出：训练时使用 L1 正则化能对参数进行稀疏作用 L1：稀疏与特征选择；L2：平滑特征 L1 正则化：$J(\\vec{\\theta}) = \\frac{1}{2} \\sum_{i=1}^{m} \\left( h_{\\vec{\\theta}}(x^{(i)}) - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^{n} |\\theta_j|$，$\\theta_j$是要正则化的参数 L2 正则化：$J(\\vec{\\theta}) = \\frac{1}{2} \\sum_{i=1}^{m} \\left( h_{\\vec{\\theta}}(x^{(i)}) - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^{n} \\theta_j^2$，同上 剪枝流程 代码 github\npaper with code DepGraph github paper ","date":"2024-06-21T00:00:00Z","permalink":"https://loveleaves.github.io/p/prune/","title":"模型剪枝介绍"},{"content":"嵌入式编程介绍 嵌入式编程（Embedded Programming）是指在嵌入式系统中编写软件的过程，嵌入式系统通常是专门为某一特定任务设计的计算机系统，不像传统计算机那样可以运行多种应用程序。嵌入式系统的应用非常广泛，从智能家居设备、汽车控制系统、工业自动化，到医疗设备等，几乎无处不在。\n嵌入式编程是什么？ 嵌入式编程是为了控制嵌入式系统硬件而编写的软件。嵌入式系统通常具有以下特点：\n资源有限：嵌入式系统一般硬件资源有限，如内存、处理能力、电池寿命等。 任务专一：嵌入式系统通常只执行单一任务或有限的几个任务。 高实时性：很多嵌入式系统需要满足严格的实时性要求，即程序必须在特定时间内完成特定操作。 稳定性高：由于嵌入式设备通常需要长时间运行，因此软件的稳定性和可靠性至关重要。 嵌入式编程不仅仅是开发简单的软件，它还需要开发者对硬件有一定了解，能够在有限的资源下优化代码，确保系统的高效和稳定运行。\n嵌入式编程的基础 硬件平台 彻底搞清单片机、ARM、MCU、DSP、FPGA之间的关系！ 嵌入式编程首先需要选择合适的硬件平台。常见的嵌入式硬件平台包括：\n单片机（MCU）：例如STMicroelectronics的STM32、Atmel的AVR系列、Microchip的PIC系列等。单片机广泛应用于各种小型设备。 数字信号处理器（DSP）：用于复杂的计算，像离散余弦变换、快速傅里叶变换，常用于图像处理，在数码相机等设备中使用。 开发板：如树莓派、Arduino、ESP32等，它们适合快速原型开发。 FPGA：如Xilinx、Intel（Altera）等的FPGA芯片，适用于对硬件有高要求的应用。 ASIC：定制/半定制芯片，设计用于解决特殊需求。 ARM: 一个英国的芯片设计公司，但是不生产芯片。只卖知识产权。 嵌入式操作系统 对于一些复杂的嵌入式应用，开发者需要选择合适的操作系统来管理硬件资源。常见的嵌入式操作系统有：\nRTOS（实时操作系统）：如FreeRTOS、ChibiOS等，适用于需要高实时性的嵌入式应用。 Linux：例如在树莓派等开发板上运行嵌入式Linux，适用于需要丰富功能和较强处理能力的系统。 裸机编程：没有操作系统支持，直接对硬件进行编程，适用于资源较为有限的设备。 编程语言 嵌入式开发常用的编程语言主要有：\nC语言：由于其高效、底层控制能力和较小的代码体积，C语言是嵌入式编程中最常用的语言。 C++：对于一些更复杂的系统，C++提供了面向对象的特性，帮助开发者更好地管理代码。 汇编语言：在一些资源非常有限或者对性能要求极高的场景下，可能需要使用汇编语言来直接控制硬件。 嵌入式编程工具 嵌入式开发离不开合适的开发工具，这些工具通常包括：\nIDE（集成开发环境）：如Keil、IAR Embedded Workbench、Eclipse等，用于编写、编译和调试嵌入式代码。 编译器：GCC（GNU Compiler Collection）是最常用的开源编译器，它支持多种架构的嵌入式开发。 调试工具：JTAG调试器、SWD（Serial Wire Debug）调试器等，用于硬件级调试，帮助开发者实时查看代码执行状态。 仿真器：一些开发环境如Proteus提供硬件仿真，帮助开发者在没有实际硬件的情况下测试代码。 References soc介绍 怎么干好嵌入式MCU、ARM、DSP这一行 深入理解CPU和异构计算芯片GPU/FPGA/ASIC （上篇） ","date":"2023-03-21T00:00:00Z","permalink":"https://loveleaves.github.io/p/embedded_programing_intro/","title":"【嵌入式编程】 嵌入式编程介绍"},{"content":"References https://www.bilibili.com/video/BV1fA4y1o715 https://www.bilibili.com/video/BV1QK411d76w 算法通关手册 LeetCode 刷题攻略 二分查找 概念 二分查找的做法：定义查找的范围 [left,right]，初始查找范围是整个数组。每次取查找范围的中点 mid，比较 nums[mid] 和 target 的大小，如果相等则 mid 即为要寻找的下标，如果不相等则根据 nums[mid] 和 target 的大小关系将查找范围缩小一半。\n关键点：\n搜索区间：注意区间的开闭，是否满足定义 循环不变量：最终搜索子区间，及之后退出循环的left、right指向位置 简单场景：单target查找 以leetcode-704为例：\n搜索区间：左闭右闭 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 标准写法 def search(self, nums: List[int], target: int) -\u0026gt; int: left = 0 # 搜索区间：[left,right] right = len(nums) - 1 while left \u0026lt;= right: mid = (left+right)//2 if nums[mid] \u0026lt; target: left = mid + 1 elif nums[mid] \u0026gt; target: right = mid - 1 else: return mid return -1 这里因为定义搜索区间为左闭右闭，所以：\nleft、right初始值毫无疑问 最终搜索子区间索引为：[i,i] while循环作为子区间搜索，索引子区间[i,i]肯定属于搜索区间，所以判断条件为\u0026lt;= 当nums[mid] \u0026lt; target时，已知条件是target肯定在右边，但为什么不能更新为left = mid，是因为考虑到缩小到的子区间里可能有mid==left情况，此时如果不+1移动更新区间，就是死循环；right值处理跟left类似 所以只要在mid==left时更新区间，其实也可能设置为mid，因为[mid, right]也是符合条件的搜索区间，代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 其他写法 def search(self, nums: List[int], target: int) -\u0026gt; int: left = 0 right = len(nums) - 1 while left \u0026lt;= right: mid = (left+right)//2 if nums[mid] \u0026lt; target: if mid == left: left = mid + 1 else: # 不为mid+1也没问题，不过部分子区间重复搜索 left = mid elif nums[mid] \u0026gt; target: if mid == left: right = mid - 1 else: right = mid else: return mid return -1 搜索区间：左闭右开 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 标准写法 def search(self, nums: List[int], target: int) -\u0026gt; int: left = 0 # 搜索区间：[left,right) right = len(nums) while left \u0026lt; right: mid = (left+right)//2 if nums[mid] \u0026lt; target: left = mid + 1 elif nums[mid] \u0026gt; target: right = mid else: return mid return -1 这里因为定义搜索区间为左闭右开，所以：\nleft、right初始值毫无疑问 最终搜索子区间索引为：[i,i+1] while循环作为子区间搜索，索引子区间[i,i]不属于搜索区间，所以判断条件为\u0026lt; 当nums[mid] \u0026lt; target时，但为什么不能更新为left = mid，和上面类似；当nums[mid] \u0026gt; target时，则已知最小可搜索空间为[left,mid)，当然也可以为[left,mid+i)（mid\u0026lt;=mid+i\u0026lt;=right），但这就多了许多重复搜索 所以只要在mid==left时更新区间，其实也可能设置为mid，因为[mid, right]也是符合条件的搜索区间，代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 其他写法 def search(self, nums: List[int], target: int) -\u0026gt; int: left = 0 # 搜索区间：[left,right) right = len(nums) while left \u0026lt; right: mid = (left+right)//2 if nums[mid] \u0026lt; target: if mid == left: left = mid + 1 else: left = mid elif nums[mid] \u0026gt; target: right = mid else: return mid return -1 搜索区间：左开右开 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 标准写法 def search(self, nums: List[int], target: int) -\u0026gt; int: left = -1 # 搜索区间：(left,right) right = len(nums) while left + 1 \u0026lt; right: mid = (left+right)//2 if nums[mid] \u0026lt; target: left = mid elif nums[mid] \u0026gt; target: right = mid else: return mid return -1 原因和前两个类似，这里：\n最终搜索子区间索引为：[i,i+1,i+2] 利用二分性质：第一个或最后一个target位置 以leetcode-34为例，定义搜索空间为左闭右闭：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 搜索第一个target位置 def lowerBound(nums, target): left = 0 right = len(nums) - 1 while left \u0026lt;= right: mid = (left + right)//2 if nums[mid] \u0026lt; target: left = mid + 1 # 等于情况移动right：不断将子搜索区间移动到小于target的第一个位置 else: right = mid - 1 return left def searchRange(self, nums: List[int], target: int) -\u0026gt; List[int]: first_pos = lowerBound(nums, target) # 找不到target情况 if first_pos == len(nums) or nums[first_pos] != target: return [-1, -1] end_pos = lowerBound(nums, target+1) - 1 return [first_pos, end_pos] 上面的nums[mid] == target情况修改为移动left：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def lowerBound(nums, target): left = 0 right = len(nums) - 1 while left \u0026lt;= right: mid = left + (right - left)//2 # 等于情况移动left：不断将子搜索区间移动大于target的第一个位置 if nums[mid] \u0026lt;= target: left = mid + 1 else: right = mid - 1 return left def searchRange(self, nums: List[int], target: int) -\u0026gt; List[int]: first_pos = lowerBound(nums, target) # 找不到target情况 if first_pos == 0 or nums[first_pos-1] != target: return [-1, -1] end_pos = lowerBound(nums, target-1) return [end_pos, first_pos-1] 总结 由上可以总结如下：\n二分查找在mid和target值相等时，继续移动区间，则在有多个target值的情况时： 1、相等时移动right，最终结果为等于target的第一个位置 2、相等时移动left，最终结果为大于target的第一个位置 注意 但当相等情况复杂时，如果相等位置切分不当，left最终位置可能与预期位置不一致，可以通过以leetcode-33为例思考。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def search(self, nums: List[int], target: int) -\u0026gt; int: def moveLeft(i): end = nums[-1] if nums[i] \u0026gt; end: return target \u0026gt;= nums[i] or target \u0026lt;= end else: return target \u0026gt;= nums[i] and target \u0026lt;= end left = 0 right = len(nums) - 1 while left \u0026lt;= right: mid = (left+right)//2 # 如果相等情况不return mid，则moveLeft判断就需要进行仔细考虑该场景下相等情况子区间的移动 if nums[mid] == target: return mid elif moveLeft(mid): left = mid+1 else: right=mid-1 if left == len(nums) or nums[left] != target: return -1 return left 局部可二分 以leetcode-162为例，定义搜索空间为左闭右闭：\n为什么可以使用二分 简单证明：\n我们可以以下标为x轴，元素值为y轴，在平面直角坐标系里绘制出每个元素的位置，再以直线连接，这样构成了一副折线图。由于题目保证两边界之外的元素为负无穷，相邻值不相等且至少存在一个非负无穷元素，所以必然有峰。那么我们任取相邻两点为m、m+1，则如果nums[m]\u0026lt;nums[m+1]，那么m+i, i=1,2..范围肯定存在一个该范围的最大值且为峰顶，同理，如果小于，那么反方向也肯定存在一个该范围的最大值且为峰顶。因而可以用二分解决。\n1 2 3 4 5 6 7 8 9 10 11 12 13 def findPeakElement(self, nums: List[int]) -\u0026gt; int: left = 0 right = len(nums) - 2 # 忽略末尾元素，防止越界 # 或者这样处理 # right = len(nums) - 1 # nums.append(-inf) while left \u0026lt;= right: mid = (left+right)//2 if nums[mid] \u0026gt; nums[mid+1]: right = mid - 1 else: left = mid + 1 return left 回溯 概念 回溯法就是暴力解法。其基本思想是通过遍历每个阶段的所有可能选择，从而获得想要的所有可能，通常使用递归实现。并且通常从第一步开始选择，到最后一步结束，所以呈现类似对树进行DFS的操作，每层代表着每一步，从上往下的每个节点代表着累积的选择。\n递阶段：每次递的过程代表了每步进行了一种选择，递操作结束时代表所有步都做出了一种选择。 归阶段：每次归的过程往往伴随着撤销操作，代表对上一个选择的放弃，归操作结束时代表撤销所有步的所有选择。 关键点：\n递阶段：考虑当前步的所有选择，可通过条件进行剪枝。每步的选择可分为关联选择和无关选择。 关联选择：步与步之间的选择是有关联关系的，某步选了，其他步就会有约束（如不能选）； 无关选择：步与步之间的选择互不干扰，不受其他步的约束。 递结束：当前所有步的选择结果是否符合 归阶段：注意撤销之前选择 其他： 选择约束：某步的选择有约束，如可以不选、必须选或不能重复选等 递结束条件：需要多少步等 无关选择类型 以leetcode-17为例：\n无关选择：每步的选择与其他步不相关 递结束条件：步数为digits长度 选择约束：每步的所有选择必须选一个 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def letterCombinations(self, digits: str) -\u0026gt; List[str]: if not digits: return [] ans = [] # 存储每步的选择 paths = [] num2char = { \u0026#39;1\u0026#39;: \u0026#34;\u0026#34;, \u0026#39;2\u0026#39;: \u0026#34;abc\u0026#34;, \u0026#39;3\u0026#39;: \u0026#34;def\u0026#34;, \u0026#39;4\u0026#39;: \u0026#34;ghi\u0026#34;, \u0026#39;5\u0026#39;: \u0026#34;jkl\u0026#34;, \u0026#39;6\u0026#39;: \u0026#34;mno\u0026#34;, \u0026#39;7\u0026#39;: \u0026#34;pqrs\u0026#34;, \u0026#39;8\u0026#39;: \u0026#34;tuv\u0026#34;, \u0026#39;9\u0026#39;: \u0026#34;wxyz\u0026#34; } def dfs(i): # 已经走完最后一步 if i==len(digits): ans.append(\u0026#34;\u0026#34;.join(paths)) return # 遍历所有选择，选择之间无关联 for c in num2char[digits[i]]: # 作出当前步的选择，往下递 paths.append(c) dfs(i+1) # 归时撤销之前选择 paths.pop() # 从第一步开始 dfs(0) return ans 关联选择类型 以leetcode-78为例：\n关联选择：每步的选择与其他步相关 递结束条件：步数为k 满足结果条件：选择为组合不重复，非排列 选择约束：每步的选择为前面选择后剩下的，且必须选一个 简单粗暴，但超时，因为去重和修改每步选择的实现耗时严重\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def combine(self, n: int, k: int) -\u0026gt; List[List[int]]: ans = set() paths = [] def dfs(i, choice): if i==k: # 满足结果条件，去除重复 ans.add(tuple(sorted(paths))) return for index in range(len(choice)): new_choice=choice.copy() # 缩小下一步可用选择 del new_choice[index] paths.append(choice[index]) dfs(i+1, new_choice) paths.pop() dfs(0, [i for i in range(1,n+1)]) return [list(item) for item in ans] 优化：修改每步选择的实现，加入结果条件的约束\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def combine(self, n: int, k: int) -\u0026gt; List[List[int]]: ans = [] paths = [] choices = [i for i in range(1,n+1)] # 所有选择 mask = [True for _ in range(n)] # dfs实现，所以一个数组即可记录一条路径上的选择结果 def dfs(i): if i==k: ans.append(paths.copy()) return for j in range(len(choices)): # 选择是否可用 if mask[j]: # 添加满足结果条件约束 if len(paths) \u0026gt;0: # 严格递增的选择，上一步的选择比当前大，证明已经遍历过该选择 if choices[j] \u0026lt; paths[-1]: continue paths.append(choices[j]) # 额外对选择进行标记 mask[j]=False dfs(i+1) paths.pop() # 选择其他时进行回退 mask[j]=True dfs(0) return ans 根据满足结果条件进行优化：注意到结果为其实为选择的排列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def combine(self, n: int, k: int) -\u0026gt; List[List[int]]: ans = [] paths = [] choices = [i for i in range(1,n+1)] def dfs(i): # 这里第几步不是用i表示，而是paths长度，i表示上一步选择的位置 if len(paths)==k: ans.append(paths.copy()) return # 从之前选择位置往后选 for j in range(i, len(choices)): paths.append(choices[j]) dfs(j+1) paths.pop() dfs(0) return ans 同理，leetcode-51\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def solveNQueens(self, n: int) -\u0026gt; List[List[str]]: ans = [] if n == 0: return ans # 注意这里不能写成（行引用，非n个独立list）：[[\u0026#34;.\u0026#34;] *n] * n paths = [[\u0026#34;.\u0026#34;] *n for _ in range(n)] column = [False] * n ldiag = [False] * (2 * n - 1) # 左对角线 rdiag = [False] * (2 * n - 1) # 右对角线 def dfs(row): if row == n: ans.append([\u0026#34;\u0026#34;.join(item) for item in paths]) return for i in range(n): # 难点：注意到结果要满足的条件 if column[i] or ldiag[n - row + i - 1] or rdiag[row + i]: continue paths[row][i] = \u0026#39;Q\u0026#39; column[i] = ldiag[n - row + i - 1] = rdiag[row + i] = True dfs(row + 1) paths[row][i] = \u0026#39;.\u0026#39; column[i] = ldiag[n - row + i - 1] = rdiag[row + i] = False dfs(0) return ans 动态规划 动态规划的定义 动态规划（Dynamic Programming）：简称 DP，是一种求解多阶段决策过程最优化问题的方法。在动态规划中，通过把原问题分解为相对简单的子问题，先求解子问题，再由子问题的解而得到原问题的解。\n动态规划最早由理查德 · 贝尔曼于 1957 年在其著作「动态规划（Dynamic Programming）」一书中提出。这里的 Programming 并不是编程的意思，而是指一种「表格处理方法」，即将每一步计算的结果存储在表格中，供随后的计算查询使用。\n动态规划的核心思想 动态规划的核心思想：\n把「原问题」分解为「若干个重叠的子问题」，每个子问题的求解过程都构成一个 「阶段」。在完成一个阶段的计算之后，动态规划方法才会执行下一个阶段的计算。 在求解子问题的过程中，按照「自顶向下的记忆化搜索方法」或者「自底向上的递推方法」求解出「子问题的解」，把结果存储在表格中，当需要再次求解此子问题时，直接从表格中查询该子问题的解，从而避免了大量的重复计算。 这看起来很像是分治算法，但动态规划与分治算法的不同点在于：\n适用于动态规划求解的问题，在分解之后得到的子问题往往是相互联系的，会出现若干个重叠子问题。 使用动态规划方法会将这些重叠子问题的解保存到表格里，供随后的计算查询使用，从而避免大量的重复计算。 动态规划的特征 究竟什么样的问题才可以使用动态规划算法解决呢？\n首先，能够使用动态规划方法解决的问题必须满足以下三个特征：\n最优子结构性质 重叠子问题性质 无后效性 最优子结构性质 最优子结构：指的是一个问题的最优解包含其子问题的最优解。\n举个例子，如下图所示，原问题 $S = \\lbrace a_1, a_2, a_3, a_4 \\rbrace$，在 $a_1$ 步我们选出一个当前最优解之后，问题就转换为求解子问题 $S_{\\text{子问题}} = \\lbrace a_2, a_3, a_4 \\rbrace$。如果原问题 $S$ 的最优解可以由「第 $a_1$ 步得到的局部最优解」和「 $S_{\\text{子问题}}$ 的最优解」构成，则说明该问题满足最优子结构性质。\n也就是说，如果原问题的最优解包含子问题的最优解，则说明该问题满足最优子结构性质。\n重叠子问题性质 重叠子问题性质：指的是在求解子问题的过程中，有大量的子问题是重复的，一个子问题在下一阶段的决策中可能会被多次用到。如果有大量重复的子问题，那么只需要对其求解一次，然后用表格将结果存储下来，以后使用时可以直接查询，不需要再次求解。\n之前我们提到的「斐波那契数列」例子中，$f(0)$、$f(1)$、$f(2)$、$f(3)$ 都进行了多次重复计算。动态规划算法利用了子问题重叠的性质，在第一次计算 $f(0)$、$f(1)$、$f(2)$、$f(3)$ 时就将其结果存入表格，当再次使用时可以直接查询，无需再次求解，从而提升效率。\n无后效性 无后效性：指的是子问题的解（状态值）只与之前阶段有关，而与后面阶段无关。当前阶段的若干状态值一旦确定，就不再改变，不会再受到后续阶段决策的影响。\n也就是说，一旦某一个子问题的求解结果确定以后，就不会再被修改。\n举个例子，下图是一个有向无环带权图，我们在求解从 $A$ 点到 $F$ 点的最短路径问题时，假设当前已知从 $A$ 点到 $D$ 点的最短路径（$2 + 7 = 9$）。那么无论之后的路径如何选择，都不会影响之前从 $A$ 点到 $D$ 点的最短路径长度。这就是「无后效性」。\n而如果一个问题具有「后效性」，则可能需要先将其转化或者逆向求解来消除后效性，然后才可以使用动态规划算法。\n动态规划的基本思路 如下图所示，我们在使用动态规划方法解决某些最优化问题时，可以将解决问题的过程按照一定顺序（时间顺序、空间顺序或其他顺序）分解为若干个相互联系的「阶段」。然后按照顺序对每一个阶段做出「决策」，这个决策既决定了本阶段的效益，也决定了下一阶段的初始状态。依次做完每个阶段的决策之后，就得到了一个整个问题的决策序列。\n这样就将一个原问题分解为了一系列的子问题，再通过逐步求解从而获得最终结果。\n这种前后关联、具有链状结构的多阶段进行决策的问题也叫做「多阶段决策问题」。\n通常我们使用动态规划方法来解决问题的基本思路如下：\n划分阶段：将原问题按顺序（时间顺序、空间顺序或其他顺序）分解为若干个相互联系的「阶段」。划分后的阶段⼀定是有序或可排序的，否则问题⽆法求解。 这里的「阶段」指的是⼦问题的求解过程。每个⼦问题的求解过程都构成⼀个「阶段」，在完成前⼀阶段的求解后才会进⾏后⼀阶段的求解。 定义状态：将和子问题相关的某些变量（位置、数量、体积、空间等等）作为一个「状态」表示出来。状态的选择要满⾜⽆后效性。 一个「状态」对应一个或多个子问题，所谓某个「状态」下的值，指的就是这个「状态」所对应的子问题的解。 状态转移：根据「上一阶段的状态」和「该状态下所能做出的决策」，推导出「下一阶段的状态」。或者说根据相邻两个阶段各个状态之间的关系，确定决策，然后推导出状态间的相互转移方式（即「状态转移方程」）。 初始条件和边界条件：根据问题描述、状态定义和状态转移方程，确定初始条件和边界条件。 最终结果：确定问题的求解目标，然后按照一定顺序求解每一个阶段的问题。最后根据状态转移方程的递推结果，确定最终结果。 实现及优化思路 通常思路：\n先确定每次操作及选择（子问题） 确定状态转移方程和初始值 用递归实现（逆向） 用数组（形状：n * choices）存储状态，改为循环实现（正向） 根据状态转移方程确定子问题关联了多少步的状态，从而优化空间 关键点：\n子问题 状态转移方程 初始值（满足条件和不满足条件） 0-1背包 概念 有 n 个物品，第 i 个物品的体积为 w[i] ，价值为 v[i] 。\n每个物品至多选一个，求体积和不超过 capacity 时的最大价值和。\n注意点：\n当前操作？枚举第 \\( i \\) 个物品选或不选： 不选，剩余容量不变； 选，剩余容量减少 \\( w[i] \\)。 子问题？在剩余容量为 \\( c \\) 时， 从 前 \\( i \\) 个物品 中得到的最大价值和。 下一个子问题？分类讨论： 不选：在剩余容量为 \\( c \\) 时，\n从 前 \\( i-1 \\) 个物品 中得到的最大价值和。 选：在剩余容量为 \\( c - w[i] \\) 时，\n从 前 \\( i-1 \\) 个物品 中得到的最大价值和。 回溯思考：有n步，每步有两种选择。 递归公式：\n$$ dfs(i, c) = \\max(dfs(i-1, c), dfs(i-1, c - w[i]) + v[i]) $$例子 以leetcode-494为例：\n回溯实现，python超时，C++通过\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def findTargetSumWays(self, nums: List[int], target: int) -\u0026gt; int: ans = [0] n = len(nums) def dfs(i, t): if i == n: if t == target: ans[0] += 1 return # 每步可选\u0026#39;+\u0026#39;或\u0026#39;-\u0026#39; dfs(i+1, t-nums[i]) dfs(i+1, t+nums[i]) dfs(0, 0) return ans[0] 动态规划\n注意到：所求方案中的负数和或正数和与总和及target值相关，可转换为0-1背包问题进行求解 状态转移方程：$dfs(i,c)=dfs(i-1,c)+dfs(i-1,c-nums[i])$ dfs(i,c)含义：前i个和为c的方案数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 # 递归形式 def findTargetSumWays(self, nums: List[int], target: int) -\u0026gt; int: target += sum(nums) # 数学约束，保证target存在 if target \u0026lt; 0 or target % 2 != 0: return 0 target //=2 n = len(nums) @cache def dfs(i, t): if i\u0026lt;0: if t==0: return 1 return 0 if nums[i] \u0026gt; t: return dfs(i-1, t) return dfs(i-1, t) + dfs(i-1, t-nums[i]) return dfs(n-1, target) # 数组形式 def findTargetSumWays(self, nums: List[int], target: int) -\u0026gt; int: target += sum(nums) if target \u0026lt; 0 or target % 2 != 0: return 0 target //=2 n = len(nums) # 动态转移方程改为 dfs(i+1,c)=dfs(i,c)+dfs(i,c-nums[i]) dfs = [[0]*(target+1) for _ in range(n+1)] # dfs[0][0]表示最后一轮且c-nums[i]刚好为0 # 其实dfs[i][0]都应该初始化为1，但下面c \u0026lt; nums[i]操作肯定会执行进行拷贝，所以只用初始化第一个 dfs[0][0] = 1 for i in range(n): # 这里遍历范围为target+1，保证n步都能满足 for c in range(target+1): if c \u0026lt; nums[i]: dfs[i+1][c] = dfs[i][c] else: dfs[i+1][c] = dfs[i][c]+dfs[i][c-nums[i]] return dfs[n][target] # 数组形式可优化空间，由状态转移方程可以知道：某一状态只会用到前一个状态的结果，所以只需要两个数组即可 def findTargetSumWays(self, nums: List[int], target: int) -\u0026gt; int: target += sum(nums) if target \u0026lt; 0 or target % 2 != 0: return 0 target //=2 n = len(nums) # 两个数组存储，空间 O(target) dfs = [[0]*(target+1) for _ in range(2)] dfs[0][0] = 1 # 用cur，next标记当前状态和下一个状态，也可用取模操作，但取模操作耗时高 cur, next = 0, 1 for i in range(n): for c in range(target+1): if c \u0026lt; nums[i]: dfs[next][c] = dfs[cur][c] else: dfs[next][c] = dfs[cur][c]+dfs[cur][c-nums[i]] cur, next = next, cur return dfs[cur][target] # 注意到：下一次的状态其实只需要当前的两个位置的状态结果c和c-nums[i]，nums[i]非负，所以可用一个数组逆序转移 def findTargetSumWays(self, nums: List[int], target: int) -\u0026gt; int: target += sum(nums) if target \u0026lt; 0 or target % 2 != 0: return 0 target //=2 n = len(nums) dfs = [0]*(target+1) dfs[0] = 1 for x in nums: for c in range(target, -1, -1): if c \u0026gt;= x: dfs[c] = dfs[c]+dfs[c-x] return dfs[target] 完全背包 概念 有 \\( n \\) 种物品，第 \\( i \\) 种物品的体积为 \\( w[i] \\)，价值为 \\( v[i] \\)。\n每种物品 无限次重复 选，求体积和不超过 \\( capacity \\) 时的最大价值和。\n注意点：\n当前操作？枚举第 \\( i \\) 种物品选一个或不选： 不选，剩余容量不变； 选一个，剩余容量减少 \\( w[i] \\)。 子问题？在剩余容量为 \\( c \\) 时，从 前 \\( i \\) 种物品 中得到的最大价值和。 下一个子问题？分类讨论： 不选：在剩余容量为 \\( c \\) 时，从 前 \\( i-1 \\) 种物品 中得到的最大价值和。 选一个：在剩余容量为 \\( c - w[i] \\) 时，从 前 \\( i \\) 种物品 中得到的最大价值和。 递归公式： $$ dfs(i, c) = \\max(dfs(i-1, c), dfs(i, c - w[i]) + v[i]) $$例子 以leetcode-322为例\n不同于0-1背包某个物品只能选一次 这里要求最小数量：修改转移方程和不满足时返回值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 递归实现 def coinChange(self, coins: List[int], amount: int) -\u0026gt; int: @cache def dfs(i, c): if i\u0026lt;0: if c==0: return 0 return inf if coins[i] \u0026gt; c: return dfs(i-1, c) return min(dfs(i-1, c), dfs(i, c-coins[i])+1) ans = dfs(len(coins)-1, amount) return ans if ans \u0026lt; inf else -1 # 和上一题同理，改为数组+空间优化 def coinChange(self, coins: List[int], amount: int) -\u0026gt; int: n = len(coins) dfs = [inf]*(amount+1) dfs[0]=0 for x in coins: for c in range(amount+1): if c\u0026gt;=x: dfs[c] = min(dfs[c], dfs[c-x]+1) ans = dfs[amount] return ans if ans \u0026lt; inf else -1 ","date":"2022-06-17T00:00:00Z","permalink":"https://loveleaves.github.io/p/coding/","title":"【Coding】算法题编程记录"}]