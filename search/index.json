[{"content":"总结 个人总结，带有偏见，仅作参考\n事物的两面性：一件事从正反面甚至不同方面去思考，思考过程可以理性/感性，站在不同视角不受约束地为己方辩护，最后总结不要带有倾向性。 贴标签/去标签：给人或物贴标签，易于利用已有经验，但也会忽略关键细节。 利己性：根据自己（自发/他人诱发）的目的，调整自己的思想价值观念和行为，使其利于达成自己的目的。 行为复杂性：某一想法无法实现理论设想的行为，因为需要外物去执行，会因外物的利己性导致偏差，甚至替换原有想法。 电影 夜行动物：遗传利弊（原生家庭/后天人格等）、价值观念差异、情感/理性 肖申克的救赎：改变的决心/毅力 书籍 动漫 英雄联盟：双城之战：情感（什么是亲情/友情/爱情）、保守/革新 快乐时刻 人生不止眼前和远方的苟且，还有当下多巴胺的快乐。\n定期花点时间做点自己真正喜欢的事，不管其是否有意义 多接触新的人或事，了解年轻人的想法，保持年轻的心态 ","date":"2025-03-15T00:00:00Z","permalink":"https://loveleaves.github.io/p/life/","title":"记录一些可能对个人思考有用的东西"},{"content":"References https://www.imooc.com/article/361234 https://blog.csdn.net/qq_40610003/article/details/143609078 前言 本文档全面介绍了系统架构师教程，涵盖了角色与职责、所需技能、职业发展路径以及架构设计原则和模式等内容，旨在帮助读者从入门到实践系统架构设计。文章还深入探讨了架构评估与优化策略，并提供了实际案例分析和常用工具介绍，帮助读者全面提升系统架构设计能力。\n介绍 系统架构师（System Architect, SA, SAr）是软件开发团队中的关键角色，负责指导团队进行架构设计和实施。本文档从系统架构师的角色与职责开始，逐步深入到架构设计原则、评估与优化，以及实际案例分析，最后探讨如何通过实践和工具来提升架构设计能力。\nSE和SA区别 系统工程师SE：负责本版本系统分析与设计的所有活动，关注当前版本的所有需求，关注当前版本所有的技术方案，管理SE团队。 架构师SA：负责本产品的架构设计和架构维护，关注影响架构的当前需求和未来需求，关注影响架构的技术方案，负责领域架构在当前版本的落地和产品架构的生命周期管理。 角色与职责 系统架构师的主要职责包括但不限于：\n架构设计：设计系统的整体框架，包括模块划分、组件间关系、数据流等。 技术选型：根据业务需求和技术趋势选择合适的技术栈。 性能优化：确保系统在高并发、大数据量等场景下仍能保持高效运行。 安全性保障：确保系统的安全性，防止数据泄露等安全事件。 团队领导：指导开发团队按照架构设计进行开发，并解决开发过程中遇到的技术难题。 监控与维护：监控系统运行状态，及时发现并解决性能瓶颈等问题。 用户反馈：与用户沟通，收集反馈，并根据用户反馈不断优化架构设计。 需要掌握的技能 系统架构师需要掌握以下技能：\n编程语言：具备至少一种主流编程语言的深厚技术功底，如Java、Python、C#等。 数据结构与算法：深入理解常用的数据结构（如数组、链表、树、图等）和算法（如排序、查找等）。 计算机网络：掌握计算机网络基础知识，如TCP/IP协议、HTTP协议等。 数据库技术：精通至少一种关系型数据库（如MySQL、Oracle）或非关系型数据库（如MongoDB）。 操作系统：熟悉主流的操作系统（如Linux、Windows）和虚拟化技术。 架构设计：理解常用的设计模式（如单例模式、工厂模式等）和架构模式（如微服务、SOA等）。 性能优化：掌握常见的性能优化方法和技术。 安全性：了解常见的安全漏洞和防护方法。 DFX特性：可维可测可靠等。 团队协作：具备良好的团队协作能力和沟通能力。 职业发展路径 系统架构师的职业发展路径通常如下：\n软件工程师：从一个普通的软件工程师开始，逐步积累编程经验。 高级工程师：通过不断学习和实践，成为公司内部的技术专家。 系统架构师：在高级工程师的基础上，进一步提升自己的系统设计能力。 技术总监：成为公司内部的技术决策者，负责整体技术方向和架构设计。 CTO：成为公司的首席技术官，负责公司的技术战略和产品开发。 基础架构知识 架构设计原则与模式 设计模式及其应用 设计模式是面向对象编程中的概念，用于解决特定问题的通用解决方案。常见的设计模式包括单例模式、工厂模式、观察者模式等。\n架构设计基本原则 KISS原则：保持简单，使系统易于理解和维护。 YAGNI原则：避免过度设计，只实现当前需要的功能。 DRY原则：不要重复自己，通过抽象和模块化减少代码冗余。 单一职责原则：每个模块或类只负责一个功能，避免职责混杂。 高内聚、低耦合：模块内部高度紧密，模块间弱耦合。 面向接口编程：通过定义接口来解耦实现细节。 常见架构模式解析 微服务架构：将一个大型系统拆分成多个小型、相互独立的服务，每个服务负责一个特定的功能。 SOA（面向服务的架构）：将系统组件抽象为服务，通过服务间的通信实现业务流程。 事件驱动架构：通过事件触发系统组件的响应，适用于异步处理场景。 架构设计中的常见问题及解决方案 问题1：单点故障\n解决方案：通过冗余设计和故障转移机制来解决单点故障问题。 问题2：性能瓶颈\n解决方案：通过性能测试找出性能瓶颈，并通过缓存、负载均衡等方式进行优化。 问题3：安全性问题\n解决方案：通过输入验证、权限管理和加密传输等方式来提高系统安全性。 架构评估与优化 架构性能评估方法 性能测试：使用工具（如JMeter、LoadRunner）模拟不同负载下的系统性能。 代码审查：检查代码中是否存在潜在的性能瓶颈。 监控与日志：通过监控系统运行状态和分析日志来发现性能问题。 架构安全性与可靠性考虑 安全性考虑：\n输入验证：确保所有输入都经过验证，防止SQL注入、跨站脚本攻击等。 权限管理：确保用户只能访问其权限范围内的资源。 加密传输：使用SSL/TLS协议加密传输数据，防止数据被窃听。 可靠性考虑：\n冗余设计：通过冗余设计提高系统的可用性，如使用多副本存储数据。 故障转移：在主服务不可用时自动切换到备用服务。 容错处理：设计系统时考虑可能出现的异常情况，并提供相应的容错机制。 实际案例分析 典型系统架构案例解析 案例1：电商平台\n架构设计：包括用户中心、订单中心、支付中心等模块。 技术选型：使用Spring Boot进行后端开发，React进行前端开发，MySQL和Redis作为数据库和缓存。 案例解析：通过微服务架构将大型系统拆分为多个小型服务，每个服务专注于一个特定功能。 案例2：视频流媒体平台\n架构设计：包括内容分发、视频编码、用户界面等模块。 技术选型：使用Node.js进行后端开发，React Native进行前端开发，MongoDB和Elasticsearch作为数据库。 案例解析：通过事件驱动架构实现异步处理，提高系统响应速度。 架构设计中的常见问题及解决方案 问题1：单点故障\n解决方案：通过冗余设计和故障转移机制来解决单点故障问题。 问题2：性能瓶颈\n解决方案：通过性能测试找出性能瓶颈，并通过缓存、负载均衡等方式进行优化。 问题3：安全性问题\n解决方案：通过输入验证、权限管理和加密传输等方式来提高系统安全性。 架构优化路径 电商平台\n通过引入缓存机制来减少数据库查询压力。 使用负载均衡来提高系统响应速度。 通过事件驱动架构实现异步处理，减少阻塞等待时间。 视频流媒体平台\n通过使用CDN来提高内容分发速度。 通过使用容器化部署来提高系统的灵活性和可扩展性。 通过引入机器学习算法来优化视频编码效率。 实践与工具 常用架构设计工具介绍 架构设计工具：\nVisio：Microsoft提供的架构设计工具，支持多种图形设计。 Archimate：支持架构建模语言，能够进行企业架构设计。 Lucidchart：在线协作绘图工具，支持架构设计和流程图绘制。 架构设计的实践步骤 实践步骤：\n需求分析：与业务团队沟通，明确业务需求。 技术选型：根据业务需求和技术趋势选择合适的技术栈。 架构设计：设计系统的整体框架，包括模块划分、组件间关系等。 系统实现：根据架构设计进行系统实现。 测试与部署：进行性能测试、安全测试等，确保系统满足要求。 运维监控：监控系统运行状态，不断优化架构设计。 如何构建个人架构设计案例集 构建案例集：\n记录设计过程：记录每次架构设计的过程，包括需求分析、技术选型、架构设计等。 总结经验教训：总结每次设计中的经验教训，不断改进自己的设计能力。 分享交流：通过博客、GitHub等渠道分享自己的设计经验，与他人交流学习。 记录设计过程示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 架构设计案例集 ## 案例1：电商平台架构设计 ### 需求分析 - 用户中心：提供用户信息管理功能。 - 订单中心：处理订单创建、支付、发货等业务逻辑。 ### 技术选型 - 后端：Spring Boot - 前端：React - 数据库：MySQL、Redis ### 架构设计 - 微服务架构：将系统拆分为多个小型服务，每个服务专注于一个特定功能。 - 负载均衡：使用Nginx进行负载均衡，提高系统可用性。 ### 测试与部署 - 性能测试：使用JMeter进行性能测试，确保系统满足性能要求。 - 安全测试：进行输入验证、权限管理等，确保系统安全性。 ### 运维监控 - 监控系统运行状态，及时发现并解决性能瓶颈等问题。 - 使用ELK（Elasticsearch、Logstash、Kibana）进行日志监控。 通过以上步骤，你可以构建出一个完整的个人架构设计案例集，记录自己的设计经验和心得，不断提升自己的架构设计能力。\n","date":"2025-03-08T00:00:00Z","permalink":"https://loveleaves.github.io/p/se_intro/","title":"【SE/SA】 系统架构师/系统工程师介绍"},{"content":"References tensorrt docs tensorrt api install tensorrt TensorRT samples Implementation of popular deep learning networks with TensorRT TensorRT推理部署方案 learning-cuda-trt code tensorRT quantization C++硬代码方案 代表：tensorrtx 流程：C++硬代码=》TRT API =》 TRT Builder =》 TRT Engine ONNX方案 流程：ONNX(libnvonnxparser.so) =》TRT API =》 TRT Builder =》 TRT Engine 一般思路： 导出模型onnx，查看输入和输出。 查看代码，找到onnx的预处理，分析预处理逻辑 利用上述信息实现onnx py推理实现 验证正常可实现转TRT模型用C++实现推理 TensorRT库文件 libnvinfer.so：TensorRT核心库 libnvinfer_plugin.so：nvidia官方提供的插件，github libprotobuf.so：protobuf库 libnvonnxparser.so：ONNX解析 TensorRT部署推理模型流程 模型构建 tensorrt的工作流程如下图： 首先定义网络 优化builder参数 通过builder生成engine,用于模型保存、推理等 engine可以通过序列化和逆序列化转化模型数据类型（转化为二进制byte文件，加快传输速率），再进一步推动模型由输入张量到输出张量的推理。 code structure 定义 builder, config 和network，其中builder表示所创建的构建器，config表示创建的构建配置（指定TensorRT应该如何优化模型），network为创建的网络定义。 输入，模型结构和输出的基本信息（如下图所示） 生成engine模型文件 序列化模型文件并存储 模型推理 执行推理的步骤：\n准备模型并加载\n创建runtime：createInferRuntime(logger)\n使用运行时时，以下步骤：\n反序列化创建engine, 得为engine提供数据：runtime-\u0026gt;deserializeCudaEngine(modelData, modelSize),其中modelData包含的是input和output的名字，形状，大小和数据类型\n1 2 3 4 5 6 class ModelData(object): INPUT_NAME = \u0026#34;data\u0026#34; INPUT_SHAPE = (1, 1, 28, 28) // [B, C, H, W] OUTPUT_NAME = \u0026#34;prob\u0026#34; OUTPUT_SIZE = 10 DTYPE = trt.float32 从engine创建执行上下文:engine-\u0026gt;createExecutionContext()\n创建CUDA流cudaStreamCreate(\u0026amp;stream)：\nCUDA编程流是组织异步工作的一种方式，创建流来确定batch推理的独立 为每个独立batch使用IExecutionContext(3.2中已经创建了)，并为每个独立批次使用cudaStreamCreate创建CUDA流。 数据准备：\n在host上声明input数据和output数组大小，搬运到gpu上 要执行inference，必须用一个指针数组指定input和output在gpu中的指针。 推理并将output搬运回CPU 启动所有工作后，与所有流同步以等待结果:cudaStreamSynchronize\n按照与创建相反的顺序释放内存\n重要接口使用说明：\nTR10中的节点索引变更为字符串，之前是数值 必须使用createNetworkV2,并指定为1（表示显性batch）。createNetwork已经废弃，非显性batch官方不推荐。这个方式直接影响推理时enqueue还是enqueueV2（TR10为V3） builder、config等指针，记得释放，否则会有内存泄漏，使用ptr-\u0026gt;destroy()（TR10使用delete）释放 markOutput表示是该模型的输出节点，mark几次，就有几个输出，addlnput几次就有几个输入。这与推理时相呼应 workspaceSize是工作空间大小，某些layer需要使用额外存储时，不会自己分配空间，而是为了内存复用，直接找tensorRT要workspace空间。 bindings是tensorRT对输入输出张量的描述，bindings = input-tensor + output-tensor。比如input有a, output有b,c, d,那么bindings = [a, b, c, d],bindings[0] = a, bindings[2] = c。此时看到engine- \u0026gt;getBindingDimensions(0)你得知道获取的是什么（TRT10改成了IOTensors） enqueueV2是异步推理，加入到stream队列等待执行。输入的bindings则是tensors的指针（注意是device pointer）。其shape对应于编译时指定的输入输出的shape(这里只演示全部shape静态)（TRT10使用enqueueV3） 动态shape 构建网络时：\n1.1. 必须在模型定义时，输入维度给定为-1，否则该维度不会动态。注意一下两点： 1.1.1. 若onnx文件，则onnx文件打开后应该看到为动态或者-1 1.1.2. 如果你的模型中存在reshape类操作，那么reshape的参数必须随动态进行计算。而大部分时候这都是问题。除非你是全卷积模型，否则大部分时候只需要为batch_size维度设置为动态，其他维度尽量避免设置动态 1.2. 配置profile: 1.2.1. create: builder-\u0026gt;createOptimizationProfile() 1.2.2. set: setDimensions()设置kMIN, kOPT, kMAX的一系列输入尺寸范围 1.2.3. add:config-\u0026gt;addOptimizationProfile(profile);添加profile到网络配置中 推理阶段时：\n2.1. 您需要在选择profile的索引后设置input维度：execution_context-\u0026gt;setBindingDimensions(0, nvinfer1::Dims4(1, 1, 3, 3)); （TR10为setInputShape） 2.1.1. 关于profile索引: 2.1.2. 在运行时，向engine请求绑定维度会返回用于构建网络的相同维度。这意味着，得到的还是动态的维度[-1, in_channel, -1, -1]： 1 2 engine.getBindingDimensions(0) // return [-1, 1, -1, -1] // execution_context-\u0026gt;getTensorShape // TR10接口 获取当前的实际维度，需要查询执行上下文： 1 context.getBindingDimensions(0) // return [3, 1, 3, 3] 检查正确性\n我们通常可以利用pytorch来校验是否发生了错误 ONNX模型操作 代码实战：\npytorch-gen-onnx.py：是之前讲过的从pytorch转换onnx格式的代码。 通过onnx-ml.proto和make-onnx-pb.sh了解onnx的结构 2.1. onnx是基于protobuf来做数据存储和传输,*.proto后缀文件, 其定义是protobuf语法，类似json。 2.2. 对于变量结构、类型等，我们可以参照onnx-ml.proto里面的定义。这个文件有800多行，放心我们只要搞清楚里面的核心部分就行： ModelProto:当加载了一个onnx后，会获得一个ModelProto。它包含一个GraphProto和一些版本，生产者的信息。 GraphProto: 包含了四个repeated数组(可以用来存放N个相同类型的内容，key值为数字序列类型.)。这四个数组分别是node(NodeProto类型)，input(ValueInfoProto类型)，output(ValueInfoProto类型)和initializer(TensorProto类型)； NodeProto: 存node，放了模型中所有的计算节点,语法结构如下： ValueInfoProto: 存input，放了模型的输入节点。存output，放了模型中所有的输出节点； TensorProto: 存initializer，放了模型的所有权重参数 AttributeProto:每个计算节点中还包含了一个AttributeProto数组，用来描述该节点的属性，比如Conv节点或者说卷积层的属性包含group，pad，strides等等； 2.3. 通过protoc编译onnx-ml.proto，产生onnx-ml.pb.cc文件 1 bash make-onnx-pb.sh create-onnx.py 3.1. create-onnx.py直接从构建onnx，不经过任何框架的转换。通过import onnx和onnx.helper提供的make_node，make_graph，make_tensor等等接口我们可以轻易的完成一个ONNX模型的构建。 3.2. 需要完成对node，initializer，input，output，graph，model的填充 3.3. 读懂creat-onnx.py以make_node为例： edit-onnx.py 4.1. 由于protobuf任何支持的语言，我们可以使用[c/c++/python/java/c#等等]实现对onnx文件的读写操作 4.2. 掌握onnx和helper实现对onnx文件的各种编辑和修改 增：一般伴随增加node和tensor 1 2 graph.initializer.append(xxx_tensor) graph.node.insert(0, xxx_node) 删： 1 graph.node.remove(xxx_node) 改： 1 input_node.name = \u0026#39;data\u0026#39; read-onnx.py 5.1 通过graph可以访问参数，数据是以protobuf的格式存储的，因此当中的数值会以bytes的类型保存。需要用np.frombuffer方法还原成类型为float32的ndarray。注意还原出来的ndarray是只读的。 ONNX Parser onnx解析器有两个选项，\nlibnvonnxparser.so或者 onnx-tensorrt parser(源代码)。 使用源代码的目的，是为了更好的进行自定义封装，简化插件开发或者模型编译的过程，更加具有定制化，遇到问题可以调试 onnx-tensorrt parser代码使用：\n什么是onnx: 先看名字：Open Neural Network Exchange(ONNX) 是一个开放的生态系统，使代码不被局限在框架和平台中。 具体一点：onnx可以把你的神经网络模型(PyTroch, TF, Caffe)统统转为标准的ONNX格式(一种protobuf格式)，然后就可在各种平台(云平台, windows, linux)和设备(cpu, gpu, npu)上运行 先看文件gen-onnx.py以pytorch构建的模型为例讲：pytorch模型转onnx格式 构建一个pytorch网络，并声明一个model对象 如果进行推理，将模型设为推理状态：这一点很重要，因为像dropout, batchnorm这样的算子在推理和训练模式下的行为是不同的。 导出为onnx模型：torch.onnx.export() 运行python脚本，生成onnx，在main.cpp中会对其进行解析 1 python gen-onnx.py 运行后的图示： Protobuf则通过onnx-ml.proto编译得到onnx-ml.pb.h和onnx-ml.pb.cc或onnx_ml_pb2.py 然后用onnx-ml.pb.cc和代码来操作onnx模型文件，实现增删改 onnx-ml.proto则是描述onnx文件如何组成的，具有什么结构，他是操作onnx经常参照的东西 再看文件main.cpp讲解如何解析onnx格式 使用onnx解析器：createParser的api在文件NvOnnxParser.h中 在这里使用onnx的结果填充到network中，而手动构建网络则是将输入和算子填入network中，区别如图所示： 导出后，可以使用netron软件进行打开查看:https://github.com/lutzroeder/Netron 除了构建过程的区别，makefile中，库文件也需要加上nvonnxparser： 注意：\nseverity_string 和 log仅是工具函数，无需过分关注 导出TRT模型 为了使用onnx导出网络有三种方式：\n我们使用自带的解析器，libnvonnxparser.so 从源代码编译：onnx-tensorrt，主要protobuf文件： onnx-ml.proto 来源 onnx-operators-ml.proto 来源 利用官方工具trtexec，YOLOv8部署推理案例 Usage: 1 2 3 4 5 /usr/src/tensorrt/bin/trtexec \\ --onnx=yolov8s.onnx \\ --saveEngine=yolov8s.engine \\ --fp16 # or --int8 Plugin 1.如何在pytorch里面导出一个插件 2.插件解析时如何对应，在onnx parser中如何处理 3.插件的creator实现 4.插件的具体实现，继承自IPluginV2DynamicExt 5.插件的序列化与反序列化\n量化 int8量化 对于int8，需要配置setFlag nvinfer1::BuilderFlag::kINT8，并且配置setInt8Calibrator 对于Int8EntropyCalibrator，则需要继承自IInt8EntropyCalibrator2 Int8EntropyCalibrator的作用，是读取并预处理图像数据作为输入 标定的原理，是通过输入标定图像I，使用参数WInt8推理得到输出结果PInt8，然后不断调整WInt8，使得输出PInt8与PFloat32越接近越好 因此标定时通常需要使用一些图像，正常发布时，一般使用100张图左右即可 常用的Calibrator Int8EntropyCalibrator2 熵校准选择张量的比例因子来优化量化张量的信息论内容，通常会抑制分布中的异常值。这是当前推荐的熵校准器。默认情况下，校准发生在图层融合之前。推荐用于基于 CNN 的网络。 Iint8MinMaxCalibrator 该校准器使用激活分布的整个范围来确定比例因子。它似乎更适合NLP任务。默认情况下，校准发生在图层融合之前。推荐用于NVIDIA BERT等网络。 计算机中的float计算量是非常大的，而改成int8后，计算量相比可以提升数倍 对于实际操作时，input[float32], w[int8], bias[float32], output[float32] 步骤如下： input[int8] = to_int8(input[float32]) y[int16] = input[int8] * w[int8] # 此处乘法会由计算机转换为int16，保证精度 output[float32] = to_float32(y[int16]) + bias[float32] 所以整个过程的只是为了减少float32的乘法数量以实现提速 对于to_int8的过程，并不是直接的线性缩放，而是经过KL散度计算最合适的截断点（最大、最小值），进而进行缩放，使得权重的分布尽可能小的被改变 可以参照这个地址：https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf ","date":"2025-03-02T00:00:00Z","permalink":"https://loveleaves.github.io/p/tensorrt_deploy/","title":"【TensorRT】 TensorRT模型部署介绍"},{"content":"References onnx量化推理例子 onnxruntime docs onnxruntime quantization ONNX Runtime Quantization Example, Pre-processing step Overview Quantization in ONNX Runtime refers to 8 bit linear quantization of an ONNX model.\nDuring quantization, the floating point values are mapped to an 8 bit quantization space of the form: val_fp32 = scale * (val_quantized - zero_point)\nscale is a positive real number used to map the floating point numbers to a quantization space. It is calculated as follows:\nFor asymmetric quantization:\n1 scale = (data_range_max - data_range_min) / (quantization_range_max - quantization_range_min) For symmetric quantization:\n1 scale = max(abs(data_range_max), abs(data_range_min)) * 2 / (quantization_range_max - quantization_range_min) zero_point represents zero in the quantization space. It is important that the floating point zero value be exactly representable in quantization space. This is because zero padding is used in many CNNs. If it is not possible to represent 0 uniquely after quantization, it will result in accuracy errors.\nONNX Quantization introduction ONNX Runtime provides python APIs for converting 32-bit floating point model to an 8-bit integer model, a.k.a. quantization. These APIs include pre-processing, dynamic/static quantization, and debugging.\nPre-processing: Pre-processing is to transform a float32 model to prepare it for quantization. The goal of these steps is to improve quantization quality. Dynamic Quantization: Dynamic quantization calculates the quantization parameters (scale and zero point) for activations dynamically. Static Quantization: quantization parameters are calculated in advance (offline) using a calibration data set. Quantization Debugging: Quantization may negatively affect a model’s accuracy. A solution to this problem is to compare the weights and activations tensors of the original computation graph vs those of the quantized one, identify where they differ most, and avoid quantizing these tensors, or choose another quantization/calibration method. Create Float16 and Mixed Precision Models offical web Converting a model to use float16 instead of float32 can decrease the model size (up to half) and improve performance on some GPUs. There may be some accuracy loss, but in many models the new accuracy is acceptable. Tuning data is not needed for float16 conversion, which can make it preferable to quantization.\nORT model format The ORT format is the format supported by reduced size ONNX Runtime builds. Reduced size builds may be more appropriate for use in size-constrained environments such as mobile and web applications.\nBoth ORT format models and ONNX models are supported by a full ONNX Runtime build.\nONNX onnx tutorial ONNX文件介绍 1、.ONNX的本质，是一种Protobuf格式文件 2、Protobuf则通过onnx-ml.proto编译得到onnx-ml.pb.h和onnx-ml.pb.cc或onnx_ml_pb2.py 3、然后用onnx—ml.pb.cc和代码来操作onnx模型文件，实现增删改 4、onnx—ml.proto则是描述onnx文件如何组成的，具有什么结构，他是操作onnx经常参照的东西 details、concepts ONNX结构 model：表示整个onnx的模型，包含图结构和解析器格式、opset版本、导出程序类型model.graph：表示图结构，通常是我们netron看到的主要结构 model.graph.node:表示图中的所有节点，数组，例如conv、bn等节点就是在这里的，通过input、output 表示节点之间的连接关系 model.graph.initializer:权重类的数据大都储存在这里 model.graph.input：整个模型的输入储存在这里，表明哪个节点是输入节点，shape是多少model.graph.output：整个模型的输出储存在这里，表明哪个节点是输出节点，shape是多少 对于anchorgrid类的常量数据，通常会储存在model.graph.node中，并指定类型为Constant,该类型节点在 netron中可视化时不会显示出来 onnx文件及其结构、正确导出onnx、onnx读取、onnx创建、onnx修改、onnx解析器 ONNX文件操作 code 1.ONNX的主要结构：graph、graph.node、graph.initializer、graph.input、graph.output 2.ONNX的节点构建方式：onnx.helper,各种make函数 3.ONNX的proto文件：onnx-proto2 4.理解模型结构的储存、权重的储存、常量的储存、netron的解读对应到代码中的部分 ONNX模型文件正确导出 自pytorch2.5以后，onnx的导出有两个版本exporter实现：export_simple_model_to_onnx_tutorial\ntorch.onnx.export 对于任何用到shape、size返回值的参数时，例如：tensor.view(tensor.size(0),-1)这类操作，避免直接使用tensor.size的返回值，而是加上int转换，tensor.view(int(tensor.size(0),-1),断开跟踪 对于nn.Upsample或nn.functional.interpolate函数，使用scale_factor指定倍率，而不是使用size参数指定大小 对于reshape、view操作时，—1的指定请放到batch维度。其他维度可以计算出来即可。batch维度禁止指定为大于-1的明确数字 torch.onnx.export指定dynamic_axes参数，并且只指定batch维度，禁止其他动态 使用opset_version=11,不要低于11 避免使用inplace操作，例如y[·,0:2]=y[·,0:2]*2-0.5 尽量少的出现5个维度，例如ShuffleNet Module，可以考虑合并wh避免出现5维 尽量把让后处理部分在onnx模型中实现，降低后处理复杂度 掌握了这些，就可以保证后面各种情况的顺利了 这些做法的必要性体现在，简化过程的复杂度，去掉gather、shape类的节点，很多时候，部分不这么改看似也是可以但是需求复杂后，依旧存在各类问题。按照说的这么修改，基本总能成。做了这些，就不需要使用onnx—simplifer了\n以上导出方法在导出自定义算子后，如果要在onnxruntime导入使用，首先需要再定义onnxruntime算子\ntorch.onnx.export(\u0026hellip;, dynamo=True) using torch.export and Torch FX to capture the graph. It was released with PyTorch 2.5 1 2 3 4 5 6 7 8 9 10 # Export the ONNX model onnx_program = torch.onnx.export(torch_model, example_inputs, dynamo=True) # Optimize the ONNX model # The ONNX model can be optimized with constant folding, and elimination of redundant nodes. onnx_program.optimize() # Save the ONNX model onnx_program.save(\u0026#34;demo.onnx\u0026#34;) # Check the ONNX model onnx_model = onnx.load(\u0026#34;deom.onnx\u0026#34;) onnx.checker.check_model(onnx_model) Example Simple Example The example has three parts:\nPre-processing Quantization Debugging YOLOv8 code Static Quantization ","date":"2025-02-20T00:00:00Z","permalink":"https://loveleaves.github.io/p/onnx_quantization/","title":"【ONNX量化】 ONNX量化推理介绍"},{"content":"计算机体系结构 存储器层次结构设计 分层思想/模型：分层解构，更好地理解，分工明确，可维护性高。 缓存（Cache） 特点\n硬件上：成本高但性能好 使用上：部分内容会被重复利用 应用场景：CPU 性能和Cache Line ","date":"2025-02-18T00:00:00Z","permalink":"https://loveleaves.github.io/p/cs/","title":"【CS】计算机科学重要思想、成果记录"},{"content":"References Int8量化-介绍 量化方法汇总 从TensorRT与ncnn看CNN卷积神经网络int8量化算法 谷歌量化白皮书：Quantizing deep convolutional networks for efficient inference: A whitepaper、Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference ppq 神经网络 - 量化与部署 模型压缩：模型量化打怪升级之路 - 1 工具篇 神经网络加速基础知识 计算机体系结构/组成原理 主要了解以下部分：\n指令系统 计算机组成原理和结构 流水线技术 指令耗时/热点指令 现代处理器 经典CPU体系结构 x86架构（CISC） 胶水typo，多核心 部分组件公共化，提高集成度 GPU架构 共享指令译码和控制，ALU运行的指令相同（分支发散问题） GPU架构介绍 ASIC专用芯片架构 继续移除非必要指令（浮点、图形支持等） 特定领域设计 异构计算与主从设备交互 找到性能瓶颈（performance bottleneck） 高算力场景=》用ASIC等芯片，提高算力，高延迟 低延迟场景=》用FPGA等芯片，降低延迟，低算力 性能热点分析工具 torch Profiler Nsight Compute Nsight Compute 量化硬件实现 量化算子 基本公式：\n1 2 3 4 float value = 1.0; // 输入值 float scale = 0.1; // 用于缩放输入值（尺度因子） int32 qt_32 = round_fn(value/scale); // 取整 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 取整函数round_fn比较特别，在不同硬件上有不同的取整模式（主要对中间值，如1.5，-2.5等），常见取整模式：\nRound half to even，torch 、 C使用，向偶数方向取整 Round half away from zero，向正负无穷方向取整 Round half toward zero，向0方向取整 Round half down，向下取整 Round half up，向上取整 量化子图与全精度子图（quantized subgraph） 权重是可以直接计算出来的，推理的时候只要计算一下量化算子即可\n通常情况，量化算子全部支持场景： 存在不支持量化算子，可用子图分割分离不支持运算子图分开计算，但会导致访存开销为热点 反量化算子 基本公式：\n1 2 3 Char value = 1; // 量化算子/运算输出值 float scale = 0.1; // 用于缩放输入值（尺度因子） Float deq = (value * scale); 量化模式（量化与反量化） 对称量化：基本量化模式，分布对称 1 2 3 int32 qt_32 = round_fn(value/scale); // 取整 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 // 反量化对应量化反向操作，类似encode《=》decode 非对称量化：充分利用int8数值范围（如relu负数范围） 1 2 int32 qt_32 = round_fn(value/scale) + offset; // 取整 uint8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 整数量化（power of two）：部分硬件不支持浮点运算，用整数运算替换 1 2 int32 qt_32 = round_fn(value * (2 \u0026lt;\u0026lt; shift)); // 取整，shift-定点位 int8 qt_8 = clip(qt_32, Q_MIN, Q_MAX); // 范围截断 指数量化\u0026hellip; tensor量化与通道量化 以上对称/非对称量化、整数量化中的offset、shift可以整个数据为粒度进行量化（可能数值偏差大，量化差），也可以采用其他粒度进行量化：\ntensor量化（per-tensor）：以单个tensor为粒度 通道量化（per-channel）：以单个channel为粒度 量化计算怎么写 整数运算：在许多硬件上，整数运算的微指令条数和指令吞吐量等可能和浮点差不多甚至比浮点差 访存：量化后数据传输耗时少 向量化技术：SIMD/SIMT，代码向量化网站 量化计算一般是：量化+反量化，目的是为了保证量化计算的逻辑与原来一致 量化乘法（quantized mul） 正常int8计算会溢出，所以先反量化成float计算乘法再量化，即量化计算一般要加上rescale操作\n1 2 3 4 5 6 7 // 原本量化运算 ouput[i][j]=inputa[i][j]*inputb[i][j]; //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn(inputa[i][j]*scale_a * inputb[i][j] * scale_b / scale_c)); // scale 为float 即 ouput[i][j]=quantizied(inputa[i][j] * inputb[i][j] / scale_abc); // scale_abc 可提前算 // 同理，如果采用整数量化 即 ouput[i][j]=quantizied(inputa[i][j] * inputb[i][j] \u0026lt;\u0026lt; round(log2 scale_abc)); // scale_abc 可提前算 量化加法 加法要求两个操作数的scale必须一致 1 2 3 4 5 6 // 原本量化运算 ouput[i][j]=inputa[i][j]+inputb[i][j]; //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn((inputa[i][j]*scale_a + inputb[i][j] * scale_b) / scale_c)); // scale 为float // 这里加法要求scale_a和scale_b必须一致（两个操作数的scale） 即 ouput[i][j]=quantizied((inputa[i][j] + inputb[i][j]) / scale_ab); // scale_ab 可提前算 量化激活函数 要求输入输出的scale必须一致 1 2 3 4 5 6 7 // 原本clip量化运算 ouput[i][j]=max(inputa[i][j], min); //in/out均为int8 // 如果采用对称量化 ouput[i][j]=clip(round_fn((inputa[i][j]*scale_in + min) / scale_out)); // scale 为float // 这里加法要求scale_in和scale_out必须一致 即 ouput[i][j]=inputa[i][j] + min / scale_in; // 注意这里没有round_fn、clip操作，min被动量化 // 这时这类算子被称为被动量化算子，如clip、relu、concat等 量化矩阵乘（quantized Gemm） int8输入=》int16/32计算乘法=》int32/64保存求和结果=》量化为int8输出 量化非线性运算 算子包含非线性运算。如：exp、tanh、sigmoid、softmax等 非线性运算：用int无法替代float计算求得结果 CPU、GPU上，不做量化，以全精度模式运行 FPGA、ASIC、DSP上，不支持浮点运算，需要更改算子计算逻辑，以线性运算拟合或直接查表 计算图 算子 常见算子：https://github.com/onnx/onnx/blob/main/docs/Operators.md 最小调度单位 算子融合加速：减少访存调用栈开销，优化计算逻辑 常见计算图优化（算子融合） 计算图优化实践：https://www.bilibili.com/video/BV1Kr4y1n7cy/\n激活函数融合：Computing Op -\u0026gt; Activation =\u0026gt; ConputAct 常见OP：Conv、ConvTranpose、Gemm 常见Act：Relu、Clip（relu6）、Prelu、Tanh、Sigmoid、Switsh 移除batchnorm和dropout 常量折叠：把常量融合进行计算 矩阵乘融合 conv-add融合：Conv + any =\u0026gt; Y = Wx + (Y2 + B) Conv：Y1=WX+B any：Y2 联合定点 用于支持多后端使用，保留原始计算图信息和量化后的计算图信息\n图调度（Graph Dispatching） 误差分析后发现部分算子的误差较大，可将其单独调度到非量化平台计算 图模式匹配 一个计算图可以表示为一个由节点、边集、输入边、输出边组成的四元组 C = {N, E, I, O}。\n我们往往需要在计算图中寻找指定结构。\n如何用一个严谨的方式定义结构？ 如何设计计算模式匹配法，使得其尽可能高效？ 图模式匹配是量化算法、算子融合、算子调度的基础。 图模式匹配可用方法：子图匹配、遍历模式匹配 例子 想象一个场景，onnx不支持swish算子，其可能用以下算子组合实现： 这样有一个问题，量化时会将这三个算子都量化一遍，但其实只需要量化最后一个mul算子即可。这里就可以利用图模式匹配匹配到这个替代的swish结构，并针对性进行处理。\n1 2 3 4 5 6 7 8 9 // 匹配swish，子图模式匹配 search_engine = SearchableGraph(graph) results = search_engine.pattern_matching( patterns = lambda x: x.is_computing_op(\u0026#39;Sigmoid\u0026#39;, \u0026#39;Mul\u0026#39;), edges = [[0, 1], [1, 2], [0, 2]], exclusive = True ) for computing_op, sigmoid, mul in results: ... 遍历模式匹配 匹配模式：起点表达式=》中继点..=》终点..，自动机 步骤：图拆成树，树拆成链，在每个链上进行模式匹配，期间可用动态规划优化 子图模式匹配 子图同构问题为NP-Hard问题，使用近似算法 避免模式pattern多义性，保持互斥 算子调度 SOI正向传播：从开始算子往后找，可能有多个匹配 正向传播的反方向，从终点算子开始往前找 调度争议区：既可以量化，又不可以量化 调度约束： 激活函数与计算节点保持同一平台 NMS、shape、TOPK、MAX与计算节点保持同一平台 参与图融合的算子保持同一平台 孤立计算节点不量化 多输入算子所有输入同平台 手动调度：权衡精度和速度，考虑硬件支持情况 神经网络部署 运行时（runtime） 实际硬件执行库，针对不同硬件有不同实现\n神经网络部署 各厂商的训练框架、推理框架、硬件厂商 部署流程：训练框架训练模型=》导出统一中间表达模型（可选）=》指定推理框架=》指定硬件执行 部署建议：\n确保你的网络可以被Onnx表示，避免其中出现复杂条件逻辑及循环逻辑。 学会自定义算子，以备不时之需，（包括自定义算子的推理实现）。 避免使用各种小Trick，额外加入的算子很可能会破坏图优化。 神经网络能跑多快是Runtime决定的，神经网络加速应当根据runtime进行。 用一下 Onnx Simplifier。 写一个固定的 batchsize大小（latency和吞吐）。 ONNX部署推理 onnxruntime TensorRT Develop Guide, docs、quantization 连贯量化区：不要在网络中过度使用不可量化算子 网络结构设计、量化点插入不能破坏图融合 Tensor对齐 Profiler工具分析：Nsight System 自定义算子，必要时自己写plugin：https://github.com/NVIDIA/TensorRT/tree/release/10.8/plugin 量化理论分析 量化参数选择 假设 Ln/s用比值来评估量化偏差，忽略实际值的大小 int8实际应为-128，这里为了对称写成-127 注意这里的截断边界条件为.5，如127.5，-127.5，为了尽可能保留原精度 最大值截断 也就是说最大值截断在元素值趋于无限时，会出现误差发散的情况。 分位数截断 实际运用时，结合3-sigma原则取近似sigma值 最优截断 Bernard Widrow公式 最优估计问题：\n最优截断要求pdf的三阶积分，并求导令上式为0，对于大部分分布而言，无法顺利求得解析解。 同时在很多情况下，局部的MSE最优并不是全局MSE最优的。 数据量小时，估计的方差很大。 枚举最优截断 梯度优化截断 量化误差分析 https://www.bilibili.com/video/BV1V94y117Ej/\n量化框架 PPQ PPQ框架介绍 大模型LLM推理加速 TensorRT pytorch-quantization ONNX onnxruntime quantization onnx介绍 NCNN NCNN Conv量化详解 ","date":"2025-02-10T00:00:00Z","permalink":"https://loveleaves.github.io/p/quantization/","title":"【量化】 神经网络量化介绍"},{"content":"设计模式简介 以下引用自菜鸟教程、design pattern\n设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。\n设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。\n什么是 GOF（四人帮，全拼 Gang of Four）？ 在 1994 年，由 Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 四人合著出版了一本名为 Design Patterns - Elements of Reusable Object-Oriented Software（中文译名：设计模式 - 可复用的面向对象软件元素） 的书，该书首次提到了软件开发中设计模式的概念。\n四位作者合称 GOF（四人帮，全拼 Gang of Four）。他们所提出的设计模式主要是基于以下的面向对象设计原则。\n对接口编程而不是对实现编程。 优先使用对象组合而不是继承。 设计模式之美-王争 知识概览图 课程目录 文章导览 简介 开篇词 | 一对一的设计与编码集训，让你告别没有成长的烂代码！ 01 | 为什么说每个程序员都要尽早地学习并掌握设计模式相关知识？ 02 | 从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？ 03 | 面向对象、设计原则、设计模式、编程规范、重构，这五者有何关系？ 04 | 理论一：当谈论面向对象的时候，我们到底在谈论什么？ 05 | 理论二：封装、抽象、继承、多态分别可以解决哪些编程问题？ 06 | 理论三：面向对象相比面向过程有哪些优势？面向过程真的过时了吗？ 07 | 理论四：哪些代码设计看似是面向对象，实际是面向过程的？ 08 | 理论五：接口vs抽象类的区别？如何用普通的类模拟抽象类和接口？ 09 | 理论六：为什么基于接口而非实现编程？有必要为每个类都定义接口吗？ 10 | 理论七：为何说要多用组合少用继承？如何决定该用组合还是继承？ 11 | 实战一（上）：业务开发常用的基于贫血模型的MVC架构违背OOP吗？ 12 | 实战一（下）：如何利用基于充血模型的DDD开发一个虚拟钱包系统？ 13 | 实战二（上）：如何对接口鉴权这样一个功能开发做面向对象分析？ 14 | 实战二（下）：如何利用面向对象设计和编程开发接口鉴权功能？ 15 | 理论一：对于单一职责原则，如何判定某个类的职责是否够“单一”？ 16 | 理论二：如何做到“对扩展开放、修改关闭”？扩展和修改各指什么？ 17 | 理论三：里式替换（LSP）跟多态有何区别？哪些代码违背了LSP？ 18 | 理论四：接口隔离原则有哪三种应用？原则中的“接口”该如何理解？ 19 | 理论五：控制反转、依赖反转、依赖注入，这三者有何区别和联系？ 20 | 理论六：我为何说KISS、YAGNI原则看似简单，却经常被用错？ 21 | 理论七：重复的代码就一定违背DRY吗？如何提高代码的复用性？ 22 | 理论八：如何用迪米特法则（LOD）实现“高内聚、松耦合”？ 23 | 实战一（上）：针对业务系统的开发，如何做需求分析和设计？ 24 | 实战一（下）：如何实现一个遵从设计原则的积分兑换系统？ 25 | 实战二（上）：针对非业务的通用框架开发，如何做需求分析和设计？ 26 | 实战二（下）：如何实现一个支持各种统计规则的性能计数器？ 27 | 理论一：什么情况下要重构？到底重构什么？又该如何重构？ 28 | 理论二：为了保证重构不出错，有哪些非常能落地的技术手段？ 29 | 理论三：什么是代码的可测试性？如何写出可测试性好的代码？ 30 | 理论四：如何通过封装、抽象、模块化、中间层等解耦代码？ 31 | 理论五：让你最快速地改善代码质量的20条编程规范（上） 32 | 理论五：让你最快速地改善代码质量的20条编程规范（中） 33 | 理论五：让你最快速地改善代码质量的20条编程规范（下） 34 | 实战一（上）：通过一段ID生成器代码，学习如何发现代码质量问题 35 | 实战一（下）：手把手带你将ID生成器代码从“能用”重构为“好用” 36 | 实战二（上）：程序出错该返回啥？NULL、异常、错误码、空对象？ 37 | 实战二（下）：重构ID生成器项目中各函数的异常处理代码 38 | 总结回顾面向对象、设计原则、编程规范、重构技巧等知识点 39 | 运用学过的设计原则和思想完善之前讲的性能计数器项目（上） 40 | 运用学过的设计原则和思想完善之前讲的性能计数器项目（下） 41 | 单例模式（上）：为什么说支持懒加载的双重检测不比饿汉式更优？ 42 | 单例模式（中）：我为什么不推荐使用单例模式？又有何替代方案？ 43 | 单例模式（下）：如何设计实现一个集群环境下的分布式单例模式？ 44 | 工厂模式（上）：我为什么说没事不要随便用工厂模式创建对象？ 45 | 工厂模式（下）：如何设计实现一个Dependency Injection框架？ 46 | 建造者模式：详解构造函数、set方法、建造者模式三种对象创建方式 47 | 原型模式：如何最快速地clone一个HashMap散列表？ 48 | 代理模式：代理在RPC、缓存、监控等场景中的应用 49 | 桥接模式：如何实现支持不同类型和渠道的消息推送系统？ 50 | 装饰器模式：通过剖析Java IO类库源码学习装饰器模式 51 | 适配器模式：代理、适配器、桥接、装饰，这四个模式有何区别？ 52 | 门面模式：如何设计合理的接口粒度以兼顾接口的易用性和通用性？ 53 | 组合模式：如何设计实现支持递归遍历的文件系统目录树结构？ 54 | 享元模式（上）：如何利用享元模式优化文本编辑器的内存占用？ 55 | 享元模式（下）：剖析享元模式在Java Integer、String中的应用 56 | 观察者模式（上）：详解各种应用场景下观察者模式的不同实现方式 57 | 观察者模式（下）：如何实现一个异步非阻塞的EventBus框架？ 58 | 模板模式（上）：剖析模板模式在JDK、Servlet、JUnit等中的应用 59 | 模板模式（下）：模板模式与Callback回调函数有何区别和联系？ 60 | 策略模式（上）：如何避免冗长的if-else/switch分支判断代码？ 61 | 策略模式（下）：如何实现一个支持给不同大小文件排序的小程序？ 62 | 职责链模式（上）：如何实现可灵活扩展算法的敏感信息过滤框架？ 63 | 职责链模式（下）：框架中常用的过滤器、拦截器是如何实现的？ 64 | 状态模式：游戏、工作流引擎中常用的状态机是如何实现的？ 65 | 迭代器模式（上）：相比直接遍历集合数据，使用迭代器有哪些优势？ 66 | 迭代器模式（中）：遍历集合的同时，为什么不能增删集合元素？ 67 | 迭代器模式（下）：如何设计实现一个支持“快照”功能的iterator？ 68 | 访问者模式（上）：手把手带你还原访问者模式诞生的思维过程 69 | 访问者模式（下）：为什么支持双分派的语言不需要访问者模式？ 70 | 备忘录模式：对于大对象的备份和恢复，如何优化内存和时间的消耗？ 71 | 命令模式：如何利用命令模式实现一个手游后端架构？ 72 | 解释器模式：如何设计实现一个自定义接口告警规则功能？ 73 | 中介模式：什么时候用中介模式？什么时候用观察者模式？ 74 | 总结回顾23种经典设计模式的原理、背后的思想、应用场景等 75 | 在实际的项目开发中，如何避免过度设计？又如何避免设计不足？ 76 | 开源实战一（上）：通过剖析Java JDK源码学习灵活应用设计模式 77 | 开源实战一（下）：通过剖析Java JDK源码学习灵活应用设计模式 78 | 开源实战二（上）：从Unix开源开发学习应对大型复杂项目开发 79 | 开源实战二（中）：从Unix开源开发学习应对大型复杂项目开发 80 | 开源实战二（下）：从Unix开源开发学习应对大型复杂项目开发 81 | 开源实战三（上）：借Google Guava学习发现和开发通用功能模块 82 | 开源实战三（中）：剖析Google Guava中用到的几种设计模式 83 | 开源实战三（下）：借Google Guava学习三大编程范式中的函数式编程 84 | 开源实战四（上）：剖析Spring框架中蕴含的经典设计思想或原则 85 | 开源实战四（中）：剖析Spring框架中用来支持扩展的两种设计模式 86 | 开源实战四（下）：总结Spring框架用到的11种设计模式 87 | 开源实战五（上）：MyBatis如何权衡易用性、性能和灵活性？ 88 | 开源实战五（中）：如何利用职责链与代理模式实现MyBatis Plugin？ 89 | 开源实战五（下）：总结MyBatis框架中用到的10种设计模式 90 | 项目实战一：设计实现一个支持各种算法的限流框架（分析） 91 | 项目实战一：设计实现一个支持各种算法的限流框架（设计） 92 | 项目实战一：设计实现一个支持各种算法的限流框架（实现） 93 | 项目实战二：设计实现一个通用的接口幂等框架（分析） 94 | 项目实战二：设计实现一个通用的接口幂等框架（设计） 95 | 项目实战二：设计实现一个通用的接口幂等框架（实现） 96 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（分析） 97 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（设计） 98 | 项目实战三：设计实现一个支持自定义规则的灰度发布组件（实现） 99 | 总结回顾：在实际软件开发中常用的设计思想、原则和模式 100 | 如何将设计思想、原则、模式等理论知识应用到项目中？ 加餐一 | 用一篇文章带你了解专栏中用到的所有Java语法 加餐二 | 设计模式、重构、编程规范等相关书籍推荐 春节特别加餐 | 王争：如何学习《设计模式之美》专栏？ 加餐三 | 聊一聊Google是如何做Code Review的 加餐四 | 聊一聊Google那些让我快速成长的地方 加餐五 | 听一听小争哥对Google工程师文化的解读 加餐六 | 什么才是所谓的编程能力？如何考察一个人的编程能力？ 加餐七 | 基础学科的知识如何转化成实际的技术生产力？ 加餐八 | 程序员怎么才能让自己走得更高、更远？ 加餐九 | 作为面试官或候选人，如何面试或回答设计模式问题？ 加餐十 | 如何接手一坨烂业务代码？如何在烂业务代码中成长？ 结束语 | 聊一聊机遇、方向、能力、努力！ MVC和DDD 两者对比：业务开发常用的基于贫血模型的MVC架构违背OOP吗\nMVC MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。这种模式用于应用程序的分层开发。 https://www.runoob.com/design-pattern/mvc-pattern.html 基于贫血模型的传统的开发模式，是一种彻彻底底的面向过程的编程风格 DDD 领域驱动设计（Domain Driven Design，简称DDD） 基于充血模型的开发模式，面向对象编程风格 软件建模 软件建模介绍 将想法通过模型可视化地表达出来，方便记忆和进一步分析，方便团队/同事交流，口语交流容易失真。 软件建模体现了软件设计的思想，在需求和实现之间架起了一座桥梁，通过模型指导软件系统的具体实现。 模型并不是软件系统的一个完备表示，而是所研究系统的一种抽象。 如何进行软件建模 软件建模原则\n1、选择正确的模型，模型要与现实相联系 2、从不同的视角，使用不同的模型去表示一个系统 3、模型是抽象的，是选取系统某个最显著的特征并进行简化表示，因此需要通过不同的视角采用不同模型表示： **外部视角：**对系统上下文或环境进行建模 **交互视角：**对系统及其环境或者系统的构件之间的交互进行建模，建立用例模型 **结构化视角：**对系统的组织或者系统所处理的数据的结构进行建模，建立静态模型 **行为视角：**对系统的动态行为以及系统如何响应事件进行建模，建立动态模型 软件建模方法 在不同的领域和场景下有不同的软件建模方法，其各自的建模思想和采用的建模工具也不尽相同，如：\n结构化方法（Structured Method） 面向对象方法（Object Oriented Method） 基于构件方法（Component Based Method） 面向服务方法（Service Oriented Method） \u0026hellip; 面向对象软件建模方法 UML介绍 UML：Unified Modeling Language（统一建模语言），是面向对象的软件建模工具，使用UML进行建模的作用：\n可以更好的理解问题 可以及早的发现错误或者被遗漏的点 可以更加方便的进行组员之间的沟通 支持面向对象软件开发建模，可以更好的描述显示编程的情景。 对于复杂的系统来说，如果概要模型做的好，那么整个系统的模型也就很清晰明了。 UML一共有10种图，可分为四大类： 用例图 静态图：类图、对象图、包图 行为图：状态图、活动图、交互图，交互图分为序列图和协作图。 实现图：部署图、构件图 主要包括4种关系: 关联关系(association) 依赖关系(dependency) 泛化关系(generalization) 实现关系(realization) 4种视角 References UML实战教程 UML教程 UML2.5笔记 ＵＭＬ基础与建模实践教程 Tools 在线免费：draw.io UML常用图介绍 假设用UML建模以下场景：\n“机票订购系统是一个允许用户在线查询航班、购票、管理行程及退票的平台。系统区分了访客（未登录用户）与注册用户的功能权限：访客仅能浏览航班信息，而注册用户在登录后，还能进行购票、查看已购票以及退订操作。此外，系统内置了与外部信用评分系统的接口，该接口用于监控用户退票行为，若用户一个月内退票超过两次，其在信用评分系统中的等级会下调，信用等级过低时，系统将限制其继续购票。”\n用例图（Use Case Diagram）\n用例图是用来描述客户的需求，从用户的角度描述系统的功能，并指出系统的执行者，强调谁在使用系统，系统执行者完成了哪些功能。用例图包括角色、用例和关系。 类图（Class Diagram）\n用来展示系统中的类、类之间的关系（如继承、关联、聚合等）。适用于系统设计阶段，帮助开发人员理解系统的数据结构和类之间的关系。 顺序图（时序图，sequence diagram）\n描述对象之间如何通过消息交互以完成特定任务。适用于详细设计阶段，用于展示操作的时间顺序。 状态图（State Diagram）\n描述对象或系统在不同状态之间的转移和条件。适用于描述对象生命周期，特别是在系统的状态变化较为复杂时。 活动图（Activity Diagram）\n描述工作流、业务流程或操作的顺序。适用于系统行为建模、业务流程建模等。 构件图（组件图, Component Diagram）\n用来展示系统的物理组件及它们之间的依赖关系。适用于高层设计阶段，帮助理解系统的模块化结构。 部署图（Deployment Diagram）\n描述系统的硬件架构及其部署情况，显示硬件节点、节点之间的通信和软件组件部署到硬件节点的情况。适用于系统部署和运维阶段。 ","date":"2025-02-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/design_pattern/","title":"【软件设计】 设计模式介绍"},{"content":"ARM SIMD ARM平台基于ARM v7-A架构的ARM Cortex-A系列处理器(Cortex-A5, Cortex-A7,Cortex-A8, Cortex-A9, Cortex-A15)上的NEON加速：\n针对C/C++语言：循环展开等编译优化，-O2启用 针对NEON intrinsics：NEOM SIMD C/C++语言接口，针对架构启用V向量扩展，选择浮点处理器和ABI（application Binary Interface）接口类型 针对汇编语言：内联汇编，直接操作neon指令和寄存器 路线：了解相应编译优化=》使用intrinsic接口，学习对应汇编代码=》内联汇编，在编译器汇编代码基础上（否则可能反优化）学习并优化 references NEON Programmer\u0026rsquo;s Guide Cortex-A Series Programmer\u0026rsquo;s Guide 算子源码 AI算子：腾讯ncnn 数据处理算子：numpy simd 图像处理算子：Nvidia carotene，OpenCV third party 理论学习 指令流水线 经典的五级流水线模型 1、取指（IF）\n以程序计数器（PC）中的内容作为地址，从存储器中取出指令并放入指令寄存器（IR）； PC值加4（假设每条指令占4字节），指向顺序的下一条指令。 2、指令译码/读寄存器周期（ID）\n对指令进行译码，并用IR中的寄存器地址去访问通用寄存器组，读出所需的操作数； 对IR中的立即数进行扩展 3、执行/有效地址计算周期（EX）\nALU对上一个周期中准备好的操作数进行运算或处理。在这个阶段，不同类型的指令进行的操作不同。\n（1）load和store指令：ALB把指令中所指定的寄存器的内容与偏移量相加，形成访存有效地址； （2）寄存器-寄存器 ALU 指令：ALU按照操作码指定的操作对从通用寄存器组中读出的数据进行运算； （3）寄存器-立即数 ALU 指令：ALU按照操作码指定的操作对从通用寄存器组中读出的操作数和指令中给出的立即数进行运算； （4）分支指令：ALU把指令中给出的偏移量与PC值相加，形成转移目标的地址。同时，对在前一个周期读出的操作数进行判断，确定分支是否成功。 4、存储器访问/分支完成周期（MEM）\n（1）load和store指令：load指令根据上一个周期计算出的有效地址从存储器中读出的相应的数据；store把指定的数据写入这个有效地址对应的存储单元。 （2）分支指令：如果分支“成功”，就把前一个周期中计算好的转移目标地址送入PC。分支指令执行完成；否则，就不进行任何操作。 5、写回周期（WB）\n把结果写入通用寄存器组。对于ALU运算来说，这个结果来自ALU，而对于load指令来说，这个结果来自存储器。 SIMD加速原理 《计算机体系结构：量化研究方法》。Neon是ARM平台的SIMD（Single Instruction Multiple Data，单指令多数据流）指令集实现，书中4.1~4.3讨论了SIMD，推荐阅读。 之所以能加速的原因总结：\n（1）通过加长的寄存器减少数据的读取/写入次数，从而减少将数据读入寄存器的时间开销。例如Neon可以一次性将16个int8（16*8=128bit）数据读入专用寄存器，这一次读取时间开销，明显少于16个int8数据一个一个地读入的时间之和。写入同理。（注意不要和cache的减少访存时间的原理混淆。从cache读取余下的第2~第16个int8数据到寄存器仍然是要花费时钟周期的）。 （2）执行SISD（single instruction, Single data，单指令流单数据流，这里可理解为标量计算）指令时，需要完成（时间开销大的）冒险（hazard）检查。既然使用SIMD指令计算，就暗示这些数据之间无依赖性，也就从指令集层面回避了不必要的时间开销。 了解硬件决定的速度极限：Software Optimization Guide 我们可能还要关心，我们所编写的Neon Intrinsics，可以将手头上硬件的性能发挥到多少水平？是否还有提升空间？这些是好问题。\n在讨论一个问题前，先插入一个使笔者拍案叫绝的相关案例：在另一本计算经典《深入理解计算机系统》 （一般简称 CS:APP）的第5章 优化程序性能 中，该书作者考虑若干计算机硬件特性，将矩阵乘法连续优化了6个版本，直至优化到了该x86 CPU的吞吐量上限（注：对于某种指令，延迟latency 主要关注单条该指令的最小执行时间，吞吐量throughout主要关注单位时间内系统（一个CPU核）最多执行多少条该指令。因为AI计算的数据量比较大，我们更关注吞吐量） 回到问题，我们需要知道我们的吞吐量上界是多少。ARM官方为每个CPU架构（手机CPU一般大核是A7X架构，小核是A5X架构）提供对应的Software Optimization Guide，里面有进行各种运算的latency和throughout。以A76架构（采用该架构作为大核架构的CPU例如骁龙855，麒麟980）为例子，从ARM官网下载对应的pdf（https://developer.arm.com/documentation/swog307215/a/?lang=en） 翻到ASIMD（Advance SIMD）那里，就能查阅各条Neon指令相应的latency和throughout。不同架构的吞吐量上界会有所不同，其他架构请自行在ARM官网文档中心下载。 理论数据有了，至于如何通过实验测试峰值，可参考BBuf的文章 如何判断算法是否有可优化空间？ （https://zhuanlan.zhihu.com/p/268925243）\n反汇编分析生成代码质量 可通过反汇编的方式查看Intrinsics 生成的汇编是否满足预期，如果不满足预期则进行手写汇编优化。具体操作可参考梁德澎的文章 移动端arm cpu优化学习笔记第4弹\u0026ndash;内联汇编入门（https://zhuanlan.zhihu.com/p/143328317）\nmaterials （1）研讨会视频 \u0026ldquo;Performance Analysis for Optimizing Embedded Deep Learning Inference Software,\u0026rdquo; a Presentation from Arm - Edge AI and Vision Alliance，建立优化分析思维 （2）研讨会视频 LCU14-504: Taming ARMv8 NEON: from theory to benchmark results （3）研讨会视频 HKG15-408: ARM v8-A NEON optimization （4）Ne10（ARM官方的计算库）：https://github.com/projectNe10/Ne10 （5）Arm Optimized Routines（ARM官方的计算、网络、字符串库）：https://github.com/ARM-software/optimized-routines （6）Neon优化Chromium的案例：https://developer.arm.com/documentation/101964/developer.arm.com NEON 介绍 ARM NEON 是 ARM 架构的一种 SIMD（Single Instruction, Multiple Data）扩展，旨在加速多媒体、数字信号处理（DSP）、图像处理、音视频编解码、加密算法等高并发计算任务。NEON 是 ARMv7 （ARMv7-A只支持单精度，32x64-bit寄存器；Armv8-A AArch64支持双精度，32x128-bit寄存器，针对浮点操作的Vector Floating Point，VFP）及之后版本的处理器的标准扩展，广泛用于智能手机、嵌入式设备、平板电脑以及其他移动设备中，尤其是处理需要并行化的计算密集型应用时，它能显著提高性能。\n重要概念 lane：如一个float32x4_t类型的变量float32x4_t v = {1.0f, 2.0f, 3.0f, 4.0f}，它占用 128 位，存储 4 个 32 位的浮点数，在这个向量寄存器 v 中，每个值依次存储在不同的lane序号为0、1、2、3中。 NEON 寄存器 定义：NEON 使用专门的寄存器来存储向量数据，这些寄存器通常用于处理多个数据元素，ARMv7-A只支持单精度，32x64-bit寄存器；Armv8-A AArch64支持双精度，32x128-bit寄存器。 作用：NEON 寄存器组包含了 128 （Q字母）或 64（D字母） 位宽的寄存器，可以存储多个 8 位、16 位、32 位、64 位整数或浮点数据。 例子： Q0-Q15：128 位宽的 NEON 寄存器，用于存储 8 位、16 位、32 位、64 位的数据（整数或浮点数）。 D0-D15：64 位宽的 NEON 寄存器，也用于存储 64 位数据。 向量和标量操作 定义：NEON 支持对向量（多个元素）和标量（单个元素）进行操作。 作用：标量操作是普通的逐元素操作，而向量操作则允许一次性处理多个数据元素。 例子： vadd.f32：向量浮点加法操作。 vadd.i32：向量整数加法操作。 NEON 数据类型 定义：NEON 支持多种数据类型，包括整数、浮点数、双精度浮点数和混合类型数据。 作用：不同的数据类型适应不同的应用需求，如 8 位整数、32 位浮点数等。 例子： i8, i16, i32, i64：不同宽度的整数类型。 f32, f64：浮点数类型，支持单精度和双精度浮点数。 NEON 指令集 定义：NEON 提供了一组专门的指令来处理数据并执行并行计算。NEON 指令包括加法、乘法、减法、移位、汇聚（归约）、比较、选择、数据类型转换等。 作用：这些指令能够加速处理向量数据，尤其是应用于图像处理、音频处理、视频编解码、加密算法等领域。 例子： vadd：向量加法指令。 vmul：向量乘法指令。 vsub：向量减法指令。 vmax：向量最大值选择指令。 扩展数据类型 定义：NEON 提供了扩展数据类型的支持，如高/低16位扩展、饱和算术、向量数据类型转换等。 作用：这种扩展数据类型用于在计算过程中执行高效的数据操作和转换，避免数据溢出或精度丢失。 例子： vshl：向左移位操作。 vqadd：饱和加法指令，防止数据溢出。 数据载入和存储指令 定义：NEON 提供了一些专门的加载（load）和存储（store）指令，用于从内存中加载数据到寄存器，或将寄存器中的数据存储回内存。 作用：这些指令能够优化内存访问，支持从多个内存地址加载和存储数据。 例子： vld1：加载向量数据指令。 vst1：存储向量数据指令。 数据汇聚和归约操作 定义：NEON 提供了对向量数据的汇聚（归约）操作，例如求和、最大值、最小值等。 作用：这些操作通常用于计算总和、平均值、最大值等统计量，广泛应用于信号处理和数据分析中。 例子： vaddv：对向量元素进行加法归约，返回所有元素的和。 vmaxv：对向量元素进行最大值归约，返回最大值。 条件执行 定义：NEON 支持条件执行，通过设置条件码（flags），可以对某些指令的执行进行条件限制。 作用：可以根据特定的条件执行指令，避免不必要的计算，提高性能。 例子： vsel：根据掩码（mask）选择性地执行指令。 SIMD 聚合指令（广播操作） 定义：NEON 支持广播操作，允许单一标量值扩展到整个向量中。广播操作使得标量与向量的数据处理更加简便。 作用：通过广播操作，标量可以与向量中的每个元素进行计算，提高了指令的灵活性。 例子： vdup：将一个标量值复制到整个向量中。 NEON 浮点数运算 定义：NEON 支持单精度浮点数和双精度浮点数的运算，符合 IEEE 754 标准。 作用：这些浮点数运算指令可用于科学计算、图像处理等应用。 例子： vadd.f32：单精度浮点数向量加法。 vmul.f32：单精度浮点数向量乘法。 数据类型转换 定义：NEON 支持多种类型之间的转换操作，如浮点与整数类型之间的转换。 作用：这种转换对于不同数据类型之间的运算非常重要，可以确保类型匹配并避免数据丢失。 例子： vcvt.f32.s32：将 32 位整数转换为 32 位单精度浮点数。 vcvt.s32.f32：将 32 位单精度浮点数转换为 32 位整数。 向量掩码 定义：NEON 支持通过掩码控制哪些向量元素应该被操作。掩码机制允许在处理多个数据时根据特定条件选择性地操作某些元素。 作用：掩码可以控制并行操作的粒度，提高计算的灵活性。 例子： vmla：向量乘加指令，根据掩码控制哪些元素参与计算。 NEON Intrinsic 兼容armv7和v8（部分指令可能不兼容），所以不同架构之间迁移方便，不需要改代码\nReferences NEON-Intrinsics Neon Programmer Guide for Armv8-A Coding for Neon intrinsics检索，用来查看接口和支持架构 ARM Neon Intrinsics 学习指北：从入门、进阶到学个通透 numpy simd 数据和计算指令类型的格式 1、向量数据类型格式：\u0026lt;type\u0026gt;\u0026lt;size\u0026gt;x\u0026lt;number of lanes\u0026gt;_t\n比如float32x4_t，=float,=32,=4 向量数据类型： 2、向量数组类型：\u0026lt;type\u0026gt;\u0026lt;size\u0026gt;x\u0026lt;number of lanes\u0026gt;x\u0026lt;length of array\u0026gt;_t\n比如 1 2 3 4 struct int16x4x2_t { int16x4_t val[2]; }; 向量指令格式：\u0026lt;opname\u0026gt;\u0026lt;flags\u0026gt;_\u0026lt;type\u0026gt;\n比如vmulq_f32，=vmul，=q,=f32 Note 普通计算逻辑考虑优化编译器优化、类型量化等 循环一般用do-while的形式 对于非整数倍元素个数的解决方法： leftovers 使用 NEON 的广播操作，避免显示复制数据 使用 NEON 的饱和操作，避免数据溢出 利用数据类型转换操作，并合理进行量化 利用shift、insert、mask等 计算机组成结构运行相关（通用） 并行\n充分利用计算机流水线：去除数据依赖 逻辑操作代替分支选择（分支预测） 数据预加载（预取/并行） 资源利用\n充分利用寄存器资源，分块处理数据，但避免寄存器溢出(Register Spilling）（测试时开启O2优化使编译器允许寄存器存储临时变量） 内存合理对齐分配，按对应寄存器长度读取 多线程处理，如OpenMP（并行/数据共享） 利用数据连续特性、利用cache NEON 汇编 可用__aarch64__宏区分是armv8，否则armv7，针对性编写代码\nReferences 移动端arm cpu优化学习笔记第4弹\u0026ndash;内联汇编入门 arm 内联汇编使用 arm内联汇编的一般格式，detail、docs\n1 2 3 4 5 6 7 8 __asm__ qualifiers ( // 汇编代码部分 : OutputOperands //在内联汇编代码中被修改的变量列表 : InputOperands //在内联汇编代码中用到的变量列表 : Clobbers //在内联汇编代码中用到的寄存器列表 ); Note 先写intrinsic代码反汇编，学习编译器优化后的汇编代码，再优化 重点关注指令流水线排布，避免CPU的Hazard ","date":"2025-02-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/arm-neon/","title":"【SIMD】 ARM SIMD指令集NEON等介绍"},{"content":"References The RISC-V Instruction Set Manual Volume II: Privileged Architecture RVV spec Xuantie+900+Series+RVV-0.7.1+Intrinsic+Manual 算子源码 ARM-software/CMSIS, CMSIS-DSP Nuclei-software/NMSIS Note illegal instruction：修改CSR的mstatus标志位 important concepts VLEN (Vector Length) 定义：向量寄存器的长度，表示每个寄存器可以存储的最大元素数量，通常是硬件设定的，例如 128 位、256 位或 512 位。 作用：决定向量寄存器的容量和能处理的数据量。 例子： 如果 VLEN 为 256 位且每个元素为 32 位整数，则每个寄存器最多存储 8 个元素（256 / 32 = 8）。 SLEN (Stride Length) 定义：元素在内存中的步长，即两个连续元素之间的内存偏移量。 作用：影响内存访问模式，特别是在访问非连续内存时，SLEN 决定了元素之间的间隔。 例子： 假设一个向量寄存器存储 4 个元素，每个元素大小为 32 位，而 SLEN 设置为 2，这意味着每个向量元素在内存中的位置间隔为 2 个 32 位单元。 ELEN (Element Length) 定义：每个向量元素的大小（单位：比特），决定了每个元素占用多少内存。 作用：影响向量中每个元素的数据类型大小，在指令中用e表示，如e32。 例子： 如果 ELEN 设置为 32 位，则每个向量元素为 32 位宽，可以是一个 32 位整数或 32 位浮点数。 如果 ELEN 为 64 位，则每个元素占 64 位，适用于较大数据类型（如 64 位整数或浮点数）。 LMUL (Vector Register Grouping Factor) 定义：向量寄存器的分组因子，控制每个向量寄存器内元素的数量，决定寄存器的并行度。 作用：LMUL 会影响每个向量寄存器中包含的元素数量，从而影响并行性，在指令中用m表示，如m1。 例子： LMUL = 1：每个寄存器存储最大数量的元素（假设 VLEN = 256 位，ELEN = 32 位，则每个寄存器存储 8 个元素）。 LMUL = 2：每个寄存器只存储 4 个元素，寄存器总数增加，适合提高并行度。 LMUL = 4：每个寄存器只存储 2 个元素。 VL (Vector Length Register) 定义：VL 是一个寄存器，用来控制当前向量指令的长度，即当前指令能处理的元素数量。 作用：在 RVV 指令中，VL 决定了向量运算的迭代次数，向量操作将执行 VL 次。 例子： 如果 VL = 4，那么该指令将对前 4 个向量元素执行操作，用setvl(max)指令可以得到指令类型的最大元素数量，其中每个指令指定vl可处理不同数量的元素。 VTYPE (Vector Type Register) 定义：VTYPE 控制向量操作的类型，如元素长度 (ELEN) 和 LMUL 的配置。 作用：配置向量操作的具体参数，帮助硬件理解如何处理向量指令。 例子： VTYPE 设置为 ELEN = 32 位，LMUL = 1，表示每个向量寄存器存储 32 位元素，且每个寄存器的并行度为 1。 Vector Mask (vmsk) 定义：向量掩码用于控制哪些向量元素应该被操作，哪些应该被忽略。 作用：掩码机制使得程序能够选择性地执行向量操作。 例子： 若 vmsk = 11110000（二进制），则只有前 4 个向量元素会被操作，后 4 个元素将被忽略。 Vector Registers (v0 - vn) 定义：向量寄存器用于存储向量数据，RISC-V 定义了 v0 到 v31 的向量寄存器。 作用：这些寄存器用于存储和处理向量数据，数量和大小可由硬件决定。 例子： v0 和 v1 可以分别存储 256 位的向量数据，适用于不同长度的数据类型。 Vector Load/Store Instructions 定义：向量加载和存储指令，用于将数据从内存加载到向量寄存器，或将向量寄存器中的数据存储回内存。 作用：支持各种内存访问模式，如连续或非连续访问。 例子： vlb：加载字节数据到向量寄存器。 vsb：将字节数据存储回内存。 Vector Arithmetic Instructions 定义：向量算术指令用于执行向量加法、减法、乘法、除法等算术运算。 作用：向量算术指令在多核处理器中并行执行运算。 例子： vadd：向量加法，执行两个向量的逐元素加法。 vmul：向量乘法，执行两个向量的逐元素乘法。 Vector Compare Instructions 定义：向量比较指令用于比较向量中的元素，返回布尔掩码结果。 作用：常用于条件判断和控制流。 例子： vseq：判断两个向量的元素是否相等，结果返回掩码。 vsgt：判断向量元素是否大于另一个向量，返回布尔掩码。 Vector Reduction Instructions 定义：向量归约指令用于将向量中的多个元素归约为一个单一结果，如求和、求最大值等。 作用：常用于矩阵运算、图像处理等应用。 例子： vredsum：求和，将向量中所有元素相加。 vredmax：求最大值，返回向量中的最大元素。 Vector Scatter/Gather Instructions 定义：用于从非连续的内存地址中加载数据或将数据存储到非连续的内存地址。 作用：提高对非连续内存的访问效率。 例子： vscatter：将向量元素存储到不连续的内存位置。 vgather：从不连续的内存位置加载数据到向量寄存器。 Vector-Scalar Operations 定义：向量与标量之间的操作，允许标量与每个向量元素进行逐一运算。 作用：通过标量与向量元素的结合，处理常数数据。 例子： vaddvi：将一个标量与向量中的每个元素相加。 vmulvi：将一个标量与向量中的每个元素相乘。 Vector Predication 定义：根据掩码或布尔条件选择性执行向量操作。 作用：通过掩码决定哪些元素进行计算，哪些跳过。 例子： vmand：与掩码进行与运算，满足条件的元素进行计算。 Vector Tail \u0026amp; Masking 定义：当 VL 不能完全填充向量寄存器时，通过尾部掩码控制哪些元素需要操作。 作用：避免浪费计算资源，确保运算的有效性。 例子： 如果 VL = 5，而寄存器有 8 个元素，掩码将控制只操作前 5 个元素。 Vector Unit (VU) 定义：向量单元是硬件中的计算单元，负责执行向量指令。 作用：处理向量计算，提高处理器的并行度。 例子： 在支持 RVV 的处理器中，向量单元可以同时处理多个向量运算。 Note 常见使用方式 以float32类型dot计算为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 void riscv_dot_prod_f32( const float32_t * pSrcA, const float32_t * pSrcB, uint32_t blockSize, float32_t * result) { float32_t sum = 0.0f; size_t blkCnt = blockSize; size_t l; vfloat32m8_t v_A, v_B; vfloat32m8_t vsum; l = __riscv_vsetvlmax_e32m8(); vsum = __riscv_vfmv_v_f_f32m8(0.0f, l); for (; (l = __riscv_vsetvl_e32m8(blkCnt)) \u0026gt; 0; blkCnt -= l) { v_A = __riscv_vle32_v_f32m8(pSrcA, l); pSrcA += l; v_B = __riscv_vle32_v_f32m8(pSrcB, l); pSrcB += l; vsum = __riscv_vfmacc_vv_f32m8(vsum, v_A, v_B, l); } l = __riscv_vsetvl_e32m8(1); vfloat32m1_t temp00 = __riscv_vfmv_v_f_f32m1(0.0f, l); l = __riscv_vsetvlmax_e32m8(); temp00 = __riscv_vfredusum_vs_f32m8_f32m1(vsum, temp00, l); sum = __riscv_vfmv_f_s_f32m1_f32(temp00); *result = sum; } ","date":"2025-02-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/rvv/","title":"【SIMD】 Risc-v SIMD指令集RVV介绍"},{"content":"环境准备 1.1 Git下载 前往【Git官网】，下载安装程序 一直点下一步，默认安装即可\nHugo下载 前往【Hugo Github Tags】，选择对应版本下载，下载后解压即可 Windows下载版本：hugo_extended_xxxxx_windows_amd64.zip\n搭建博客 创建博客 （1）在hugo.exe所在文件夹的地址栏敲打cmd，然后Enter唤起命令行\n（2）敲打命令hugo new site xxxx创建hugo文件\n（3）敲打命名cd xxxx切换目录，并把hugo.exe复制到刚生成的文件夹中\n（4）敲打命令hugo server -D启动服务，访问http://localhost:1313，Ctrl+C停止服务 （hugo默认是没有主题的，需要进行主题配置）\n配置主题 （1）前往【Hugo Themes】，查找自己喜欢的主题，进行下载\n（2）这边以【Stack主题】为例，将下载好的主题解压，放到/themes文件夹中\n（3）将exampleSite样例数据中的 Content 和 hugo.yaml 复制到主文件夹中，并删掉hugo.toml和content/post/rich-content\n（4）修改 hugo.yaml 中的 theme，将他修改为跟主题文件夹同名\n（5）再次启动hugo服务，查看主题，具体主题配置修改 hugo.yaml，这里不细说，感兴趣可自行查找相关文章\n启用 Giscus 评论 Giscus 是利用 GitHub Discussions 实现的评论系统，开源、无跟踪、无广告、永久免费。\nHugo 对 Giscus 有很好的支持，在 hugo-theme-jane 主题中配置启用Giscus 很简单。\n要启用 Giscus 请先确保：\n仓库是公开的，否则访客将无法查看 discussions。 giscus app 已安装，否则访客将无法评论和回应。 Discussions 功能已在你的仓库中启用。 前面搭建的博客仓库就是公开的，满足了第一点，接下来要做的就是安装 Giscus app 和启用 Discussions。\nReferences https://www.codeaer.com/post/enable-giscus-comments-in-hugo/ 配置 Giscus 根据版本有所不同，0.143.1版本可使用以下模板\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # repoId、categoryId参考网址修改：https://giscus.app/zh-CN giscus: repo: \u0026#34;xxx/xxx.github.io\u0026#34; repoId: \u0026#34;xxx\u0026#34; category: \u0026#34;General\u0026#34; categoryId: \u0026#34;xxx\u0026#34; mapping: \u0026#34;pathname\u0026#34; # comment value is the default value strict: 0 reactionsEnabled: 1 # emitMetadata: 0 inputPosition: \u0026#34;top\u0026#34; theme: \u0026#34;dark\u0026#34; lang: \u0026#34;zh-CN\u0026#34; lazyLoading: true crossorigin: \u0026#34;anonymous\u0026#34; Github部署 常规部署 （1）前往【Github官网】，创建仓库 {github用户名}.github.io\n（2）前往Setting -\u0026gt; Pages -\u0026gt; Branch选择main分支，然后保存，会自动开启 https://{github用户名}.github.io 的地址，这地址也是以后访问博客的地址\n（3）回到hugo文件中，执行命令hugo -D，会生成 public 静态资源文件夹\n（4）在 public 执行以下命令上传到github仓库上，第一次上传可能需要输入账号密码\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main （5）上传成功后访问 https://{github用户名}.github.io，成功搭建属于自己的Hugo博客\nGithub Action自动部署 （1）Github创建一个新的仓库，用于存放Hugo的主文件\n（2）前往Setttings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens，创建一个token(classic)\n（3）token选择永不过期，并勾选 repo 和 workflow 选项\n（4）为保证安全，将生成的token，保存的仓库的变量中，前往Settings -\u0026gt; Secrets and variables -\u0026gt; Actions中设置\n（5）在hugo主文件创建一个.github/workflows/xxxx.yaml文件，将以下内容复制进去，想具体了解更多，可查看【Github Action文档】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: deploy # 代码提交到main分支时触发github action on: push: branches: - main jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;latest\u0026#34; extended: true - name: Build Web run: hugo -D - name: Deploy Web uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.你的token变量名 }} EXTERNAL_REPOSITORY: 你的github名/你的仓库名 PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy （6）在hugo主文件创建.gitignore文件，来避免提交不必要的文件\n1 2 3 4 5 6 7 # 自动生成的文件 public resources .hugo_build.lock # hugo命令 hugo.exe （7）将hugo的主文件上传到仓库，上传成功后会触发Github Action，来自动部署你的静态页面\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main Reference https://letere-gzj.github.io/hugo-stack/p/hugo/custom-blog/ ","date":"2025-02-05T00:00:00Z","permalink":"https://loveleaves.github.io/p/hugo-blog/","title":"Hugo + Github 免费部署自己的博客"},{"content":"References C进阶：https://www.bookstack.cn/read/whyilearnc/README.md 中科大超算中心资料手册：https://scc.ustc.edu.cn/zlsc/ https://www.zhihu.com/question/33576416 https://heptagonhust.github.io/HPC-roadmap/ HPC指南：https://github.com/l0ngc/hpc-learning 高等数值分析（高性能计算，并行计算）：https://math.ecnu.edu.cn/~jypan/Teaching/ParaComp/ https://developer.nvidia.com/hpc-sdk-downloads 概念 并行计算三要素\n硬件：并行计算机/体系结构 算法：并行算法设计/应用问题的并行度 软件：并行编程环境/Linux/Fortran/C/C++/MPI/OpenMP 代码优化 分支预测：https://blog.csdn.net/yaojingqingcheng/article/details/120913601 simd优化： 简单例子：https://blog.csdn.net/csdn546229768/article/details/128728780 https://blog.csdn.net/yaojingqingcheng/article/details/121616954 数据结构布局优化：https://blog.csdn.net/yaojingqingcheng/article/details/122418208 循环优化技术：输入值嵌入、分支消除、减少子过程调用次数、循环合并、子过程合并、改变循环变量的迭代顺序、改变数组维数、循环展开、循环分块（提高cache命中率，利用cache line） video 利用局部性原理 CPU寄存器、内存、外存：优化缓存，如用restrict关键字说明指针间地址不存在关联。 并行编程 概念 指令并行：CPU流水线 分布式并行：MPI 共享存储式并行：OpenMP、OpenCL、OpenACC SIMD（Single Instruction Multi-Data） SIMD是CPU实现DLP（Data Level Parallelism）的关键 x86架构 SSE指令集（Streaming SIMD Extensions系列），使用XMM寄存器 AVX指令集（Advanced Vector Extensions系列），使用YMM寄存器，相比SSE扩充浮点 arm架构 neon v7/v8 riscv架构 riscv-v 优点：更高速的计算方法 缺点：更高的开发复杂度，专用的CPU组件 SIMT（Single Instruction Multi-Threads） CUDA/ROCM CUDA：NIDIA ROCM：AMD OpenMP（Open Multi-Processing） openMP介绍 高性能计算入门：OpenMP并行编程技术（一）:https://www.bilibili.com/video/BV1ss4y1K7q1?p=1 OpenMP编程三要素： 编译指导（Compiler Directive）：包含并行域指令、工作共享指令、同步指令、数据环境 运行库函数（Runtime Library Routines） 环境变量（Environment Variables） OpenMP模式：fork-join，是针对CPU的并行编程模型，基于线程 硬件内存模型： CPU在主存上有L1、L2、L3多级缓存 L3为多核共有，但L1和L2为每个核心私有，所以存在缓存一致性问题（False Sharing） OpenCL（Open Computing Language） 跨平台 基于C/C++语言 OpenACC 针对GPU，OpenMP模型在GPU上的扩展，支持AMD GPU openACC介绍 MPI MPI，Message Passing Interface，消息传递接口，主要用于进程间的消息传递（或数据传递） MPI介绍 性能分析 程序流程分析 静态分析：即对代码进行数据对象、函数接口封装和调用分析，工具understand 动态分析：即程序实际调用过程中分析执行的函数及流程，工具gprof ","date":"2025-01-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/hpc/","title":"【HPC】高性能计算总结"},{"content":"References C++ Core Guidelines 核心 C++ 语言构造的参考手册 现代 C++ 大典 cs106b C++知识总结 C++ 语言参考 优秀开源 github cpp trending Abseil Abseil 是一个由 Google 开源的 C++/python 库，提供了一组常用的工具和基础设施，用于补充 C++ 标准库中缺失的功能或提高效率。 C++17的string_view前身就是来自absl::string_view abseil-cpp Dlib Dlib 是一个流行的 C++ 库，主要用于机器学习、计算机视觉和图像处理。它提供了丰富的机器学习功能，支持多种算法和优化方法。 dlib XGBoost XGBoost 是一个高效的机器学习库，特别适用于梯度提升决策树（GBDT）算法，广泛用于回归、分类和排序任务。 xgboost Google\u0026rsquo;s glog (Google Logging Library) 功能：glog 是一个 C++ 日志库，提供了强大的日志记录功能，包括日志级别（DEBUG、INFO、WARNING、ERROR 和 FATAL）、日志输出到文件、以及日志格式化。 特点：简单易用，支持日志级别设置、日志输出的细粒度控制，还可以在生产环境中非常高效地记录日志。 链接：glog GitHub spdlog 功能：spdlog 是一个非常快速的 C++ 日志库，旨在提供低延迟、高性能的日志记录功能。 特点：spdlog 提供线程安全的日志记录支持，能够输出到控制台或文件，支持日志级别、日志格式等功能。 链接：spdlog GitHub folly (Facebook Open-source Library) 功能：folly 是 Facebook 开发的一个 C++ 库，包含了许多高性能的组件和工具，适用于大规模系统的开发。它包括内存管理、并发、容器、算法、IO等多个方面的扩展。 特点：folly 提供了大量与系统底层交互的工具，具有很高的性能，适用于对性能要求极高的应用。 链接：folly GitHub Boost 功能：Boost 是一个广泛使用的 C++ 库集合，提供了许多扩展标准库的功能，包括智能指针、正则表达式、线程、文件系统、算法等。 特点：Boost 提供了丰富的功能，经过多年的开发和优化，成为了 C++ 生态中非常重要的工具库之一。很多 C++ 标准库中的特性都源自 Boost（如 std::shared_ptr 和 std::filesystem）。 c++17中的std::filesystem、std::any、std::varient等直接来自于boost中。boost::program_options用于处理控制台的输入参数也是很方便 链接：Boost官网 fmt 功能：fmt 是一个现代化的、快速的格式化库，提供了类似 Python 中的 f-string 或 C# 中的 string interpolation 的功能。 特点：它允许开发者使用更加简洁和类型安全的方式进行字符串格式化。fmt 库的速度非常快，而且 API 设计符合现代 C++ 风格。 链接：fmt GitHub gflags 功能：gflags 是一个 Google 提供的命令行参数解析库，广泛用于解析应用程序启动时的命令行选项。 特点：gflags 提供了易于使用的命令行选项定义和管理功能，支持复杂的命令行解析需求，例如布尔值选项、枚举类型选项等。 链接：gflags GitHub tbb (Threading Building Blocks) 功能：tbb 是 Intel 提供的一个 C++ 并行编程库，旨在帮助开发者利用多核处理器，简化并行编程。 特点：提供了线程池、并行算法和数据结构，能够方便地进行并行化计算，且通过自动负载平衡使多核资源得到高效利用。 链接：TBB GitHub cppcoro 功能：cppcoro 是一个支持 C++20 协程的 C++ 库，提供了多种并发控制结构，如 task 和 awaiter，用于协程的高效实现。 特点：使 C++ 开发者能够高效地编写异步代码，同时保持代码简洁和易于理解。适合需要异步操作的场景。 链接：cppcoro GitHub Eigen 功能：Eigen 是一个高效的 C++ 数学库，专门用于矩阵运算、线性代数和数值计算。 特点：Eigen 提供了一个高性能的模板库，支持多维数组、矩阵操作以及高级的线性代数功能，广泛用于科学计算、机器学习等领域。 链接：Eigen GitHub C++语言参考 类和结构（class and struct） 类成员 override：重写父类虚函数 final：表示一个虚函数不能被进一步重写，或者表示一个类不能被继承 delete：禁用某个函数，如默认构造 default：明确地请求编译器为类生成默认实现 explicit：防止隐式转换调用其他函数 纯虚函数：virtual void doStep() = 0; // 要求派生类必须实现，否则派生类也将变成抽象类，无法实例化。 常成员函数const：只能调用其他常成员函数，不能修改成员变量（除mutable） static静态成员函数：不用实例化，可被直接调用 inline：内联请求，将代码插入调用函数处，较少调用栈开销 noexcept：表示该函数不会抛出异常 mutable：修饰变量可在常成员函数中修改 constexpr：表示该函数在编译时计算结果 friend：友元函数/类，允许外部函数或类在需要时访问类的私有实现 operator ：用于定义或重载类的运算符 自定义迭代器类：通常需重载==、!=、++、*解引用，实现begin、end 三/五/零之法则(rule of three) 因为C++类的特殊成员特性在实际应用可能产生用户非预期的效果，所以总结为法则用以规避可能出现的潜在风险 cpp references 资源获取即初始化(Resource Acquisition Is Initialization, RAAI) 与托管语言不同，C++ 没有自动回收垃圾机制，易导致内存泄露 C++ 将资源的生命周期与对象的生命周期所绑定（构造获取资源/析构释放资源，利用了栈上的变量在离开作用域的时候会析构的特性） c++11后的四大smart_point(shared_ptr、unique_ptr、weak_ptr、auto_ptr(在17中废除))采用了这种思想 善于利用析构特性进行自动内存回收管理，如std::lock_guard、Std::make_unique、Std::make_share等 运行时类型识别(Run Time Type Identification，RTTI) c++中RTTI的一些体现typeid、dynamic_cast、type traits 具体可以看runtime的库的函数__RTtypeid，rtti把所需的type_info(不同编译器会有所不同)信息放在vtable前，大概也是dynamic_cast要求父类必须有虚函数的原因吧 注意，取虚函数表地址时 （此处请注意环境在32位和64位下的区别，在32/64位下取对象a(带有虚函数的基类的实例)的首地址(虚函数表地址)有区分，即(int )\u0026amp;a 和 (long )\u0026amp;a的不同，为避免也可直接，（int）(int)(\u0026amp;classname)替换成（intptr_t）(intptr_t)(\u0026amp;classname)）** 用于编译时封装的 Pimpl Pimpl（Pointer to Implementation）是一种设计模式，常用于C++编程中以隐藏类的实现细节。Pimpl模式通过将实现细节移到一个私有的实现类中，从而提高代码的可维护性、降低编译时间以及实现二进制兼容性。\n编译依赖项的最小化。 接口和实现的分离。 可移植性。 一般实现： 1 2 3 4 5 6 7 // 头文件定义private类指针，源文件进行实现类impl // my_class.h class my_class { // ... all public and protected stuff goes here ... private: class impl; unique_ptr\u0026lt;impl\u0026gt; pimpl; // opaque type here }; 匿名函数 lambda表达式 引用 reference 指针 异常 模板 template 变长参数模板： 1 2 3 4 5 template \u0026lt;typename... Modules\u0026gt; explicit Sequential(Modules \u0026amp;\u0026amp;...modules) { modules_.reserve(sizeof...(Modules)); pushBack(std::forward\u0026lt;Modules\u0026gt;(modules)...); } // 递归展开，调用基础pushBack方法 完美转发：std::forward，保留原来值类型（左值/右值） std::optional：处理可能为null等值情况 std::enable_shared_from_this：在对象的成员函数中获取指向自身的智能指针，增加对象的引用计数，确保对象在异步操作或回调过程中不会被销毁 STL（Standard Template Library，标准模板库） 容器（Containers） vector.reserve 和 resize Vecotr.emplace_back和push_back std::reference_wrapper存储引用 std::initializer_list 轻量级初始化列表，不可修改; 算法（Algorithms） 迭代器（Iterators） 函数对象（Function Objects） C++ 14新特性 cppreference C++ 17新特性 cppreference C++17完全指南 并行算法库 不同编译器对并行算法库的支持: https://en.cppreference.com/w/cpp/compiler_support/17#C.2B.2B17_library_features 支持的算法 依赖tbb 使用示例 1 2 3 4 5 6 7 8 #include \u0026lt;algorithm\u0026gt; #include \u0026lt;execution\u0026gt; // std::sort(begin, end, comp); // origin std::sort(exe_policy, begin, end, comp); // 执行策略(execution policy)可选： // 1、std::execution::seq（顺序执行） // 2、std::execution::par（并行执行） // 3、std::execution::par_unseq（并行和向量化执行） C++ 20新特性 cppreference 其他 宏定义 #、#@、##、VA_ARGS 应用 1 2 3 4 5 6 7 8 9 10 #define Conn(x,y) x##y // 表示x连接y #define ToChar(x) #@x // 给x加上单引号 #define ToString(x) #x // 给x加上双引号 char* str = ToString(123132); // str=\u0026#34;123132\u0026#34;; int n = Conn(123,456); //n=123456; char* str = Conn(\u0026#34;asdf\u0026#34;, \u0026#34;add\u0026#34;) //str = \u0026#34;asdfadf\u0026#34;; char a = ToChar(1); // a=\u0026#39;1\u0026#39;; // char a = ToChar(123); // 编译器报错 #define debug(...) printf(__VA_ARGS__) // 用于宏定义中代表可变参数 运行时类型反射(Run Time Type Reflection, RTTR) 反射是一个进程检查、反省和修改其自身结构和行为的能力 众所周知，java、c#、Go等语言在语言层面支持了反射特性。而c++不支持反射，因为C++没有在语言层面提供返回类的metadata的能力，所以很多属性要靠手动注册，于是乎有人自造轮子搞了个反射机制（UE中的U++通过UHT和UBT来支持反射） ","date":"2025-01-09T00:00:00Z","permalink":"https://loveleaves.github.io/p/c_plus_plus/","title":"【编程语言】 C++高级特性及实战"},{"content":"References mpi tutorial, github OMP、MPI培训文档 并行程序设计导论 介绍 MPI，Message Passing Interface，消息传递接口，主要用于进程间的消息传递（或数据传递） 是一种库描述，不是语言 是一种标准或规范，不是具体的实现（如Intel MPI，OpenMPI等） 是一种消息传递编程模型，并成为这种编程模型的代表和事实上的标准。 并行效率不降反增（加速比下降）：负载不均衡、并行粒度的选择 MPI四类通讯模式 逻辑进程排列：MPI虚拟进程拓扑 ","date":"2025-01-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/mpi/","title":"【HPC】 MPI介绍"},{"content":"References openACC resources OpenACC 笔记 OpenACC Programming and Best Practices Guide openacc-training-materials 介绍 Open Accelerators，OpenACC 编译器：PGI，nvc或nvc++，linux下PGI编译器安装 针对GPU，OpenMP模型在GPU上的扩展，支持AMD GPU 入门例程 示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // 代码 1：test.cpp，使用命令编译：nvc++ -o test -gpu=mem:managed test.cpp #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;openacc.h\u0026gt; // Function to initialize the vectors with values void initialize(std::vector\u0026lt;double\u0026gt;\u0026amp; a, std::vector\u0026lt;double\u0026gt;\u0026amp; b, int n) { for(int i = 0; i \u0026lt; n; ++i) { a[i] = static_cast\u0026lt;double\u0026gt;(i); b[i] = static_cast\u0026lt;double\u0026gt;(2 * i); } } // detect if GPU is actually running void detect_gpu() { double a[100], b[100]; #pragma acc parallel loop for (int i = 0; i \u0026lt; 100; ++i) { if (i == 10) { if (acc_on_device(acc_device_not_host)) printf(\u0026#34;Executing on GPU.\\n\u0026#34;); else printf(\u0026#34;Not executing on GPU.\\n\u0026#34;); } a[i] += b[i]; } } int main() { const int n = 1000000; // Size of the vectors std::vector\u0026lt;double\u0026gt; a(n), b(n), c(n); double *pa = a.data(), *pb = b.data(), *pc = c.data(); // Initialize vectors a and b initialize(a, b, n); detect_gpu(); // Using OpenACC to offload the following computation to an accelerator // and explicitly handle data movement #pragma acc data copyin(pa[0:n], pb[0:n]) copyout(pc[0:n]) { #pragma acc parallel loop for(int i = 0; i \u0026lt; n; ++i) pc[i] = pa[i] + pb[i]; } // Display the first 10 results for(int i = 0; i \u0026lt; 10; ++i) { std::cout \u0026lt;\u0026lt; \u0026#34;c[\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;] = \u0026#34; \u0026lt;\u0026lt; c[i] \u0026lt;\u0026lt; std::endl; } } 编译器选项 -ta=tesla: Compiler option to target NVIDIA Tesla GPUs. -Minfo=accel: Provides feedback about the code generated by the compiler. 常用命令 循环\n#pragma acc parallel: GPU 并行运算 #pragma acc kernels: Identifies a code block for parallelization, allowing the compiler to automatically manage parallelism. #pragma acc loop: Used within parallel or kernels regions to indicate loops that should be parallelized. 函数和变量 #pragma acc routine: 让一个函数可以在 GPU 代码中被调用（也可以在 CPU 代码调用）。 #pragma acc declare: Used for declaring variables or creating a data region. 数据传输 #pragma acc data: Manages data movement to and from the GPU. #pragma acc enter data: Specifies data that should be moved to the GPU. #pragma acc exit data: Specifies data to be moved back from the GPU. #pragma acc update: Synchronizes data between the host and the GPU. copy, copyin, copyout, create, present: Clauses for data construct to define how data is handled (e.g., whether it\u0026rsquo;s copied to/from the GPU or just created there). 线程精细控制 gang, worker, vector: Used with loop directive to control how loop iterations are distributed over parallel execution units. collapse(n): Collapses nested loops to enhance parallelism. reduction(operator:list): Performs a reduction operation (like sum, max) across parallel elements. ","date":"2025-01-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/openacc/","title":"【HPC】 OpenACC介绍"},{"content":"References OMP、MPI培训文档 并行程序设计导论 OpenMP tutorial github OpenMP详细介绍专栏 OpenMP official website openMP paper 介绍 OpenMP属于片上通信、跨核并行、共享存储式并行，支持跨平台共享内存方式的多线程编程接口（规范）。\nOpenMP编程三要素 编译指导（Compiler Directive，19）：包含并行域指令、工作共享指令、同步指令、数据环境 运行库函数（Runtime Library Routines，32） 环境变量（Environment Variables，9） Note OpenMP编程模型：内存共享模型，OpenMP是专为多处理器/核，共享内存机器所设计的。底层架构可以是UMA和NUMA。即(Uniform Memory Access和Non-Uniform Memory Access) 基于线程的并行性 显示的控制并行，极高的控制度 共享变量（默认），私有变量（通过private指定），数据竞争（Race Condition）（通过critical和atomic等同步机制） CPU在主存上有L1、L2、L3多级缓存，L3为多核共有，但L1和L2为每个核心私有，所以存在缓存一致性问题（False Sharing） Fork-Join模型：以一个主线程开始，通过fork创建并行线程组，通过join同步合并只留下主线程。 使用 编译 1 2 3 4 #include \u0026lt;omp.h\u0026gt; \u0026gt; gcc -fopenmp test.c \u0026gt; export OMP_NUM_THREADS=n # 指定线程数量，omp_get_num_threads()获取 \u0026gt; ./a.out 编译器指令 OpenMP编译器指令用于各种目的： 产生平行区域 在线程之间划分代码块 在线程之间分配循环迭代 序列化代码段 线程之间的工作同步 格式如下 #pragma omp \u0026lt;directive\u0026gt; [clause[[,] clause] ...] 通用规则：\n区分大小写 指令遵循编译指令的C/C++规则 每个指令只能指定一个指令名 每个指令最多使用一个后续语句，该语句必须是结构化块 通过在指令行末尾用反斜杠（“\\”）转义换行符，可以在后续行上“继续”长指令行 OpenMP基本指令 1、定义并行区域 #pragma omp parallel 用途: 定义一个并行区域，启动多个线程并行执行该区域中的代码。 示例： 1 2 3 4 #pragma omp parallel { // 并行执行的部分 } #pragma omp for 用途: 将循环的迭代分配给多个线程并行执行。 示例： 1 2 3 4 #pragma omp parallel for for (int i = 0; i \u0026lt; n; i++) { // 并行执行的循环体 } #pragma omp single 用途：指定代码块只由第一个到达线程执行，其他线程跳过该代码块。 2、同步机制(Synchronization) #pragma omp critical 用途: 定义一个临界区，保证代码块在同一时刻只被一个线程执行，以防止竞争条件。 1 2 3 4 5 6 7 8 9 10 11 12 13 float res; #pragma omp parallel { float B; int i, id, nthrds; id = omp_get_thread_num0; nthrds=omp_get_num_threads0; for(i=id;i\u0026lt;niters;i+=nthrds){ B= big _job(i); #pragma omp critical //Threads wait their turn. Only one at a time calls consume() res += consume (B); } } #pragma omp barrier 用途: 强制所有线程在此处同步，确保所有线程都执行到这一步后，才继续执行后续代码。 1 2 3 4 5 6 7 #pragma omp parallel { int id=omp_get_thread_num0; A[id] = big_calc1 (id); #pragma omp barrier // 只有当所有线程都到达barrier的时候才会继续运行 B[id] = big_calc2(id, A); } #pragma omp atomic 1 2 3 4 5 6 7 8 #pragma omp parallel { double tmp, B; B= DOITO; tmp = big ugly(B); #pragma omp atomic X+= tmp; } #pragma omp for 1 2 3 4 5 6 7 #pragma omp parallel { #pragma omp for for(i=0;i\u0026lt;n;i++){ // i is private by default do...; } } 3、变量的作用域 shared：默认情况下，并行区域外申明的变量在并行区域中是共享的，可以使用shared子句显式指定变量为共享的。 示例： 1 2 3 4 5 int a; #pragma omp parallel for shared(a) for (int i = 0; i \u0026lt; n; i++) { // a为公有变量 } private：每个线程在并行区域中有自己独立的变量副本，线程之间相互独立，互不干扰。并行区域内申明的变量默认为私有的，并行区域外申明的变量需要显式申明private 示例： 1 2 3 4 5 6 int a; #pragma omp parallel for private(a) for (int i = 0; i \u0026lt; n; i++) { int b; //a,b均为私有变量 } reduction： 用于将每个线程的私有变量在并行区域结束时进行归约（如求和、求最大值等），最终将结果存储到共享变量中。 示例： 1 2 3 4 5 int sum = 0; #pragma omp parallel for reduction(+:sum) for (int i = 0; i \u0026lt; 10; i++) { sum += i; } 4、调度方法 static：静态调度将循环的迭代均匀分配给所有线程，并且相邻的迭代会被分配在同一个线程，分配方式在程序开始执行时就已经确定。 示例: 1 2 3 4 #pragma omp parallel for schedule(static, 3) for (int i = 0; i \u0026lt; n; i++) { // 每个线程执行3个连续的迭代 } dynamic：动态调度在执行时分配迭代，每当一个线程完成当前分配的迭代时，它会动态获取下一个块的迭代。 guided：引导调度是一种动态调度的变体，但块大小（chunk size）随着任务的完成而逐渐减小。 auto：自动调度将调度策略的选择权交给编译器或运行时库，由它们决定最佳的调度方式。 runtime：运行时调度允许在程序运行时通过环境变量设置调度策略。 环境变量 OMP_SCHEDULE：负责规定调度方式。 OMP_NUM_THREADS：设置执行期间要使用的最大线程数。 OMP_PROC_BIND：启用或禁用线程绑定到处理器。有效值为TRUE或FALSE。 OMP_STACKSIZE：控制创建（非主）线程的堆栈大小。 ","date":"2025-01-06T00:00:00Z","permalink":"https://loveleaves.github.io/p/openmp/","title":"【HPC】 OpenMP介绍"},{"content":"References HPC/ML/OS/SW性能工具总结 汇编/嵌入式编程工具 在 Linux 环境下进行汇编或嵌入式编程时，涉及的工具和程序非常广泛，包括编译器、调试工具、构建系统、性能分析工具等。下面是一些常见的汇编或嵌入式编程工具的详细介绍：\n汇编工具 (Assembly Tools) GAS (GNU Assembler) GAS 是 GNU 编译器集合（GCC）的一部分，专门用于将汇编语言转换成机器代码（即目标文件）。它支持多种体系结构，适用于嵌入式系统开发，通常与 GCC 配合使用。\n常用选项：\n-o \u0026lt;file\u0026gt;: 指定输出文件。 -g: 生成调试信息。 -D \u0026lt;macro\u0026gt;: 定义宏。 示例：\n1 as -o main.o main.s 交叉编译工具链 (Cross Compiler Toolchain) GCC (GNU Compiler Collection) GCC 是用于 C、C++、Fortran 等语言的编译器，常用于嵌入式编程中。它可以生成目标平台的代码，并支持交叉编译（cross-compilation），即在一种平台上为另一种平台编译代码。\n常用选项：\n-o \u0026lt;file\u0026gt;: 输出文件。 -mcpu=\u0026lt;target\u0026gt;: 指定目标架构（如 ARM、MIPS）。 -m32 或 -m64: 设置生成的代码是 32 位或 64 位。 示例：\n1 arm-none-eabi-gcc -o my_program.elf main.c Clang Clang 是 LLVM 项目的一部分，作为 GCC 的替代品，Clang 提供了高效的编译功能，并且具有更加友好的错误报告。它同样支持交叉编译，特别适合现代嵌入式编程和集成开发环境（IDE）中使用。\n常用选项：\n-target \u0026lt;target\u0026gt;: 指定目标平台。 -o \u0026lt;file\u0026gt;: 输出文件。 示例：\n1 clang -target arm-none-eabi -o my_program.elf main.c Binutils Binutils 是一组二进制工具，包括汇编器、链接器、调试器等，广泛用于嵌入式系统开发。ld 和 as 工具是其中最常用的，负责汇编、链接以及生成目标文件。\n常用工具：\nas：汇编源文件。 ld：链接目标文件生成最终的可执行文件。 objcopy：将目标文件转换为不同格式。 示例：\n1 2 as -o main.o main.s ld -o my_program.elf main.o 调试工具 (Debugging Tools) GDB (GNU Debugger) GDB 是一个功能强大的调试工具，适用于 C/C++ 等程序的调试。在嵌入式开发中，GDB 通常配合交叉编译工具链和硬件调试器（如 JTAG、SWD）一起使用。\n常用命令：\nrun：启动程序。 break \u0026lt;line\u0026gt;：在指定行设置断点。 step：单步执行，进入函数。 next：单步执行，不进入函数。 示例：\n1 gdb my_program.elf OpenOCD OpenOCD 是一个用于与目标硬件（如 ARM 处理器）进行通信的调试工具。它支持通过 JTAG 或 SWD 接口进行调试，可以与 GDB 配合使用。\n常用命令：\ntargets：列出连接的目标。 reset halt：复位并停止目标。 flash write_image erase \u0026lt;file\u0026gt; 0x0：将固件烧录到设备。 示例：\n1 openocd -f interface/stlink-v2.cfg -f target/stm32f4x.cfg JLink (SEGGER J-Link) JLink 是 SEGGER 提供的一个商业级调试器，支持 JTAG 和 SWD 接口，用于调试各种嵌入式设备。它提供高性能的调试功能，广泛用于工业和开发中。\n主要功能：\n支持高速调试，能够快速读写内存和寄存器。 与多种 IDE（如 Keil、IAR、Eclipse）兼容。 提供强大的脚本支持和自动化功能。 常用命令：\nconnect: 连接目标硬件。 r: 重置目标设备。 loadfile : 加载二进制文件到目标设备。 示例：\n1 JLinkExe -device STM32F407VG -if SWD LLDB LLDB 是 LLVM 提供的调试工具，类似于 GDB，但更加现代化。它具有更高效的性能，特别适用于基于 Clang 的编译工具链。\n常用命令：\nrun：启动程序。 breakpoint set：设置断点。 step：单步执行。 示例：\n1 lldb my_program.elf 构建工具 (Build Tools) Make Make 是一个非常常用的构建工具，使用 Makefile 管理项目的编译过程。它会根据 Makefile 中的规则自动执行编译、链接等操作，尤其适合嵌入式项目。\n常用命令：\nmake：构建项目。 make clean：清理编译结果。 示例：\n1 make -f Makefile CMake CMake 是一个跨平台的自动化构建工具，可以生成适用于不同平台的构建文件（如 Makefile、Ninja 文件等）。它在现代嵌入式开发中非常流行，支持复杂的项目构建配置。\n常用命令：\ncmake .：生成构建文件。 make：执行构建。 示例：\n1 2 cmake . make 其他工具 nm nm 是一个用于列出二进制文件（例如可执行文件、共享库、目标文件等）符号表的工具。它显示文件中定义和引用的符号，包括函数、变量等。通过 nm，用户可以查看符号的类型和地址信息。\n常用选项：\nnm : 列出指定文件的符号。 -g: 只显示全局符号。 -n 或 \u0026ndash;numeric-sort: 按地址排序符号。 示例：\n1 nm my_program|grep func Objdump objdump 用于反汇编和查看目标文件的详细信息。它可以显示汇编代码、符号表、段信息等，帮助开发人员理解程序的低级结构。\n常用命令：\nobjdump -d \u0026lt;file\u0026gt;：反汇编文件。 objdump -t \u0026lt;file\u0026gt;：显示符号表。 示例：\n1 objdump -d my_program Readelf readelf 用于显示 ELF 文件的详细信息，提供比 objdump 更加专注于 ELF 文件结构的查看。它支持查看 ELF 头、段、节区、符号表等信息。\n常用命令：\nreadelf -h \u0026lt;file\u0026gt;：显示 ELF 文件头信息。 readelf -S \u0026lt;file\u0026gt;：显示节区信息。 示例：\n1 readelf -h my_program 热点分析 热点分析通常通过使用 性能分析工具 来实现，工具会提供每个函数、方法、代码块的执行时间、调用次数、CPU 占用率等信息，帮助开发人员识别耗时最多的部分。\n常见的热点分析方法 调用图（Call Graph）：通过调用图分析函数之间的调用关系，找到调用最频繁的部分。 性能剖析（Profiling）：通过工具生成程序运行时的性能数据，分析哪些函数或代码块占用了最多的时间或资源。 热代码路径（Hot Code Path）分析：关注那些频繁执行的路径或分支，优化这些路径的性能。 内存热点分析：分析程序中哪些数据结构或对象频繁创建、销毁，导致内存管理不善或频繁的垃圾回收。 实际操作 函数级分析：分析程序中的每个函数，找出耗时最多的函数并进行优化。 多线程/并发分析：对于并发程序，热点分析还要考虑线程的执行时间、锁竞争和同步问题，识别线程间的性能瓶颈。 内存分析：分析内存的分配和释放，找出内存泄漏或频繁的内存分配导致的性能瓶颈。 性能分析工具 gprof：GNU profile工具 适用语言：C、C++、Pascal、Fortran 介绍：用于程序的性能优化以及程序瓶颈问题的查找和解决。通过分析应用程序运行时产生的“flat profile”，可以得到每个函数的调用次数，每个函数消耗的处理器时间，也可以得到函数的“调用关系图”，包括函数调用的层次关系，每个函数调用花费了多少时间。 缺点：对并行程序支持较差，不能提供细粒度的分析，主要适用于函数级别的性能分析。 使用步骤：\n1、用gcc、g++、xlC编译程序时，使用-pg参数，如：g++ -pg -o test test.cpp。编译器会自动在目标代码中插入用于性能测试的代码片断，这些代码在程序运行时采集并记录函数的调用关系和调用次数，并记录函数自身执行时间和被调用函数的执行时间。 2、执行编译后的可执行程序，如：./test。该步骤运行程序的时间会稍慢于正常编译的可执行程序的运行时间。程序运行结束后，会在程序所在路径下生成一个缺省文件名为gmon.out的文件，这个文件就是记录程序运行的性能、调用关系、调用次数等信息的数据文件。 3、使用gprof命令来分析记录程序运行信息的gmon.out文件，如：gprof test gmon.out。则可以在显示器上看到函数调用相关的统计、分析信息。 Perf 适用语言： C, C++ 平台： Linux 特点： Perf 是 Linux内置的性能分析工具，可用于分析 CPU 使用率、内存访问、系统调用等。它是一个命令行工具。适用于深度的 Linux 系统级性能分析。 缺点：需要一定的学习成本，报告可能较为复杂。 Perf是一个很大的工具，此处仅展示分析某个应用的的用法。 使用步骤（使用gprof的那个可执行文件）：\n1、perf record ./test，部分性能参数需要root权限 2、perf report References\nhttps://www.brendangregg.com/perf.html perf tutorial WSL2安装perf perf原理及火焰图 perf分析c热点函数 perf简单例子-程序调用栈火焰图\n1 2 3 4 5 6 7 8 9 10 11 perf record -F 99 -p 2347 -g -- sleep 30 # perf record表示采集系统事件, 没有使用 -e 指定采集事件, 则默认采集 cycles(即 CPU clock 周期), -F 99 表示每秒 99 次, -p 2347 是进程号, 即对哪个进程进行分析, -g 表示记录调用栈, sleep 30 则是持续 30 秒. # 统计每个调用栈出现的百分比, 然后从高到低排列 perf report -n –stdio # 解析perf收集的信息 perf script -i perf.data \u0026amp;\u0026gt; perf.unfold # 生成折叠后的调用栈 # 使用开源软件：https://github.com/brendangregg/FlameGraph.git ./stackcollapse-perf.pl perf.unfold \u0026amp;\u0026gt; perf.folded # 生成火焰图 ./flamegraph.pl perf.folded \u0026gt; perf.svg perf简单例子-分析热点函数、指令\n1 2 3 4 5 6 7 8 # 通过-g选项保留源代码信息 gcc -g test.c -o test # 通过perf record命令对test程序采样，-g表示采样调用栈 perf record -F 999 ./test # 查看热点分布 perf report # 查看热点函数testA中的热点指令及语句 perf annotate --stdio --symbol=testA Intel VTune Profiler 适用语言： 多语言支持 平台： Windows、Linux 特点： Intel VTune Profiler 是一个功能强大的性能分析工具，可用于分析 CPU 使用率、内存访问、多线程性能等。适用于 Intel 处理器。 可以看到 perf 看不到L3cache 等硬件特性 references\nhttps://www.cnblogs.com/bandaoyu/p/16751995.html https://zhuanlan.zhihu.com/p/12642264312 https://blog.csdn.net/yaojingqingcheng/article/details/120335335 TAU 适用语言： C、C++、python 官网：https://www.cs.uoregon.edu/research/tau/home.php 特点： 是一个面向MPI与OpenMP并行程序的profiler，在目前看到的OpenMPI的Profiler中算是比较健全的一个。相比于Intel的vtune面向OpenMPI的时候会有些限制，TAU可以根据不同的MPI发行版重新编译。 references\nTAU Profiler安装 python 使用性能测试工具TAU测试MPI程序记录 深入解析TAU工具 GPU 分析工具 全部工具：https://developer.nvidia.com/tools-overview\ncuda-gdb cuda-gdb -g -G编译选项 Nsight Compute nvprof，计算能力8.0以下使用 注意系统要求（如win11 ws2才支持）：system-requirements、unknown-error-on-device-0-when-running-ncu-on-wsl 使用方案：\n1、用户界面：https://docs.nvidia.com/nsight-compute/NsightCompute/index.html 2、CLI方式：https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html ComputeSanitizer https://docs.nvidia.com/compute-sanitizer/ComputeSanitizer/index.html#id1\n功能正确性检查工具，包含：memcheck、racecheck、initcheck、synccheck等 cuda12.0以下内存检查使用CUDA-MEMCHECK，以上使用ComputeSanitizer HPCtoolkit 适用语言： C、C++、CUDA 官网：HPCToolkit 特点：支持CUDA 内存分析工具 gdb：-g源码调试 tsan TSan（ThreadSanitizer）是一个用于检测多线程程序中的 数据竞争 和 线程安全问题 的工具。它是由 Google 开发的，用于帮助开发者发现并修复多线程程序中的并发问题，这些问题可能导致难以复现的错误和难以调试的行为。\n1. 什么是数据竞争？ 数据竞争是指多个线程并发地访问同一块内存区域，并且至少有一个线程在写入该内存区域，而其他线程可能在读或写该内存。数据竞争通常会导致不可预测的程序行为，比如程序崩溃、结果错误等。数据竞争的问题尤其难以发现，因为它们通常依赖于程序执行的特定时序和上下文。\n2. TSan 的功能 ThreadSanitizer 是一种 动态检测工具，它能够监测并发程序中的线程交互，并在检测到数据竞争时，给出详细的报告。它通过 **插桩（Instrumentation） **方式，插入检查代码，追踪每个线程对共享内存的访问，以此来检测潜在的数据竞争。\n具体功能包括：\n检测数据竞争：在多线程程序中，TSan 能够发现不同线程对同一内存位置的并发访问（读-写或写-写），并且报告潜在的数据竞争。 报告细节：当 TSan 检测到数据竞争时，会提供详细的错误报告，包含竞争发生的栈信息、线程信息、访问的内存位置等，帮助开发者定位问题。 跨平台支持：TSan 支持 Linux、macOS、Android 和其他平台，通常与 Clang 和 GCC 编译器兼容。 3. 如何使用 TSan TSan 是通过编译器插件实现的，因此需要在编译程序时启用它。以下是启用 TSan 的基本步骤：\n1 2 3 4 5 6 7 8 9 10 # 1、编译时启用 TSan，使编译器将 TSan 插桩到代码中，在程序运行时启用线程安全检查。 g++ -fsanitize=thread -g test.cpp -o test # 2、运行时，程序将被 TSsan 监控，检测线程间的竞争。 ./test # 如果程序中有数据竞争，TSan 会输出类似以下的报告： ThreadSanitizer: data race in function \u0026#39;foo\u0026#39; at address 0x601000000020 #0 0x7f89b5cb5e6f in foo #1 0x7f89b5cb5e79 in bar #2 0x7f89b5cb5f89 in main TSan 会提供详细的栈跟踪，指出哪些线程、哪些内存地址、在哪些函数中发生了数据竞争。 4. TSan 的工作原理 TSan 通过对程序进行 插桩，在程序中每次内存访问（读/写）时插入检查代码，追踪每个线程对内存的访问。它会记录每个线程对共享内存的访问并进行比较，以判断是否存在数据竞争。\n主要机制：\n内存访问追踪：TSan 会追踪每个线程对内存地址的访问情况，记录访问的时间戳和线程标识。 同步原语检测：TSan 会检查线程之间的同步操作（如 mutex、lock、atomic）是否正确使用，确保线程安全。 数据竞争检测：如果两个线程访问同一内存位置，并且至少一个是写操作，TSan 会标记为潜在的数据竞争。 5. TSan 检测的线程安全问题 除了检测数据竞争，TSan 还可以帮助识别以下并发编程中的常见问题：\n死锁：如果两个线程因相互等待而导致死锁，TSan 也可以通过检测锁的顺序和依赖关系来帮助识别死锁。 非原子操作：在多线程环境中，如果某些操作不是原子的，可能会导致竞态条件。TSan 可以通过对同步操作的检查，帮助发现这些问题。 不当的内存同步：如果线程没有适当的同步机制（如 mutex 或 atomic）来协调对共享数据的访问，可能会出现竞态条件，TSan 会标记这些不安全的内存访问。 6. TSan 的优点和限制\n优点：能够捕获到很难复现的多线程问题，提供详细的报告，包括访问的内存位置、线程栈、数据竞争的上下文，帮助开发者快速定位并修复问题。 限制：会有一定的性能开销（开发阶段使用），可能不会检测所有类型的并发问题，特别是某些边缘情况或者深度依赖于硬件的并发问题。 AddressSanitizer (ASan) ASan（AddressSanitizer）是一个用于检测 内存错误 的强大工具，特别是针对 缓冲区溢出、堆栈溢出、使用后释放（use-after-free）等常见内存问题。ASan 是由 Google 开发的，作为一个 编译时检测工具，它可以在程序运行时检测出许多类型的内存错误，并提供详细的错误报告。ASan 可以用于 C 和 C++ 等语言，广泛应用于开发和测试阶段，帮助开发者发现和修复难以调试的内存错误。\nASan 的功能 ASan 的核心功能是通过 内存访问跟踪 来检测程序中的各种内存错误。它能有效检测以下几类常见的内存问题： 缓冲区溢出（Buffer Overflow）：当程序写入超出分配内存的区域时，会导致数据损坏或程序崩溃。 堆栈溢出（Stack Overflow）：当程序的栈内存超出预定范围时，可能会覆盖局部变量或函数返回地址。 使用后释放（Use-After-Free）：指在内存被释放后，程序仍然访问该内存。 内存泄漏（Memory Leak）：指程序分配了内存但没有释放，导致内存消耗不断增加。 双重释放（Double Free）：指在释放内存后再次释放该内存，可能导致程序崩溃。 未初始化内存读取（Use of Uninitialized Memory）：程序读取未初始化的内存内容，可能导致不可预测的行为。 ASan 的工作原理 ASan 通过 编译器插桩（Instrumenting Compiler）和 运行时库（Runtime Library）的配合工作来检测内存错误。 编译时插桩：在程序的源代码编译过程中，ASan 会插入额外的检查代码，这些代码会在程序运行时检查每个内存访问，确保它们在合法的内存范围内。 内存分配替换：ASan 会替换程序的 内存分配函数（如 malloc、free、new、delete）来监控内存的分配和释放操作。 内存红区（Redzones）：ASan 在每个内存块的前后插入一些特殊的 \u0026ldquo;红区\u0026rdquo;（Redzones），这些区域用于检测 越界访问。如果程序试图访问红区，ASan 会报告错误。 运行时检测：当程序访问非法内存时，ASan 会触发 运行时错误检测，并输出详细的错误信息（如错误的内存地址、堆栈信息等）。 如何使用 ASan 要启用 AddressSanitizer，您需要在编译时添加 -fsanitize=address 选项，并启用调试信息 -g（以便于调试）。 1 g++ -fsanitize=address -g -o test test.cpp ASan 错误报告 当 ASan 检测到内存错误时，它会生成详细的错误报告。该报告通常包含以下信息： 错误类型：如 use-after-free、buffer overflow、stack overflow 等。 错误位置：报告发生错误的内存地址，指出程序在哪里进行非法内存访问。 调用栈：ASan 会提供程序的调用栈信息，帮助开发者快速定位问题。 内存布局：显示内存分配情况，包括程序访问的内存区域和红区位置。 ASan 检测的内存问题 ASan 可以检测的内存问题包括： 堆栈溢出（Stack Overflow）：当局部变量超出栈边界时，ASan 会报告堆栈溢出。 缓冲区溢出（Buffer Overflow）：当访问超出数组或缓冲区的范围时，ASan 会检测到缓冲区溢出。 使用后释放（Use-After-Free）：在内存被释放后，如果程序继续使用该内存，ASan 会报告此错误。 内存泄漏（Memory Leak）：ASan 可以检测到程序中未释放的内存（通过启用 -fsanitize=address 和使用 ASAN_OPTIONS=detect_leaks=1）。 双重释放（Double Free）：当程序尝试两次释放同一块内存时，ASan 会报告此问题。 未初始化内存访问（Use of Uninitialized Memory）：当程序访问未初始化的内存时，ASan 会报告此错误。 ASan 的优点和缺点 优点：高效的内存错误检测、易于使用、详细的错误报告、广泛支持。 缺点：性能开销、仅支持动态检测、依赖编译器。 valgrind 平台：Linux / macOS / Windows（通过 Cygwin） 用途：Valgrind 是一款开源的动态分析工具，广泛用于 内存分析，如查找内存泄漏、内存越界等问题。 功能： Memcheck：用于检测内存泄漏、越界访问和未初始化的内存读取。 Cachegrind：用于缓存行为分析，评估 CPU 缓存的命中率。 Callgrind：支持函数级别的性能分析，提供详细的 CPU 性能数据。 Helgrind：用于检测并发程序中的数据竞争。 适用场景：适用于内存优化、程序调试和多线程程序的性能分析。 使用方式：通过命令行运行程序时加上 valgrind，比如 valgrind \u0026ndash;leak-check=full ./my_program。 优点：强大的内存分析功能，能够检测很多潜在的错误。 缺点：运行时开销较大，程序执行速度可能会减慢。 eBPF (Extended Berkeley Packet Filter) 类型：内核性能分析工具 功能：eBPF 可以用于监控系统的 CPU 使用情况、内存分配、I/O 性能、网络流量 等。 使用场景：eBPF 适用于 Linux 系统的全栈性能分析，特别是在容器化环境中（如 Kubernetes、Docker）。 优点：能够高效且低开销地进行性能分析，实时提供系统各个层次的性能数据。 缺点：需要一定的学习成本，并且工具的设置可能比较复杂。 在现代计算中，性能优化是提高程序效率、响应时间、资源利用率等重要方面的核心工作。不同类型的性能瓶颈可以通过不同的优化策略来解决，常见的优化策略包括并行度优化、数据传输优化、存储器访问优化、向量化优化、负载均衡优化和多线程扩展性优化。下面将详细介绍每个优化策略。\n性能优化策略 1. 并行度优化（Parallelism Optimization） 并行度优化是指将计算任务拆分成多个独立的子任务，利用多核处理器或多台机器的计算能力来加速计算过程。并行度优化主要关注如何高效地将任务分解并利用多个计算资源。\n核心策略： 任务划分：将计算任务划分为多个相对独立的子任务，确保每个子任务都能并行执行。划分可以基于数据分割或功能划分。 并行模型选择：选择合适的并行编程模型，如多线程、分布式计算、SIMD（单指令多数据）等，依赖于硬件架构和应用的需求。 粒度控制：控制任务的划分粒度，避免过多的细小任务带来的上下文切换开销。任务太小可能引发更多的线程启动和调度开销，反而会降低性能。 避免线程同步问题：在并行化时，尽量减少线程间的同步需求，如锁的竞争等，因为锁竞争会增加线程等待时间，影响性能。 实例： 多核处理器利用：将计算密集型任务分配给不同的 CPU 核心。 GPU 加速：使用图形处理单元（GPU）进行并行计算，例如深度学习中广泛使用的并行训练。 2. 数据传输优化（Data Transfer Optimization） 数据传输优化关注的是如何减少计算过程中数据的传输开销，尤其是在多核、多节点或大规模并行计算环境中，数据传输的延迟和带宽限制可能成为性能瓶颈。\n核心策略： 减少数据传输量：尽量减少进程之间、计算节点之间的通信量。可以通过局部计算、减少数据的复制或压缩数据传输来减少带宽消耗。 数据预取：根据访问模式预测数据的需求，提前加载数据到缓存中，从而减少等待时间。 内存映射与共享内存：使用共享内存或内存映射文件来避免频繁的进程间通信，特别是在多进程或多线程的应用程序中。 局部性优化：将数据分配到物理内存的本地区域，减少跨节点或跨芯片的数据传输。 实例： 在多节点集群中，避免每次计算都从主存储器加载大量数据，而是通过缓存和局部数据共享来减少传输。 在 GPU 和 CPU 之间，使用较小的批次数据传输，以减少 GPU 与主机之间的通信开销。 3. 存储器访问优化（Memory Access Optimization） 存储器访问优化主要目的是减少内存访问延迟，提高内存带宽的利用率。内存访问模式的不合理会造成严重的性能瓶颈，尤其是对于大规模数据的计算密集型任务。\n核心策略： 数据局部性优化：通过优化数据访问模式，提高数据在缓存中的命中率。可分为时间局部性（重复访问相同数据）和空间局部性（访问数据时的空间邻近性）。 缓存优化：优化程序数据结构，使数据在缓存中更容易命中，从而减少访问主内存的次数。使用预取技术和合理的缓存对齐可以显著提高缓存命中率。 避免不必要的内存访问：减少冗余的内存访问，如不必要的内存复制或多次访问相同的数据。 非一致性存储模型优化：在多处理器系统中，保持各个缓存一致性可能导致额外的开销，优化缓存一致性协议和访问策略可以提升性能。 实例： 优化矩阵运算时，按行或按列的顺序访问数据，以提高缓存命中率。 使用 NUMA（Non-Uniform Memory Access）架构时，避免频繁地访问远程内存，尽量保持计算和数据存储在同一个节点的本地内存中。 4. 向量化优化（Vectorization Optimization） 向量化是指将标量操作转换为向量操作，在单条指令中处理多个数据元素。现代处理器，尤其是具有SIMD（单指令多数据）指令集的处理器，能够通过向量化提升计算效率。\n核心策略： 利用SIMD指令：使用 SIMD 指令集（如 AVX、SSE、NEON 等）对数据进行向量化操作，在单个指令周期内处理多个数据元素。 编译器自动向量化：现代编译器（如 GCC、Clang、Intel Compiler）能够自动识别可以向量化的循环，并进行相应优化。 手动优化：在一些复杂的场景中，可以手动编写 SIMD 代码，通过内联汇编或编写特定的 SIMD 库来实现向量化优化。 数据对齐：确保数据存储在合适的内存地址对齐，以便在向量化时避免额外的开销。 实例： 在图像处理、科学计算等应用中，使用 SIMD 向量化技术对每个像素或数据点执行并行操作（如加法、乘法等）。 5. 负载均衡优化（Load Balancing Optimization） 负载均衡优化是指在多处理器、多核心或分布式系统中，合理分配计算任务，以避免某些处理器过载或闲置，从而提高计算资源的利用率。\n核心策略： 任务划分：合理划分任务，将计算负载均匀地分配给不同的计算单元。划分粒度要合适，避免过细的划分导致调度开销。 动态负载均衡：在运行时动态调整任务的分配，以应对负载变化和计算资源的不均衡。例如，在多核环境中，动态地将任务从负载较重的核心转移到空闲的核心上。 数据局部性和负载均衡的结合：在多核或多节点环境中，除了考虑负载均衡，还要考虑任务和数据的局部性，避免数据传输引发的性能瓶颈。 实例： 在分布式计算中使用负载均衡策略，避免某些计算节点过载，其他节点空闲。 在多核处理器上，使用调度算法动态调整任务负载。 6. 多线程扩展性优化（Multithreading Scalability Optimization） 多线程扩展性优化关注的是如何使程序在多核或多处理器系统上运行时能够保持良好的性能提升，尤其是在线程数增加时，如何避免性能的下降。\n核心策略： 避免线程竞争：合理设计程序，减少线程间的资源竞争。过多的锁、临界区和线程同步会导致线程间的阻塞，从而影响程序的扩展性。 线程数的调优：选择合适的线程数，避免过多线程带来的上下文切换开销。通常，线程数不应超过处理器核心数。 工作窃取（Work Stealing）：在多线程应用中，可以使用工作窃取算法，通过让空闲线程从负载较重的线程中窃取任务，平衡负载，提升扩展性。 任务划分粒度：避免过小或过大的任务粒度，过小的任务会增加线程调度开销，过大的任务则可能导致资源利用率不足。 实例： 在多核机器上，动态调整线程数，以适应任务的计算需求和机器的硬件能力。 在并行计算中，使用线程池和任务队列来有效管理线程的创建和销毁。 环境模拟 docker qemu docs\nqemu安装ARM QEMU启动ARM64 Linux内核 大致思路是： 安装qemu-system-aarch64（ARM-64bit）模拟器； 安装aarch64-linux-gnu（ARM-64bit）交叉编译器； 交叉编译linux源码，得到ARM64 Linux内核镜像； 交叉编译busybox源码，使用busybox制作initramfs； 最后使用qemu-system-aarch64启用ARM64 Linux内核； 环境管理/运维 微服务 k8s python conda 其他 内容比较compare Beyond Compare 代码调用关系 cflow：静态分析工具，用来生成 C/C++ 程序的调用图。 Callgrind：动态函数分析 ","date":"2025-01-05T00:00:00Z","permalink":"https://loveleaves.github.io/p/tool/","title":"【Tool】 记录各种用到的工具"},{"content":"介绍 CUDA（Compute Unified Device Architecture，统⼀计算架构）是由 NVIDIA 开发的并行计算平台和编程模型，旨在利用 NVIDIA GPU（图形处理单元）强大的并行计算能力来加速计算密集型任务。CUDA 提供了一种编程接口，让程序员能够直接访问 GPU 上的计算资源。通过并行化计算任务，可以显著提升执行效率。GPU 相较于 CPU，在处理大量并行任务时具有显著的优势，通常拥有成百上千的处理核心（CUDA 核心），能够同时执行大量的操作。\n核心指标：核心数、GPU显存容量、GPU计算峰值、显存带宽 GPU不能单独计算，CPU+GPU组成异构计算架构：CPU起到控制作用，一般称为主机（Host）；GPU可以看作CPU的协处理器，一般称为设备（Device）；主机和设备之间内存访问一般通过PCIe总线链接。 CUDA 提供两层API接口：CUDA驱动(driver)API和CUDA运行时(runtime)API CUDA驱动(driver)API cuda driver使用方式：libcuda.so和cuda.h，cuda-driver-api context管理机制：方便管理device 手动管理的context,cuCtxCreate(手动管理，以堆栈方式push/pop) 自动管理的context,cuDevicePrimaryCtxRetain(自动管理，runtime api以此为基础) 首先需要调用culnit初始化驱动API CUDA运行时(runtime)API cuda runtime使用方式：libcudart.so和cuda_runtime.h。runtime API随cuda toolkit发布 主要内容：核函数的使用、线程束布局、内存模型、流的使用 主要实现：归约求和、仿射变换、矩阵乘法、模型后处理 References 《CUDA 并行程序设计-GPU 编程指南》 第5、6、9章 https://github.com/loveleaves/ML_CPP/tree/main/ParallelFramework/CUDA cuda docs、programming-guide、best-practices-guide CIS 5650-GPU Programming and Architecture CUDA笔记 CUDALibrarySamples CUDA框架 基础编程框架 单文件example.cu编程框架\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 header inclusion const or macro definition declarations of C++ functions and CUDA kernels int main() { allocate host and device memory initialize data in host memory transfer data from host to device launch (call) kernel to do calculations in the device transfer data from device to host free host and device memory } definitions of C++ functions and CUDA kernels 编译指令\n1 nvcc -arch=sm_XY -code=compute_XY -o example example.cu nvcc编译工作原理 host code（standard C/C++ compiler）、device code（compiled into PTX/cubin） CUDA程序兼容性考虑：在将源代码编译为 PTX 代码时，需要用选项-arch=compute_XY指定一个虚拟架构的计算能力，用以确定代码中能够使用的CUDA功能。在将PTX代码编译为cubin代码时，需要用选项-code=sm_ZW指定一个真实架构的计算能力，用以确定可执行文件能够使用的GPU。 https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html Deep Dive into Triton Internals GPU设备设置 1、获取GPU设备数量 1 2 int iDeviceCount = 0; cudaGetDeviceCount(\u0026amp;iDeviceCount); 2、设置GPU执行时使用的设备 1 2 int iDev = 0; cudaSetDevice(iDev) 内存管理 主设内存管理 Note：GPU内存管理runtime接口传入的是双重指针。\n内存分配：malloc、cudaMalloc 数据传递：memcpy、cudaMemcpy 内存初始化：memset、cudaMemset 内存释放：free、cudaFree 主设内存传递\n1 cudaError_t cudaMemcpy(dst, src, count, kind); 枚举类型kind可取值：\ncudaMemcpyHostToHost，表示从主机复制到主机。 cudaMemcpyHostToDevice，表示从主机复制到设备。 cudaMemcpyDeviceToHost，表示从设备复制到主机。 cudaMemcpyDeviceToDevice，表示从设备复制到设备。 cudaMemcpyDefault，表示根据指针dst和src所指地址自动判断数据传输的方向。这要求系统具有统一虚拟寻址（unifiedvirtualaddressing）的功能（要求64位的主机）。 数据同步Synchronize 调用输出函数时，输出流是先存放在缓冲区的，而缓冲区不会自动刷新。只有程序遇到某种同步操作时缓冲区才会刷新。所以当要打印某个数据时，要先使用函数cudaDeviceSynchronize显式地同步主机与设备，促使缓冲区刷新。 核函数（Kernel function） 1、核函数在GPU上进行并行执行 2、注意： （1）限定词__global__ 修饰（可在void前后） （2）返回值必须是void （3）对于N是非blockSize整数倍时，必要时添加if，即使导致条件分支 注意事项：\n1、核函数只能访问GPU内存 2、核函数不能使用变长参数 3、核函数不能使用静态变量 4、核函数不能使用函数指针 5、核函数具有异步性 6、其他：核函数不支持C++的iostream 自定义设备函数 用__global__修饰的函数称为核函数，一般由主机调用，在设备中执行。如果使用动态并行，则也可以在核函数中调用自己或其他核函数。 用__device__修饰的函数叫称为设备函数，只能被核函数或其他设备函数调用，在设备中执行。 用__host__修饰的函数就是主机端的普通C++函数，在主机中被调用，在主机中执行。对于主机端的函数，该修饰符可省略。之所以提供这样一个修饰符，是因为有时可以用__host__和__device__同时修饰一个函数，使得该函数既是一个C++中的普通函数，又是一个设备函数。这样做可以减少冗余代码。编译器将针对主机和设备分别编译该函数。 不能同时用__device__和__global__修饰一个函数，即不能将一个函数同时定义为设备函数和核函数。 也不能同时用__host__和__global__修饰一个函数，即不能将一个函数同时定义为主机函数和核函数。 线程模型 线程的组织结构是由执行配置（executionconfiguration）\u0026laquo;\u0026lt;grid_size,block_size\u0026raquo;\u0026gt;决定的。这里的grid_size（网格大小）和block_size（线程块大小），对应核函数内部的内建变量 gridDim、blockDim、blockIdx、threadIdx 注意GPU系列对应框架最大允许的线程块大小，如1024 线程束：线程调度、管理 CUDA错误检查 运行时错误检测 所有CUDA运行时API函数都是以cuda为前缀的，而且都有一个类型为cudaError_t的返回值，代表了一种错误信息。只有返回值为cudaSuccess时才代表成功地调用了API函数。\n功能正确性检查 内存检查、越界访问、异常检查等 checktool 获得GPU加速的关键 CUDA事件计时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cudaEvent_t start, stop; CHECK(cudaEventCreate(\u0026amp;start)); CHECK(cudaEventCreate(\u0026amp;stop)); CHECK(cudaEventRecord(start)); cudaEventQuery(start); // 此处不能用 CHECK 宏函数，对处于TCC 驱动模式的 GPU 来说可以省略，但对处于 WDDM 驱动模式的GPU来说必须保留。 需要计时的代码块 CHECK(cudaEventRecord(stop)); CHECK(cudaEventSynchronize(stop)); float elapsed_time; CHECK(cudaEventElapsedTime(\u0026amp;elapsed_time, start, stop)); printf(\u0026#34;Time = %g ms.\\n\u0026#34;, elapsed_time); CHECK(cudaEventDestroy(start)); CHECK(cudaEventDestroy(stop)); 程序性能分析 Nsight Compute，详见tools\n影响GPU加速的关键因素 数据传输的比例：主设数据传输 算术强度（arithmeticintensity）：计算相比于数据传输耗时的占比 并行规模：数据规模要尽量匹配SM等计算资源 因此, 在编写与优化CUDA程序时，一定要想方设法（主要是指仔细设计算法）做到以下几点\n减少主机与设备之间的数据传输。 提高核函数的算术强度。 增大核函数的并行规模。 CUDA中的数学函数库 https://docs.nvidia.com/cuda/cuda-math-api/\n单精度浮点数内建函数和数学函数（singleprecisionintrinsics and math functions）。使用该类函数时不需要包含任何额外的头文件。 双精度浮点数内建函数和数学函数（doubleprecisionintrinsicsandmathfunctions）。使用该类函数时不需要包含任何额外的头文件。 半精度浮点数内建函数和数学函数（halfprecisionintrinsicsandmathfunctions）。使用该类函数时需要包含头文件\u0026lt;cuda_fp16.h\u0026gt;。 整数类型的内建函数（integerintrinsics）。使用该类函数时不需要包含任何额外的头文件。 类型转换内建函数（typecasting intrinsics）。使用该类函数时不需要包含任何额外的头文件。 单指令-多数据内建函数（SIMDintrinsics）。使用该类函数时不需要包含任何额外的头文件。 内存组织 分层思想，平衡成本和效率（在编码中体现为高内聚、低耦合） https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-variable-specifier 不同硬件架构的内存编排不一定相同 全局内存（global memory） 核函数中的所有线程都能够访问其中的数据，容量是所有设备内存中最大的。基本上就是显存容量。 主要为核函数提供数据，并在主机与设备及设备与设备之间传递数据。 host端访问数据：使用runtime接口cudaGetSymbolAddress() / cudaGetSymbolSize() / cudaMemcpyToSymbol() / cudaMemcpyFromSymbol() 同步函数__syncthreads()：只是针对同一个线程块中的线程的，不同线程块中线程的执行次序依然是不确定的（不同线程块数据要保证不依赖）。 在CUDA中还有一种内部构造对用户不透明的（nottransparent）全局内存，称为CUDAArray。CUDAArray使用英伟达公司不对用户公开的数据排列方式，专为纹理拾取服务。 动态全局内存\n生命周期（lifetime）不是由核函数决定的，而是由主机端决定的（cudaMalloc、cudaFree） 静态全局内存\n静态全局内存变量由以下方式在任何函数外部定义： 1 2 __device__ T x; // 单个变量 __device__ T y[N]; // 固定长度的数组 在核函数中，可直接对静态全局内存变量进行访问，并不需要将它们以参数的形式传给核函数。 常量内存（constant memory） 有常量缓存的全局内存，一共仅有64KB，位于常量内存空间，核函数外部用__constant__定义。 它的可见范围和生命周期与全局内存一样，host端访问数据与全局内存一样。 由于有缓存，常量内存的访问速度比全局内存高，但得到高访问速度的前提是一个线程束中的线程（一个线程块中相邻的32个线程）要读取相同的常量内存数据。 纹理内存（texture memory）和表面内存（surface memory） 类似于常量内存，也是一种具有缓存的全局内存，有相同的可见范围和生命周期，而且一般仅可读（表面内存也可写）。不同的是，纹理内存和表面内存容量更大，而且使用方式和常量内存也不一样。 对于计算能力5.0以上的GPU来说，将某些只读全局内存数据用__ldg()函数通过只读数据缓存（read-onlydatacache）读取，既可达到使用纹理内存的加速效果，又可使代码简洁。对帕斯卡架构和更高的架构来说，全局内存的读取在默认情况下就利用了__ldg()函数，所以不需要明显地使用它。 寄存器（register）和 局部内存（local memory） 存储函数入参、内建变量和临时变量等，32位。 计算能力5.0~9.0的GPU，每个中都是64K的寄存器数量，Fermi架构只有32K； 考虑：每个线程块使用的最大数量、每个线程的最大寄存器数量 局部内存是全局内存的一部分，寄存器溢出是保存在局部内存中。 共享内存（shared memory） 和寄存器类似，存在于芯片上，具有仅次于寄存器的读写速度，extern __shared__ float shared[]定义，数组大小在运行时确定,或__shared__ float shared[100]。 共享内存对整个线程块可见，其生命周期也与整个线程块一致。 一个线程块中的所有线程都可以访问该线程块的共享内存变量副本，但是不能访问其他线程块的共享内存变量副本。 注意避免n路bank冲突（n很大场景，类似TLB组相联）：共享内存在物理上被分为32个（刚好等于一个线程束中的线程数目，即内建变量warpSize的值）同样宽度的、能被同时访问的内存bank。在所有其他架构中，每个bank的宽度为4字节。当同一线程束内的多个线程不同时访问同一个bank中不同层的数据，该线程束对共享内存的访问就只需要一次内存事务（memory transaction）,就会发生bank冲突。 L1 和 L2 缓存 从费米架构开始，有了SM层次的L1缓存和设备（一个设备有多个SM）层次的L2缓存 SM及其占有率 SM（Streaming MultiProcessor）构成\n一个GPU是由多个SM构成的。一个SM包含如下资源（不同架构不一定相同）：\n一定数量的寄存器。 一定数量的共享内存。 常量内存的缓存。 纹理和表面内存的缓存。 L1缓存。 两个（计算能力6.0）或4个（其他计算能力）线程束调度器（warpscheduler），用于在不同线程的上下文之间迅速地切换，以及为准备就绪的线程束发出执行指令。 执行核心，包括： 若干整型数运算的核心（INT32）。 若干单精度浮点数运算的核心（FP32）。 若干双精度浮点数运算的核心（FP64）。 若干单精度浮点数超越函数（transcendentalfunctions）的特殊函数单元（Special Function Units，SFUs）。 若干混合精度的张量核心（tensorcores，由伏特架构引入，适用于机器学习中的低精度矩阵计算）。 SM管理\nGPU中每个SM都可以支持数百个线程并发执行 以线程块block为单位，向SM分配线程块，多个线程块可被同时分配到一个可用的SM上 当一个线程块被分配好后，就不可以在分配到其他上了 线程束（warp）\nCUDA 采用单指令多线程架构管理执行线程，每32个为一组，构成一个线程束。同一个线程块中相邻的 32个线程构成一个线程束 每个线程束中只能包含同一线程块中的线程 线程束是GPU硬件上真正的做到了并行 ** SM 的占有率**\n一般来说，要尽量让SM的占有率不小于某个值，比如%，才有可能获得较高的性能。 SM的理论占有率（theoreticaloccupancy）的两个指标: 一个SM中最多能拥有的线程块个数 一个SM中最多能拥有的线程个数 根据寄存器、共享内存等具体架构具体分析 高效正确地并发并行 原子函数（atomic function） cuda提供原子函数来进行控制数据一致性读写。其中atomicCAS函数是比较特殊的，所有其他原子函数都可以用它实现（指定架构不支持时，但性能可能较差）。\nAtomic APIs with _system suffix (example: atomicAdd_system) are atomic at scope cuda::thread_scope_system if they meet particular conditions. compute capability must greater than 7.2. Atomic APIs without a suffix (example: atomicAdd) are atomic at scope cuda::thread_scope_device. Atomic APIs with _block suffix (example: atomicAdd_block) are atomic at scope cuda::thread_scope_block. 线程束（warp）基本函数 一个SM以32个线程为单位产生、管理、调度、执行线程。这样的32 个线程称为一个线程束。 SM执行属于单指令-多线程（single instruction, multiple thread，SIMT）的执行模式：在同一时刻，一个线程束中的线程只能执行一个共同的指令或者闲置。 在伏特架构之前，一个线程束中的线程拥有同一个程序计数器（programcounter），但各自有不同的寄存器状态（registerstate），从而可以根据程序的逻辑判断选择不同的分支。因此当同一个线程束（不同的不会）中的线程顺序地执行判断语句中的不同分支时，会发生分支发散（branch divergence）。 从伏特架构开始，引入了独立线程调度（independentthreadscheduling）机制。每个线程有自己的程序计数器。这使得伏特架构有了一些以前的架构所没有的新的线程束内同步与通信的模式，但导致： 增加了寄存器负担：单个线程的程序计数器一般需要使用两个寄存器。 独立线程调度机制使得假设了线程束同步（warpsynchronous）的代码变得不再安全：必须显式同步。 线程束内的线程同步函数：都在一个线程束内时，可以将线程块同步函数__syncthreads 换成一个更加廉价的线程束同步函数__syncwarp。 其他基本函数： 线程束表决函数（warpvotefunctions） 线程束匹配函数（warpmatchfunctions） 线程束洗牌函数（warp shuffle functions） 线程束矩阵函数（warp matrix functions） 协作组（cooperativegroups） 类似线程块和线程束同步机制的推广，它提供了更为灵活的线程协作方式，包括线程块内部的同步与协作、线程块之间的（网格级的）同步与协作及设备之间的同步与协作。 https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction-cg CUDA流（CUDA stream） CUDA流介绍 主要用cuda流解决核函数外部的并行：\n核函数计算与数据传输之间的并行。 主机计算与数据传输之间的并行。 不同的数据传输（回顾一下cudaMemcpy函数中的第4个参数）之间的并行。 核函数计算与主机计算之间的并行。 不同核函数之间的并行。 任何CUDA操作都存在于某个CUDA流中，要么是默认流（default stream），也称为空流（null stream），要么是明确指定的非空流。\n在主机端产生与销毁。一个CUDA流由类型为cudaStream_t 的变量表示，cudaStreamCreate和cudaStreamDestroy创建和销毁。 为了实现不同CUDA流之间的并发，主机在向某个CUDA流中发布一系列命令之后必须马上获得程序的控制权，不用等待该CUDA流中的命令在设备中执行完毕。这样，就可以通过主机产生多个相互独立的CUDA流。 检查一个CUDA流中的所有操作是否都在设备中执行完毕：cudaStreamSynchronize同步、cudaStreamQuery查询 默认流（default stream）/ 为空流（null stream） 1 2 3 两种调用方式： my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block\u0026gt;\u0026gt;\u0026gt;(函数参数); my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block, N_shared\u0026gt;\u0026gt;\u0026gt;(函数参数); 核函数的启动是异步的（asynchronous），或者说是非阻塞的（non-blocking），所以会host会立即执行下一条语句。该命令如果是CUDA操作不会被device立即执行，因为这是默认流中的CUDA操作，必须等待前一个CUDA操作（即核函数的调用）执行完毕才会开始执行。 可以在核函数启动后放置host操作，利用前面CUDA操作完成时间。 非默认流/非空流 1 2 3 4 调用方式： my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid, N_block, N_shared, stream_id\u0026gt;\u0026gt;\u0026gt;(函数参数); my_kernel\u0026lt;\u0026lt;\u0026lt;N_grid,N_block, 0 ,stream_id\u0026gt;\u0026gt;\u0026gt;(函数参数); // 不使用动态共享内存 # stream_id是CUDA流的编号，N_shared是核函数中使用的动态共享内存的字节数。 用非默认CUDA流重叠核函数的执行与数据传递\n要实现核函数执行与数据传输的并发（重叠），必须让这两个操作处于不同的非默认流，而且数据传输必须使用cudaMemcpy函数的异步版本，即cudaMemcpyAsync函数。异步传输由GPU中的DMA（directmemoryaccess）直接实现，不需要主机参与。 在使用异步的数据传输函数时，需要将主机内存定义为不可分页内存（non-pageable memory）或者固定内存（pinned memory），在程序运行期间，其物理地址将保持不变，由cudaMallocHost和cudaFreeHost申请和释放。 统一内存（unifiedmemory）编程 介绍 统一内存是一种逻辑上的概念，一种系统中的任何处理器（CPU或GPU）都可以访问，并能保证一致性的虚拟存储器。这种虚拟存储器是通过CPU和GPU各自内部集成的内存管理单元（memorymanagementunit）实现的。 使用统一内存对硬件有较高的要求：不低于开普勒架构等。 好处：不用手动内存传输管理；相比手动内存操作可能会有更好的性能；超量分配，类似虚拟内存策略。 基本使用 统一内存在设备中是当作全局内存使用的，而且必须在主机端定义或分配内存，而不能在设备端（核函数和__device__函数）定义或分配内存。 动态申请：cudaMallocManaged 静态申请： __device____managed__int ret[1000]; 数据预取：cudaMemPrefetchAsync 多GPU编程 CUDA标准库 cuda所以接口及库详见官网：cuda docs、cuda developer\nThrust 类似于C++的标准模板库（standard template library）\nthrust、NCCL 数据结构：容器thrust::host_vector\u0026lt;typename\u0026gt;和thrust::device_vector\u0026lt;typename\u0026gt; 算法： 变换（transformation）。本书多次讨论的数组求和计算就是一种变换操作。 规约（reduction）。这是本书重点讨论过的算法。 前缀和（prefixsum）。下一节将详细讨论该算法。 排序（sorting）与搜索（searching）。 选择性复制、替换、移除、分区等重排（reordering）操作。 cuBLAS（basic linear algebra subprograms） 基本线性代数子程序，矩阵在内存中的存储是列主序（column-major order）的Fortran 风格，而不是像C语言中是行主序（row-majororder）的。\ncublas、blas cuBLAS 库包含3个API： cuBLAS API：相关数据必须在设备。 cuBLASXTAPI：相关数据必须在主机。 cuBLASLt API：一个专门处理矩阵乘法的API。 cuFFT 快速傅里叶变换（fast Fourier transforms）\ncufft cuSPARSE 稀疏（sparse）矩阵\ncusparse cusparse提供了一些稀疏矩阵、向量和稠密矩阵、向量的运算函数。 cuSolver 稠密（dense）矩阵和稀疏（sparse）矩阵计算库\ncuSolver 专注于一些比较高级的线性代数方面的计算，如矩阵求逆和矩阵对角化，类似LAPACK库。基于cuBLAS和cuSPARSE两个更基础的库实现。 cusolver、lapack cuSolver 库由以下3个相互独立的子库组成： cuSolverDN（DeNse, DN）：一个处理稠密矩阵线性代数计算的库。 cuSolverSP（SParse, SP）：一个处理稀疏矩阵的线性代数计算的库。 cuSolverRF（ReFactorization, RF）：一个特殊的处理稀疏矩阵分解的库。 cuSolver 库函数倾向于使用异步执行。为了保证一个cuSolver函数的工作已经完成，可以使用cudaDeviceSynchronize() 函数进行同步。 cuRAND 与随机数生成有关的库,包含伪随机数（pseudorandom numbers）和准随机数（quasirandom numbers）。\ncurand cuRand是后向兼容（backward compatible）的，注意cuRAND 和 the CUDA runtime的版本对应 提供了两种API：主机API和设备API。 cuDNN 深度神经网络（deep neural networks）\n是一个用于深度神经网络的 GPU 加速基元库。cuDNN 为标准例程（如前向和后向卷积、注意力、matmul、池化和规范化）提供高度优化的实现。 cudnn docs、cudnn developer ","date":"2025-01-03T00:00:00Z","permalink":"https://loveleaves.github.io/p/gpu/","title":"【GPU】 GPU架构及使用介绍"},{"content":"References openmlsys https://www.zhihu.com/question/26754848 ML Architecture 编程接口 pybind ctypes Computational Graph (计算图) 计算图由基本数据结构张量（Tensor）和基本运算单元算子（operator）构成。在计算图中通常使用节点来表示算子，节点间的有向边（Directed Edge）来表示张量状态，同时也描述了计算间的依赖关系，通常为有向无环图DAG。\n计算图是机器学习框架的核心理念之一，了解主流机器学习框架的设计思想，有助于深入掌握这一概念，建议阅读 TensorFlow 设计白皮书、 PyTorch计算框架设计论文。\n图外控制流直接使用前端语言控制流，熟悉编程语言即可掌握这一方法，而图内控制流则相对较为复杂，建议阅读TensorFlow控制流论文。\n动态图和静态图设计理念与实践，建议阅读TensorFlow Eager 论文、TensorFlow Eager Execution示例、TensorFlow Graph理念与实践、MindSpore动静态图概念。\nTorch JIT\nhttps://github.com/louis-she/torchscript-demos https://zhuanlan.zhihu.com/p/370455320 pytorch2.0新特性：https://www.bilibili.com/video/BV1p84y1675B pytorch计算图例子 How Computational Graphs are Constructed in PyTorch AI编译器和前端技术 编译器前端基础结构\n传统编译器：video AI编译器: summary、video AI System 机器学习编译 主流编译器LLVM Getting Started with LLVM Core Libraries 用LLVM开发新语言 LLVM写个简易编译器1、LLVM写个简易编译器2 编译器后端和运行时 编译器后端总体架构简图\n硬件加速器 算子编译器 当前业界的算子编译器/编译框架主要有\nTVM/Ansor [Zheng et al., 2020] MLIR [Lattner et al., 2020] 华为昇腾芯片上的TBE/AKG [Zhao et al., 2021] 加速器实践 数据处理框架 数据模块的核心组件\n模块设计重点\n易用性 高效性 保序性 AI 推理框架 移动端 腾讯ncnn 模型部署 分布式训练 进阶： 华盛顿大学 Deep Learning Systems，机器学习程序的编译过程,Apache TVM深度学习编译器 AI Systems 微软亚洲研究院 ","date":"2024-12-10T00:00:00Z","permalink":"https://loveleaves.github.io/p/mlsys/","title":"【MLsys】机器学习系统介绍"},{"content":"多线程并行/并发 同一进程各个线程之间共享内存，可用多个线程并行执行，每个线程处理数据或操作的一部分，类似OpenMP。\n线程 操作系统调度的最小单位 每个进程可以有多个线程，线程之间共享进程的内存空间，但有自己的栈、寄存器等 线程切换涉及保存和恢复上下文，内存分配，线程同步等，具有一定的系统开销（注意衡量数据规模对应的线程数量）。 在多核处理器上，线程可以实现真正的并行计算。 在 C 语言中，线程通常通过 POSIX 线程（pthread）库来实现 使用 用多线程优化下面算子：\n1 2 3 4 5 6 7 int sum_array(int *arr, int len) { int sum = 0; for(int i = 0; i \u0026lt; len; ++i) { sum += arr[i]; } return sum; } C例子 优化完成程序：(在链接时指定 -pthread，告诉 GCC 在编译和链接时启用 POSIX 线程支持)\n仅使用多线程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; typedef struct { int *arr; int start; int end; int partial_sum; } ThreadData; void *sum_partial(void *arg) { ThreadData *data = (ThreadData *)arg; data-\u0026gt;partial_sum = 0; for (int i = data-\u0026gt;start; i \u0026lt; data-\u0026gt;end; ++i) { data-\u0026gt;partial_sum += data-\u0026gt;arr[i]; } return NULL; } int sum_array(int *arr, int len, int num_threads) { pthread_t *threads = malloc(sizeof(pthread_t) * num_threads); ThreadData *thread_data = malloc(sizeof(ThreadData) * num_threads); int chunk_size = len / num_threads; int remainder = len % num_threads; // Create threads to compute partial sums for (int i = 0; i \u0026lt; num_threads; ++i) { thread_data[i].arr = arr; thread_data[i].start = i * chunk_size; thread_data[i].end = (i == num_threads - 1) ? len : (i + 1) * chunk_size; // Handle remainder elements (if any) if (i == num_threads - 1 \u0026amp;\u0026amp; remainder != 0) { thread_data[i].end += remainder; } pthread_create(\u0026amp;threads[i], NULL, sum_partial, \u0026amp;thread_data[i]); } // Wait for all threads to finish and calculate the total sum int total_sum = 0; for (int i = 0; i \u0026lt; num_threads; ++i) { pthread_join(threads[i], NULL); total_sum += thread_data[i].partial_sum; } free(threads); free(thread_data); return total_sum; } int main() { int arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; int len = sizeof(arr) int num_threads = 4; int result = sum_array(arr, len, num_threads); printf(\u0026#34;Total sum: %d\\n\u0026#34;, result); return 0; } 使用多线程+互斥锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define NUM_THREADS 4 // 使用4个线程 // 线程参数结构体 typedef struct { int *arr; int start; int end; int *sum; pthread_mutex_t *mutex; } ThreadData; void* thread_sum(void *arg) { ThreadData *data = (ThreadData *)arg; int partial_sum = 0; for (int i = data-\u0026gt;start; i \u0026lt; data-\u0026gt;end; ++i) { partial_sum += data-\u0026gt;arr[i]; } // 使用互斥锁保护共享资源sum pthread_mutex_lock(data-\u0026gt;mutex); *data-\u0026gt;sum += partial_sum; pthread_mutex_unlock(data-\u0026gt;mutex); return NULL; } int sum_array(int *arr, int len, int *sum, pthread_mutex_t *sum_mutex) { pthread_t threads[NUM_THREADS]; ThreadData thread_data[NUM_THREADS]; int chunk_size = len / NUM_THREADS; // 创建线程 for (int i = 0; i \u0026lt; NUM_THREADS; ++i) { thread_data[i].arr = arr; thread_data[i].start = i * chunk_size; thread_data[i].end = (i == NUM_THREADS - 1) ? len : (i + 1) * chunk_size; // 最后一个线程处理剩余部分 thread_data[i].sum = sum; thread_data[i].mutex = sum_mutex; pthread_create(\u0026amp;threads[i], NULL, thread_sum, (void*)\u0026amp;thread_data[i]); } // 等待所有线程完成 for (int i = 0; i \u0026lt; NUM_THREADS; ++i) { pthread_join(threads[i], NULL); } return *sum; } int main() { int arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; // 示例数组 int len = sizeof(arr) / sizeof(arr[0]); int sum = 0; // 用于存储总和 pthread_mutex_t sum_mutex; // 互斥锁 pthread_mutex_init(\u0026amp;sum_mutex, NULL); // 调用sum_array进行求和 int result = sum_array(arr, len, \u0026amp;sum, \u0026amp;sum_mutex); pthread_mutex_destroy(\u0026amp;sum_mutex); printf(\u0026#34;Sum of array: %d\\n\u0026#34;, result); return 0; } C++ 例子 优化完成程序：(在链接时指定 -pthread，告诉 GCC 在编译和链接时启用 POSIX 线程支持)\n仅使用多线程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;thread\u0026gt; int sum_array(int *arr, int len) { const int num_threads = 4; int chunk_size = len / num_threads; std::vector\u0026lt;std::thread\u0026gt; threads(num_threads); std::vector\u0026lt;int\u0026gt; partial_sums(num_threads, 0); // 定义一个线程函数，用于计算某个范围内的和 auto sum_part = [\u0026amp;](int thread_id) { int start = thread_id * chunk_size; int end = (thread_id == num_threads - 1) ? len : (thread_id + 1) * chunk_size; for (int i = start; i \u0026lt; end; ++i) { partial_sums[thread_id] += arr[i]; } }; for (int i = 0; i \u0026lt; num_threads; ++i) { threads[i] = std::thread(sum_part, i); } for (int i = 0; i \u0026lt; num_threads; ++i) { threads[i].join(); } int total_sum = 0; for (int i = 0; i \u0026lt; num_threads; ++i) { total_sum += partial_sums[i]; } return total_sum; } int main() { // 示例数组 int arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; int len = sizeof(arr) / sizeof(arr[0]); int result = sum_array(arr, len); std::cout \u0026lt;\u0026lt; \u0026#34;Sum of array: \u0026#34; \u0026lt;\u0026lt; result \u0026lt;\u0026lt; std::endl; return 0; } 使用多线程+原子操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;numeric\u0026gt; // std::accumulate void partial_sum(const std::vector\u0026lt;int\u0026gt;\u0026amp; data, size_t start, size_t end, std::atomic\u0026lt;long long\u0026gt;\u0026amp; result) { long long partial_result = 0; for (size_t i = start; i \u0026lt; end; ++i) { partial_result += data[i]; } result += partial_result; // result += std::accumulate(data.data()+start, data.data()+end, 0); } int main() { const size_t data_size = 10000000; std::vector\u0026lt;int\u0026gt; data(data_size, 1); const size_t num_threads = 4; // std::thread::hardware_concurrency(); 获取硬件支持的线程数 std::vector\u0026lt;std::thread\u0026gt; threads; std::atomic\u0026lt;long long\u0026gt; result(0); size_t chunk_size = data_size / num_threads; for (size_t i = 0; i \u0026lt; num_threads; ++i) { size_t start = i * chunk_size; size_t end = (i == num_threads - 1) ? data_size : (i + 1) * chunk_size; // 最后一个线程处理剩余部分 threads.emplace_back(partial_sum, std::cref(data), start, end, std::ref(result)); } for (auto\u0026amp; t : threads) { t.join(); } std::cout \u0026lt;\u0026lt; \u0026#34;Total sum: \u0026#34; \u0026lt;\u0026lt; result.load() \u0026lt;\u0026lt; std::endl; return 0; } 使用多线程+互斥锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;mutex\u0026gt; void partial_sum(const std::vector\u0026lt;int\u0026gt;\u0026amp; data, size_t start, size_t end, long long\u0026amp; result, std::mutex\u0026amp; mtx) { long long local_sum = 0; for (size_t i = start; i \u0026lt; end; ++i) { local_sum += data[i]; } mtx.lock(); // std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mtx); result += local_sum; mtx.unlock(); } int main() { const size_t data_size = 1\u0026#39;000\u0026#39;000; const size_t thread_count = 4; std::vector\u0026lt;int\u0026gt; data(data_size, 1); long long result = 0; std::mutex mtx; std::vector\u0026lt;std::thread\u0026gt; threads; size_t chunk_size = data_size / thread_count; for (size_t i = 0; i \u0026lt; thread_count; ++i) { size_t start = i * chunk_size; size_t end = (i == thread_count - 1) ? data_size : start + chunk_size; threads.emplace_back(partial_sum, std::cref(data), start, end, std::ref(result), std::ref(mtx)); } for (auto\u0026amp; t : threads) { t.join(); } std::cout \u0026lt;\u0026lt; \u0026#34;Total sum: \u0026#34; \u0026lt;\u0026lt; result \u0026lt;\u0026lt; std::endl; return 0; } ","date":"2024-10-22T00:00:00Z","permalink":"https://loveleaves.github.io/p/multi_threads/","title":"【HPC】 C/C++多线程并行/并发"},{"content":"嵌入式编程介绍 嵌入式编程（Embedded Programming）是指在嵌入式系统中编写软件的过程，嵌入式系统通常是专门为某一特定任务设计的计算机系统，不像传统计算机那样可以运行多种应用程序。嵌入式系统的应用非常广泛，从智能家居设备、汽车控制系统、工业自动化，到医疗设备等，几乎无处不在。\n嵌入式编程是什么？ 嵌入式编程是为了控制嵌入式系统硬件而编写的软件。嵌入式系统通常具有以下特点：\n资源有限：嵌入式系统一般硬件资源有限，如内存、处理能力、电池寿命等。 任务专一：嵌入式系统通常只执行单一任务或有限的几个任务。 高实时性：很多嵌入式系统需要满足严格的实时性要求，即程序必须在特定时间内完成特定操作。 稳定性高：由于嵌入式设备通常需要长时间运行，因此软件的稳定性和可靠性至关重要。 嵌入式编程不仅仅是开发简单的软件，它还需要开发者对硬件有一定了解，能够在有限的资源下优化代码，确保系统的高效和稳定运行。\n嵌入式编程的基础 硬件平台 嵌入式编程首先需要选择合适的硬件平台。常见的嵌入式硬件平台包括：\n单片机（MCU）：例如STMicroelectronics的STM32、Atmel的AVR系列、Microchip的PIC系列等。单片机广泛应用于各种小型设备。 开发板：如树莓派、Arduino、ESP32等，它们适合快速原型开发。 FPGA：如Xilinx、Intel（Altera）等的FPGA芯片，适用于对硬件有高要求的应用。 ASIC：定制/半定制芯片，设计用于解决特殊需求。 嵌入式操作系统 对于一些复杂的嵌入式应用，开发者需要选择合适的操作系统来管理硬件资源。常见的嵌入式操作系统有：\nRTOS（实时操作系统）：如FreeRTOS、ChibiOS等，适用于需要高实时性的嵌入式应用。 Linux：例如在树莓派等开发板上运行嵌入式Linux，适用于需要丰富功能和较强处理能力的系统。 裸机编程：没有操作系统支持，直接对硬件进行编程，适用于资源较为有限的设备。 编程语言 嵌入式开发常用的编程语言主要有：\nC语言：由于其高效、底层控制能力和较小的代码体积，C语言是嵌入式编程中最常用的语言。 C++：对于一些更复杂的系统，C++提供了面向对象的特性，帮助开发者更好地管理代码。 汇编语言：在一些资源非常有限或者对性能要求极高的场景下，可能需要使用汇编语言来直接控制硬件。 嵌入式编程工具 嵌入式开发离不开合适的开发工具，这些工具通常包括：\nIDE（集成开发环境）：如Keil、IAR Embedded Workbench、Eclipse等，用于编写、编译和调试嵌入式代码。 编译器：GCC（GNU Compiler Collection）是最常用的开源编译器，它支持多种架构的嵌入式开发。 调试工具：JTAG调试器、SWD（Serial Wire Debug）调试器等，用于硬件级调试，帮助开发者实时查看代码执行状态。 仿真器：一些开发环境如Proteus提供硬件仿真，帮助开发者在没有实际硬件的情况下测试代码。 References soc介绍 深入理解CPU和异构计算芯片GPU/FPGA/ASIC （上篇） ","date":"2023-03-21T00:00:00Z","permalink":"https://loveleaves.github.io/p/embedded_programing/","title":"【嵌入式编程】 嵌入式编程介绍"}]